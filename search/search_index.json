{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projetos","text":"<p>Por Bruno Assis</p> <p>Este portf\u00f3lio apresenta uma cole\u00e7\u00e3o de projetos onde aplico compet\u00eancias em Machine Learning, an\u00e1lise de dados e engenharia de dados para resolver desafios complexos. Cada projeto detalha uma abordagem end-to-end: desde a coleta e o pr\u00e9-processamento dos dados at\u00e9 a implementa\u00e7\u00e3o de modelos e a extra\u00e7\u00e3o de insights acion\u00e1veis.</p>"},{"location":"#projetos-disponiveis","title":"Projetos dispon\u00edveis","text":"<ul> <li>Classifica\u00e7\u00e3o de flores iris</li> </ul> <p>Um estudo de caso cl\u00e1ssico utilizando o algoritmo de \u00c1rvore de Decis\u00e3o para classificar esp\u00e9cies de flores. Inclui a an\u00e1lise explorat\u00f3ria em notebook Jupyter e o relat\u00f3rio t\u00e9cnico completo do processo.</p> <p> Ver Projeto</p>"},{"location":"decision-tree/main/","title":"Main","text":"In\u00a0[15]: hide-input Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier, plot_tree from sklearn.metrics import accuracy_score, classification_report, confusion_matrix In\u00a0[16]: hide-input Copied! <pre># %%\n# Carrega o dataset Iris\niris = load_iris()\n\n# Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o\nX = pd.DataFrame(iris.data, columns=iris.feature_names)\ny = pd.Series(iris.target, name=\"species\")\n\n# Exibe as 5 primeiras linhas do DataFrame\nX.head()\n</pre> # %% # Carrega o dataset Iris iris = load_iris()  # Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o X = pd.DataFrame(iris.data, columns=iris.feature_names) y = pd.Series(iris.target, name=\"species\")  # Exibe as 5 primeiras linhas do DataFrame X.head() Out[16]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 In\u00a0[17]: Copied! <pre># %%\n# Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica\n(X.head()\n .style\n .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais\n .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela\n .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas\n)\n</pre> # %% # Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica (X.head()  .style  .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais  .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela  .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas ) Out[17]: As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 In\u00a0[18]: Copied! <pre># %%\n# Mostra estat\u00edsticas descritivas das vari\u00e1veis\nX.describe()\n</pre> # %% # Mostra estat\u00edsticas descritivas das vari\u00e1veis X.describe() Out[18]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 In\u00a0[19]: Copied! <pre># %%\n# Gera histogramas para cada vari\u00e1vel\nX.hist(figsize=(10, 8))\nplt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\")\nplt.show()\n</pre> # %% # Gera histogramas para cada vari\u00e1vel X.hist(figsize=(10, 8)) plt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\") plt.show() In\u00a0[20]: Copied! <pre># %%\n# Divide o dataset em treino (70%) e teste (30%)\n# O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> # %% # Divide o dataset em treino (70%) e teste (30%) # O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.3, random_state=42, stratify=y )  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n</pre> In\u00a0[21]: Copied! <pre># %%\n# Cria o classificador de \u00c1rvore de Decis\u00e3o\n# criterion=\"entropy\" usa a entropia como medida de impureza\nclf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n\n# Treina o modelo com os dados de treino\nclf.fit(X_train, y_train)\n\nprint(\"Modelo treinado com sucesso!\")\n</pre> # %% # Cria o classificador de \u00c1rvore de Decis\u00e3o # criterion=\"entropy\" usa a entropia como medida de impureza clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)  # Treina o modelo com os dados de treino clf.fit(X_train, y_train)  print(\"Modelo treinado com sucesso!\") <pre>Modelo treinado com sucesso!\n</pre> In\u00a0[22]: Copied! <pre># %%\n# Faz previs\u00f5es nos dados de teste\ny_pred = clf.predict(X_test)\n\n# Imprime a acur\u00e1cia\nprint(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))\n\n# Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score\nprint(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n</pre> # %% # Faz previs\u00f5es nos dados de teste y_pred = clf.predict(X_test)  # Imprime a acur\u00e1cia print(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))  # Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score print(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names)) <pre>Acur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n\n</pre> In\u00a0[23]: Copied! <pre># %%\n# Gera a matriz de confus\u00e3o\ncm = confusion_matrix(y_test, y_pred)\n\n# Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o\nplt.figure(figsize=(6, 5))\nsns.heatmap(\n    cm, \n    annot=True, \n    fmt=\"d\", \n    cmap=\"Blues\", \n    xticklabels=iris.target_names, \n    yticklabels=iris.target_names\n)\nplt.xlabel(\"Previsto\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o\")\nplt.show()\n</pre> # %% # Gera a matriz de confus\u00e3o cm = confusion_matrix(y_test, y_pred)  # Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o plt.figure(figsize=(6, 5)) sns.heatmap(     cm,      annot=True,      fmt=\"d\",      cmap=\"Blues\",      xticklabels=iris.target_names,      yticklabels=iris.target_names ) plt.xlabel(\"Previsto\") plt.ylabel(\"Real\") plt.title(\"Matriz de Confus\u00e3o\") plt.show() In\u00a0[24]: Copied! <pre># %%\n# Plota a \u00e1rvore de decis\u00e3o gerada\nplt.figure(figsize=(20, 12))\nplot_tree(\n    clf, \n    feature_names=iris.feature_names, \n    class_names=list(iris.target_names), \n    filled=True,\n    fontsize=10\n)\nplt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\")\nplt.show()\n</pre> # %% # Plota a \u00e1rvore de decis\u00e3o gerada plt.figure(figsize=(20, 12)) plot_tree(     clf,      feature_names=iris.feature_names,      class_names=list(iris.target_names),      filled=True,     fontsize=10 ) plt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\") plt.show()"},{"location":"decision-tree/main/","title":"\u00c1rvore de Decis\u00e3o","text":"sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <pre><code>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n\n\nModelo treinado com sucesso!\n\n\nAcur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n</code></pre>"},{"location":"projeto/main/","title":"Projeto de classifica\u00e7\u00e3o com \u00e1rvore de decis\u00e3o: Esp\u00e9cies de flores Iris","text":"<p>Autor: Bruno Assis</p>"},{"location":"projeto/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de classificar esp\u00e9cies de flores do g\u00eanero Iris com base em suas caracter\u00edsticas morfol\u00f3gicas. Para esta tarefa de classifica\u00e7\u00e3o, foi utilizado o algoritmo de \u00c1rvore de Decis\u00e3o, um dos modelos mais intuitivos e poderosos para problemas de classifica\u00e7\u00e3o.</p> <p>O desenvolvimento seguiu as etapas de explora\u00e7\u00e3o, pr\u00e9-processamento, divis\u00e3o dos dados, treinamento e avalia\u00e7\u00e3o do modelo, utilizando as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>.</p>"},{"location":"projeto/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1: Explora\u00e7\u00e3o dos dados","text":"<p>A primeira etapa consistiu em uma an\u00e1lise explorat\u00f3ria para entender a natureza e a estrutura do conjunto de dados Iris.</p>"},{"location":"projeto/main/#natureza-dos-dados","title":"Natureza dos dados","text":"<p>O dataset Iris \u00e9 um conjunto de dados cl\u00e1ssico da \u00e1rea de Machine Learning. Ele cont\u00e9m 150 amostras de flores Iris, divididas igualmente em 3 esp\u00e9cies diferentes: * Setosa * Versicolor * Virginica</p> <p>Para cada amostra, s\u00e3o fornecidas 4 caracter\u00edsticas (features) em cent\u00edmetros: 1.  Comprimento da S\u00e9pala (<code>sepal length</code>) 2.  Largura da S\u00e9pala (<code>sepal width</code>) 3.  Comprimento da P\u00e9tala (<code>petal length</code>) 4.  Largura da P\u00e9tala (<code>petal width</code>)</p> <p>O objetivo do modelo \u00e9, a partir dessas 4 medidas, prever corretamente a qual das 3 esp\u00e9cies a flor pertence.</p>"},{"location":"projeto/main/#estatisticas-descritivas","title":"Estat\u00edsticas descritivas","text":"<p>Uma an\u00e1lise estat\u00edstica nos ajuda a entender a distribui\u00e7\u00e3o e a escala de cada caracter\u00edstica. A tabela abaixo resume as principais m\u00e9tricas:</p> M\u00e9trica Comprimento da S\u00e9pala (cm) Largura da S\u00e9pala (cm) Comprimento da P\u00e9tala (cm) Largura da P\u00e9tala (cm) count 150.00 150.00 150.00 150.00 mean 5.84 3.06 3.76 1.20 std 0.83 0.44 1.77 0.76 min 4.30 2.00 1.00 0.10 25% 5.10 2.80 1.60 0.30 50% 5.80 3.00 4.35 1.30 75% 6.40 3.40 5.10 1.80 max 7.90 4.40 6.90 2.50 <p>A partir da tabela, notamos que as caracter\u00edsticas possuem escalas diferentes (por exemplo, <code>petal length</code> varia muito mais que <code>sepal width</code>), algo que seria importante para outros algoritmos, mas n\u00e3o tanto para \u00c1rvores de Decis\u00e3o.</p>"},{"location":"projeto/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":"<p>Os histogramas abaixo mostram a distribui\u00e7\u00e3o de cada uma das quatro caracter\u00edsticas. As visualiza\u00e7\u00f5es s\u00e3o cruciais para identificar quais features s\u00e3o mais promissoras para separar as classes.</p> <p>Distribui\u00e7\u00e3o das vari\u00e1veis</p> <p></p> <p>Analisando os gr\u00e1ficos, podemos inferir que o comprimento e a largura da p\u00e9tala (<code>petal length</code> e <code>petal width</code>) s\u00e3o caracter\u00edsticas muito poderosas para a classifica\u00e7\u00e3o, pois suas distribui\u00e7\u00f5es mostram agrupamentos mais distintos. J\u00e1 as medidas da s\u00e9pala (<code>sepal length</code> e <code>sepal width</code>) apresentam maior sobreposi\u00e7\u00e3o entre as esp\u00e9cies.</p>"},{"location":"projeto/main/#etapa-2-pre-processamento","title":"Etapa 2: Pr\u00e9-processamento","text":"<p>Nesta etapa, preparamos os dados para o treinamento do modelo.</p> <ul> <li> <p>Limpeza e Tratamento de Valores Ausentes: Foi realizada uma verifica\u00e7\u00e3o de valores nulos ou ausentes no conjunto de dados. O dataset Iris \u00e9 conhecido por ser completo e limpo, e a an\u00e1lise confirmou que n\u00e3o havia dados faltantes, portanto, nenhuma t\u00e9cnica de imputa\u00e7\u00e3o foi necess\u00e1ria.</p> </li> <li> <p>Normaliza\u00e7\u00e3o: Modelos baseados em \u00e1rvores, como a \u00c1rvore de Decis\u00e3o, n\u00e3o s\u00e3o sens\u00edveis \u00e0 escala das features. Eles tomam decis\u00f5es baseadas em pontos de corte (ex: \"comprimento da p\u00e9tala &lt; 2.45 cm?\"), independentemente de a vari\u00e1vel estar em cent\u00edmetros ou mil\u00edmetros. Por essa raz\u00e3o, a normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o dos dados n\u00e3o foi uma etapa necess\u00e1ria para este projeto.</p> </li> </ul>"},{"location":"projeto/main/#etapa-3-divisao-dos-dados","title":"Etapa 3: Divis\u00e3o dos dados","text":"<p>Para avaliar o modelo de forma justa, o conjunto de dados foi dividido em dois subconjuntos:</p> <ol> <li>Conjunto de Treino (70% dos dados): Usado para ensinar o modelo a reconhecer os padr\u00f5es.</li> <li>Conjunto de Teste (30% dos dados): Usado para avaliar o desempenho do modelo em dados \"novos\", que ele nunca viu antes.</li> </ol> <p>Utilizamos a fun\u00e7\u00e3o <code>train_test_split</code> da biblioteca <code>scikit-learn</code>. Um par\u00e2metro crucial utilizado foi a estratifica\u00e7\u00e3o (<code>stratify=y</code>). Isso garante que a propor\u00e7\u00e3o de cada uma das tr\u00eas esp\u00e9cies de flores seja a mesma tanto no conjunto de treino quanto no de teste, evitando desequil\u00edbrios que poderiam enviesar a avalia\u00e7\u00e3o do modelo.</p> <p>O resultado da divis\u00e3o foi: * Tamanho do conjunto de treino: 105 amostras * Tamanho do conjunto de teste: 45 amostras</p>"},{"location":"projeto/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4: Treinamento do modelo","text":"<p>O modelo escolhido foi o <code>DecisionTreeClassifier</code> da <code>scikit-learn</code>.</p> <p>A implementa\u00e7\u00e3o consistiu em: 1.  Instanciar o modelo: Foi criado um classificador de \u00c1rvore de Decis\u00e3o com o hiperpar\u00e2metro <code>criterion=\"entropy\"</code>. A entropia \u00e9 uma m\u00e9trica baseada em Teoria da Informa\u00e7\u00e3o que o algoritmo usa para escolher os melhores atributos e pontos de corte para dividir os dados em cada n\u00f3 da \u00e1rvore. 2.  Treinar o modelo: O modelo foi treinado utilizando o m\u00e9todo <code>.fit()</code>, que recebe os dados e as classes do conjunto de treino (<code>X_train</code>, <code>y_train</code>). Durante este processo, o algoritmo constr\u00f3i a \u00e1rvore de regras que melhor classifica os dados de treinamento.</p>"},{"location":"projeto/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5: Avalia\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s o treinamento, o desempenho do modelo foi avaliado utilizando o conjunto de teste.</p>"},{"location":"projeto/main/#metricas-de-desempenho","title":"M\u00e9tricas de desempenho","text":"<p>A performance foi medida com base nas seguintes m\u00e9tricas:</p> <ul> <li> <p>Acur\u00e1cia: A propor\u00e7\u00e3o de previs\u00f5es corretas sobre o total de amostras. O modelo atingiu uma acur\u00e1cia de aproximadamente 89%.</p> </li> <li> <p>Relat\u00f3rio de Classifica\u00e7\u00e3o: Fornece uma vis\u00e3o detalhada do desempenho para cada classe.</p> </li> </ul> Classe Precision Recall F1-Score Support setosa 1.00 1.00 1.00 15 versicolor 0.81 0.87 0.84 15 virginica 0.86 0.80 0.83 15 <p>Da tabela, conclu\u00edmos que: * A classe setosa foi perfeitamente classificada (100% em todas as m\u00e9tricas). * Houve uma pequena confus\u00e3o entre as classes versicolor e virginica, que s\u00e3o naturalmente mais parecidas entre si.</p>"},{"location":"projeto/main/#matriz-de-confusao","title":"Matriz de confus\u00e3o","text":"<p>A Matriz de Confus\u00e3o nos permite visualizar exatamente onde o modelo acertou e errou.</p> <p></p> <p>An\u00e1lise da matriz: * Linha 'setosa': 15 foram corretamente previstas como setosa. 0 erros. * Linha 'versicolor': 13 foram corretamente previstas como versicolor, mas 2 foram incorretamente classificadas como virginica. * Linha 'virginica': 12 foram corretamente previstas como virginica, mas 3 foram incorretamente classificadas como versicolor.</p>"},{"location":"projeto/main/#visualizacao-da-arvore-de-decisao","title":"Visualiza\u00e7\u00e3o da \u00c1rvore de decis\u00e3o","text":"<p>A \u00e1rvore gerada pelo modelo pode ser visualizada para entendermos as regras que ela aprendeu.</p> <p></p> <p>A raiz da \u00e1rvore (<code>petal length (cm) &lt;= 2.45</code>) mostra que a caracter\u00edstica mais importante para a primeira divis\u00e3o \u00e9 o comprimento da p\u00e9tala, confirmando nossa an\u00e1lise explorat\u00f3ria inicial.</p>"},{"location":"projeto/main/#etapa-6-relatorio-final-e-conclusao","title":"Etapa 6: Relat\u00f3rio final e conclus\u00e3o","text":"<p>O projeto demonstrou com sucesso a aplica\u00e7\u00e3o de um modelo de \u00c1rvore de Decis\u00e3o para um problema de classifica\u00e7\u00e3o. O modelo alcan\u00e7ou um desempenho robusto, com uma acur\u00e1cia de 89% no conjunto de teste, e foi capaz de aprender regras l\u00f3gicas e interpret\u00e1veis para distinguir entre as esp\u00e9cies de flores Iris.</p> <p>A an\u00e1lise das m\u00e9tricas revelou que o modelo \u00e9 extremamente eficaz em identificar a esp\u00e9cie <code>setosa</code>, mas apresenta uma pequena dificuldade na distin\u00e7\u00e3o entre <code>versicolor</code> e <code>virginica</code>, que s\u00e3o morfologicamente mais similares.</p>"},{"location":"projeto/main/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<p>Para aprimorar ainda mais o desempenho do modelo, os seguintes passos poderiam ser explorados:</p> <ol> <li>Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros: Utilizar t\u00e9cnicas como Grid Search ou Random Search para encontrar a melhor combina\u00e7\u00e3o de hiperpar\u00e2metros (como <code>max_depth</code> e <code>min_samples_leaf</code>), o que pode reduzir o superajuste e melhorar a generaliza\u00e7\u00e3o.</li> <li>Valida\u00e7\u00e3o Cruzada (Cross-Validation): Empregar a valida\u00e7\u00e3o cruzada k-fold para obter uma estimativa mais est\u00e1vel e confi\u00e1vel do desempenho do modelo.</li> <li>Compara\u00e7\u00e3o com Outros Modelos: Treinar e avaliar outros algoritmos de classifica\u00e7\u00e3o, como Random Forest (que \u00e9 um conjunto de \u00e1rvores de decis\u00e3o), SVM ou Regress\u00e3o Log\u00edstica, para comparar os resultados.</li> <li>An\u00e1lise de Import\u00e2ncia das Features: Extrair e visualizar a import\u00e2ncia de cada uma das quatro caracter\u00edsticas para entender quais delas mais contribu\u00edram para as decis\u00f5es do modelo.</li> </ol>"}]}