{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projetos","text":"<p>Por Bruno Assis</p> <p>Este portf\u00f3lio apresenta uma cole\u00e7\u00e3o de projetos onde aplico compet\u00eancias em Machine Learning, an\u00e1lise de dados e engenharia de dados para resolver desafios complexos. Cada projeto detalha uma abordagem end-to-end: desde a coleta e o pr\u00e9-processamento dos dados at\u00e9 a implementa\u00e7\u00e3o de modelos e a extra\u00e7\u00e3o de insights acion\u00e1veis.</p>"},{"location":"#projetos-disponiveis","title":"Projetos dispon\u00edveis","text":"<ul> <li> <p>Clusteriza\u00e7\u00e3o de Dados com K-Means</p> <p>Um projeto de aprendizado n\u00e3o supervisionado utilizando o algoritmo K-Means para identificar grupos (clusters) naturais em um conjunto de dados. A an\u00e1lise inclui a determina\u00e7\u00e3o do n\u00famero ideal de clusters atrav\u00e9s do M\u00e9todo do Cotovelo e a avalia\u00e7\u00e3o da qualidade do agrupamento.</p> <p> Ver Projeto</p> </li> </ul> <ul> <li> <p>Compara\u00e7\u00e3o de M\u00e9tricas: KNN vs. K-Means</p> <p>Uma an\u00e1lise comparativa entre um algoritmo supervisionado (KNN) e um n\u00e3o supervisionado (K-Means) na tarefa de classifica\u00e7\u00e3o do dataset Iris. O projeto foca na gera\u00e7\u00e3o e interpreta\u00e7\u00e3o de m\u00e9tricas de avalia\u00e7\u00e3o.</p> <p> Ver Projeto</p> </li> <li> <p>Classifica\u00e7\u00e3o de Qualidade de Vinhos</p> <p>Um projeto completo de classifica\u00e7\u00e3o para prever a qualidade de vinhos com base em suas caracter\u00edsticas f\u00edsico-qu\u00edmicas. O estudo compara o desempenho de tr\u00eas algoritmos distintos: \u00c1rvore de Decis\u00e3o, KNN e o m\u00e9todo n\u00e3o supervisionado K-Means.</p> <p> Ver Projeto</p> </li> <li> <p>Classifica\u00e7\u00e3o de solo por sat\u00e9lite</p> <p>Um projeto de classifica\u00e7\u00e3o para determinar o tipo de solo a partir de dados multiespectrais de sat\u00e9lite, utilizando o algoritmo K-Nearest Neighbors (KNN). O processo inclui pr\u00e9-processamento, padroniza\u00e7\u00e3o de features e avalia\u00e7\u00e3o de performance.</p> <p> Ver Projeto</p> </li> </ul> <ul> <li> <p>Classifica\u00e7\u00e3o de flores iris</p> <p>Um estudo de caso cl\u00e1ssico utilizando o algoritmo de \u00c1rvore de Decis\u00e3o para classificar esp\u00e9cies de flores. Inclui a an\u00e1lise explorat\u00f3ria em notebook Jupyter e o relat\u00f3rio t\u00e9cnico completo do processo.</p> <p> Ver Projeto</p> </li> </ul>"},{"location":"K-MEANS/main/","title":"Main","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport seaborn as sns\n\nprint(\"Bibliotecas importadas com sucesso.\")\n</pre> import matplotlib.pyplot as plt import pandas as pd from sklearn.datasets import make_blobs from sklearn.preprocessing import StandardScaler from sklearn.cluster import KMeans from sklearn.metrics import silhouette_score import seaborn as sns  print(\"Bibliotecas importadas com sucesso.\") <pre>Bibliotecas importadas com sucesso.\n</pre> In\u00a0[2]: Copied! <pre># ETAPA 1: EXPLORA\u00c7\u00c3O DOS DADOS\n\n# Gera\u00e7\u00e3o de um conjunto de dados sint\u00e9tico para simular dados de sat\u00e9lites\nX, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.80, random_state=42)\n\n# Convertendo para um DataFrame do Pandas\ndf = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])\n\nprint(\"Cabe\u00e7alho do DataFrame:\")\ndisplay(df.head())\n\nprint(\"\\nEstat\u00edsticas Descritivas:\")\ndisplay(df.describe())\n</pre> # ETAPA 1: EXPLORA\u00c7\u00c3O DOS DADOS  # Gera\u00e7\u00e3o de um conjunto de dados sint\u00e9tico para simular dados de sat\u00e9lites X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.80, random_state=42)  # Convertendo para um DataFrame do Pandas df = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])  print(\"Cabe\u00e7alho do DataFrame:\") display(df.head())  print(\"\\nEstat\u00edsticas Descritivas:\") display(df.describe()) <pre>Cabe\u00e7alho do DataFrame:\n</pre> Feature_1 Feature_2 0 -9.205816 6.643647 1 -9.526658 7.015878 2 -1.851162 8.037611 3 -7.053772 -6.001088 4 -10.468827 6.517054 <pre>\nEstat\u00edsticas Descritivas:\n</pre> Feature_1 Feature_2 count 300.000000 300.000000 mean -3.402433 2.847806 std 5.253569 6.209243 min -10.815643 -8.511495 25% -7.953934 -0.992925 50% -4.866389 5.268670 75% -0.238470 8.042539 max 6.491606 10.984880 In\u00a0[10]: Copied! <pre># Visualiza\u00e7\u00e3o inicial dos dados n\u00e3o rotulados\nprint(\"Gerando visualiza\u00e7\u00e3o dos dados brutos...\")\nplt.figure(figsize=(10, 7))\nsns.scatterplot(x='Feature_1', y='Feature_2', data=df, s=50)\nplt.title('Visualiza\u00e7\u00e3o do Conjunto de Dados Sint\u00e9tico (N\u00e3o Rotulado)')\nplt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)')\nplt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)')\nplt.grid(True)\nplt.savefig('main_files/visualizacao_inicial.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # Visualiza\u00e7\u00e3o inicial dos dados n\u00e3o rotulados print(\"Gerando visualiza\u00e7\u00e3o dos dados brutos...\") plt.figure(figsize=(10, 7)) sns.scatterplot(x='Feature_1', y='Feature_2', data=df, s=50) plt.title('Visualiza\u00e7\u00e3o do Conjunto de Dados Sint\u00e9tico (N\u00e3o Rotulado)') plt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)') plt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)') plt.grid(True) plt.savefig('main_files/visualizacao_inicial.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando visualiza\u00e7\u00e3o dos dados brutos...\n</pre> In\u00a0[5]: Copied! <pre># ETAPA 2: PR\u00c9-PROCESSAMENTO\n\n# Verifica\u00e7\u00e3o de valores ausentes (embora saibamos que n\u00e3o h\u00e1 neste caso)\nprint(\"Verifica\u00e7\u00e3o de valores ausentes:\")\nprint(df.isnull().sum())\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados\nprint(\"\\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\")\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"Dados padronizados com sucesso.\")\n</pre> # ETAPA 2: PR\u00c9-PROCESSAMENTO  # Verifica\u00e7\u00e3o de valores ausentes (embora saibamos que n\u00e3o h\u00e1 neste caso) print(\"Verifica\u00e7\u00e3o de valores ausentes:\") print(df.isnull().sum())  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados print(\"\\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\") scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  print(\"Dados padronizados com sucesso.\") <pre>Verifica\u00e7\u00e3o de valores ausentes:\nFeature_1    0\nFeature_2    0\ndtype: int64\n\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\nDados padronizados com sucesso.\n</pre> In\u00a0[11]: Copied! <pre># ETAPA 4 (PARTE 1): Descoberta do 'k' \u00f3timo\n\n# Calculando a in\u00e9rcia (WCSS) para diferentes valores de k\nwcss = []\nk_range = range(1, 11)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)\n    kmeans.fit(X_scaled)\n    wcss.append(kmeans.inertia_)\n\n# Plotando o gr\u00e1fico do M\u00e9todo do Cotovelo\nprint(\"Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\")\nplt.figure(figsize=(10, 7))\nplt.plot(k_range, wcss, marker='o', linestyle='--')\nplt.title('M\u00e9todo do Cotovelo (Elbow Method)')\nplt.xlabel('N\u00famero de Clusters (k)')\nplt.ylabel('WCSS (In\u00e9rcia)')\nplt.xticks(k_range)\nplt.grid(True)\nplt.savefig('main_files/metodo_cotovelo.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 4 (PARTE 1): Descoberta do 'k' \u00f3timo  # Calculando a in\u00e9rcia (WCSS) para diferentes valores de k wcss = [] k_range = range(1, 11)  for k in k_range:     kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)     kmeans.fit(X_scaled)     wcss.append(kmeans.inertia_)  # Plotando o gr\u00e1fico do M\u00e9todo do Cotovelo print(\"Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\") plt.figure(figsize=(10, 7)) plt.plot(k_range, wcss, marker='o', linestyle='--') plt.title('M\u00e9todo do Cotovelo (Elbow Method)') plt.xlabel('N\u00famero de Clusters (k)') plt.ylabel('WCSS (In\u00e9rcia)') plt.xticks(k_range) plt.grid(True) plt.savefig('main_files/metodo_cotovelo.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\n</pre> In\u00a0[8]: Copied! <pre># ETAPA 4 (PARTE 2): Treinamento do modelo final\n\n# Definindo o k \u00f3timo com base no gr\u00e1fico anterior\nk_otimo = 4\nprint(f\"O n\u00famero \u00f3timo de clusters escolhido foi k = {k_otimo}.\")\n\n# Treinando o modelo final\nkmeans_final = KMeans(n_clusters=k_otimo, n_init='auto', random_state=42)\nkmeans_final.fit(X_scaled)\n\n# Capturando os r\u00f3tulos e os centroides\ncluster_labels = kmeans_final.labels_\ncentroids = kmeans_final.cluster_centers_\n\n# Adicionando os r\u00f3tulos dos clusters ao DataFrame\ndf['cluster'] = cluster_labels\n\nprint(\"Modelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\")\n</pre> # ETAPA 4 (PARTE 2): Treinamento do modelo final  # Definindo o k \u00f3timo com base no gr\u00e1fico anterior k_otimo = 4 print(f\"O n\u00famero \u00f3timo de clusters escolhido foi k = {k_otimo}.\")  # Treinando o modelo final kmeans_final = KMeans(n_clusters=k_otimo, n_init='auto', random_state=42) kmeans_final.fit(X_scaled)  # Capturando os r\u00f3tulos e os centroides cluster_labels = kmeans_final.labels_ centroids = kmeans_final.cluster_centers_  # Adicionando os r\u00f3tulos dos clusters ao DataFrame df['cluster'] = cluster_labels  print(\"Modelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\") <pre>O n\u00famero \u00f3timo de clusters escolhido foi k = 4.\nModelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\n</pre> In\u00a0[12]: Copied! <pre># ETAPA 5: AVALIA\u00c7\u00c3O DO MODELO\n\n# Visualiza\u00e7\u00e3o dos clusters encontrados pelo algoritmo\nprint(\"Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\")\nplt.figure(figsize=(10, 7))\nsns.scatterplot(x='Feature_1', y='Feature_2', hue='cluster', data=df, palette='viridis', s=50, legend='full')\n\n# Plotando os centroides (des-escalados para a escala original dos dados)\ncentroids_original_scale = scaler.inverse_transform(centroids)\nplt.scatter(centroids_original_scale[:, 0], centroids_original_scale[:, 1], s=200, c='red', marker='X', label='Centroides')\n\nplt.title(f'Clusters Encontrados pelo K-Means (k={k_otimo})')\nplt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)')\nplt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)')\nplt.legend()\nplt.grid(True)\nplt.savefig('main_files/clusters_finais.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n# Avalia\u00e7\u00e3o Quantitativa: Score de Silhueta (Silhouette Score)\nsilhouette_avg = silhouette_score(X_scaled, cluster_labels)\nprint(f\"\\nO Score de Silhueta para k={k_otimo} \u00e9: {silhouette_avg:.4f}\")\n</pre> # ETAPA 5: AVALIA\u00c7\u00c3O DO MODELO  # Visualiza\u00e7\u00e3o dos clusters encontrados pelo algoritmo print(\"Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\") plt.figure(figsize=(10, 7)) sns.scatterplot(x='Feature_1', y='Feature_2', hue='cluster', data=df, palette='viridis', s=50, legend='full')  # Plotando os centroides (des-escalados para a escala original dos dados) centroids_original_scale = scaler.inverse_transform(centroids) plt.scatter(centroids_original_scale[:, 0], centroids_original_scale[:, 1], s=200, c='red', marker='X', label='Centroides')  plt.title(f'Clusters Encontrados pelo K-Means (k={k_otimo})') plt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)') plt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)') plt.legend() plt.grid(True) plt.savefig('main_files/clusters_finais.png', dpi=300, bbox_inches='tight') plt.show()   # Avalia\u00e7\u00e3o Quantitativa: Score de Silhueta (Silhouette Score) silhouette_avg = silhouette_score(X_scaled, cluster_labels) print(f\"\\nO Score de Silhueta para k={k_otimo} \u00e9: {silhouette_avg:.4f}\") <pre>Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\n</pre> <pre>\nO Score de Silhueta para k=4 \u00e9: 0.8386\n</pre>"},{"location":"K-MEANS/main/","title":"An\u00e1lise Visual do Agrupamento K-Means","text":"<p>A seguir, s\u00e3o apresentados os resultados visuais chave do processo de clusteriza\u00e7\u00e3o, desde a explora\u00e7\u00e3o inicial dos dados at\u00e9 a avalia\u00e7\u00e3o final do modelo.</p>"},{"location":"K-MEANS/main/#1-visualizacao-inicial-dos-dados","title":"1. Visualiza\u00e7\u00e3o Inicial dos Dados","text":"<p>Gr\u00e1fico de dispers\u00e3o do conjunto de dados antes da aplica\u00e7\u00e3o de qualquer algoritmo. A distribui\u00e7\u00e3o sugere a presen\u00e7a de agrupamentos naturais, que buscaremos identificar.</p> <p></p>"},{"location":"K-MEANS/main/#2-determinacao-do-numero-de-clusters-metodo-do-cotovelo","title":"2. Determina\u00e7\u00e3o do N\u00famero de Clusters (M\u00e9todo do Cotovelo)","text":"<p>A curva de in\u00e9rcia (WCSS) foi plotada para diferentes valores de <code>k</code>. O \"cotovelo\" formado no gr\u00e1fico aponta <code>k=4</code> como o n\u00famero \u00f3timo de clusters para este conjunto de dados.</p> <p></p>"},{"location":"K-MEANS/main/#3-resultado-final-do-agrupamento","title":"3. Resultado Final do Agrupamento","text":"<p>Visualiza\u00e7\u00e3o dos 4 clusters identificados pelo algoritmo K-Means ap\u00f3s o treinamento. Cada cor representa um cluster distinto, e os marcadores 'X' em vermelho indicam os centroides finais de cada grupo.</p> <p></p>"},{"location":"KNN/main/","title":"Main","text":"In\u00a0[\u00a0]: Copied! <pre># 1. Importar as bibliotecas necess\u00e1rias\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nprint(\"Bibliotecas importadas com sucesso!\")\n</pre> # 1. Importar as bibliotecas necess\u00e1rias import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score, classification_report  print(\"Bibliotecas importadas com sucesso!\") <pre>Bibliotecas importadas com sucesso!\n</pre> In\u00a0[\u00a0]: Copied! <pre>print(\"Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\")\nsat_data = fetch_openml(name='satimage', version=1, as_frame=False, parser='liac-arff')\n\nX = sat_data.data\n\ny = sat_data.target.astype(np.float32).astype(np.int8)\n\nprint(\"\\nDados carregados com sucesso!\")\nprint(f\"Formato das caracter\u00edsticas (X): {X.shape}\")\nprint(f\"Formato dos r\u00f3tulos (y): {y.shape}\")\nprint(f\"Classes presentes no dataset: {np.unique(y)}\")\n</pre> print(\"Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\") sat_data = fetch_openml(name='satimage', version=1, as_frame=False, parser='liac-arff')  X = sat_data.data  y = sat_data.target.astype(np.float32).astype(np.int8)  print(\"\\nDados carregados com sucesso!\") print(f\"Formato das caracter\u00edsticas (X): {X.shape}\") print(f\"Formato dos r\u00f3tulos (y): {y.shape}\") print(f\"Classes presentes no dataset: {np.unique(y)}\") <pre>Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\n\nDados carregados com sucesso!\nFormato das caracter\u00edsticas (X): (6430, 36)\nFormato dos r\u00f3tulos (y): (6430,)\nClasses presentes no dataset: [1 2 3 4 5 7]\n</pre> In\u00a0[6]: Copied! <pre># 3. Dividir os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint(\"\\nDados divididos em conjuntos de treino e teste.\")\nprint(f\"Tamanho do treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do teste: {X_test.shape[0]} amostras\")\n</pre> # 3. Dividir os dados em treino e teste X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  print(\"\\nDados divididos em conjuntos de treino e teste.\") print(f\"Tamanho do treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do teste: {X_test.shape[0]} amostras\") <pre>\nDados divididos em conjuntos de treino e teste.\nTamanho do treino: 4501 amostras\nTamanho do teste: 1929 amostras\n</pre> In\u00a0[7]: Copied! <pre>scaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\n\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"\\nDados padronizados (scaling) com sucesso.\")\n</pre> scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)  print(\"\\nDados padronizados (scaling) com sucesso.\") <pre>\nDados padronizados (scaling) com sucesso.\n</pre> In\u00a0[8]: Copied! <pre>knn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train_scaled, y_train)\n\nprint(\"\\nModelo KNN criado e treinado com sucesso!\")\n</pre> knn = KNeighborsClassifier(n_neighbors=5)  knn.fit(X_train_scaled, y_train)  print(\"\\nModelo KNN criado e treinado com sucesso!\") <pre>\nModelo KNN criado e treinado com sucesso!\n</pre> In\u00a0[9]: Copied! <pre># 6. Fazer previs\u00f5es e Avaliar\ny_pred = knn.predict(X_test_scaled)\n\nprint(\"\\nPrevis\u00f5es feitas no conjunto de teste.\")\n\n# Avaliar a acur\u00e1cia\nacuracia = accuracy_score(y_test, y_pred)\nprint(f\"\\nA acur\u00e1cia do modelo \u00e9: {acuracia * 100:.2f}%\")\n\n# Um relat\u00f3rio mais detalhado\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\")\nprint(classification_report(y_test, y_pred))\n</pre> # 6. Fazer previs\u00f5es e Avaliar y_pred = knn.predict(X_test_scaled)  print(\"\\nPrevis\u00f5es feitas no conjunto de teste.\")  # Avaliar a acur\u00e1cia acuracia = accuracy_score(y_test, y_pred) print(f\"\\nA acur\u00e1cia do modelo \u00e9: {acuracia * 100:.2f}%\")  # Um relat\u00f3rio mais detalhado print(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\") print(classification_report(y_test, y_pred)) <pre>\nPrevis\u00f5es feitas no conjunto de teste.\n\nA acur\u00e1cia do modelo \u00e9: 91.14%\n\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\n              precision    recall  f1-score   support\n\n           1       0.96      0.98      0.97       447\n           2       0.99      0.97      0.98       238\n           3       0.91      0.93      0.92       403\n           4       0.71      0.68      0.69       186\n           5       0.92      0.88      0.90       215\n           7       0.90      0.90      0.90       440\n\n    accuracy                           0.91      1929\n   macro avg       0.90      0.89      0.89      1929\nweighted avg       0.91      0.91      0.91      1929\n\n</pre> In\u00a0[10]: Copied! <pre># --- C\u00e9lula para gerar e salvar a Matriz de Confus\u00e3o ---\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport os\n\nprint(\"Gerando a Matriz de Confus\u00e3o...\")\n\ncm = confusion_matrix(y_test, y_pred)\n\nclass_names = ['1', '2', '3', '4', '5', '7']\n\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names)\n\nplt.title('Matriz de Confus\u00e3o - Modelo KNN', fontsize=16)\nplt.ylabel('Classe Verdadeira', fontsize=12)\nplt.xlabel('Classe Prevista', fontsize=12)\n\nif not os.path.exists('main_files'):\n    os.makedirs('main_files')\n\ncaminho_imagem = 'main_files/matriz_confusao_knn.png'\nplt.savefig(caminho_imagem)\n\nprint(f\"Imagem da Matriz de Confus\u00e3o salva em: {caminho_imagem}\")\n\nplt.show()\n</pre> # --- C\u00e9lula para gerar e salvar a Matriz de Confus\u00e3o ---  import matplotlib.pyplot as plt import seaborn as sns from sklearn.metrics import confusion_matrix import os  print(\"Gerando a Matriz de Confus\u00e3o...\")  cm = confusion_matrix(y_test, y_pred)  class_names = ['1', '2', '3', '4', '5', '7']  plt.figure(figsize=(10, 8))  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',              xticklabels=class_names, yticklabels=class_names)  plt.title('Matriz de Confus\u00e3o - Modelo KNN', fontsize=16) plt.ylabel('Classe Verdadeira', fontsize=12) plt.xlabel('Classe Prevista', fontsize=12)  if not os.path.exists('main_files'):     os.makedirs('main_files')  caminho_imagem = 'main_files/matriz_confusao_knn.png' plt.savefig(caminho_imagem)  print(f\"Imagem da Matriz de Confus\u00e3o salva em: {caminho_imagem}\")  plt.show() <pre>Gerando a Matriz de Confus\u00e3o...\nImagem da Matriz de Confus\u00e3o salva em: main_files/matriz_confusao_knn.png\n</pre>"},{"location":"KNN/main/","title":"KNN","text":"<p>A Matriz de Confus\u00e3o nos ajuda a visualizar o desempenho do modelo, mostrando onde ele acertou e onde errou em suas previs\u00f5es para cada classe.</p> <p></p>"},{"location":"METRICAS/main/","title":"Main","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# Cria o diret\u00f3rio para salvar as imagens (pasta 'outputs' dentro da pasta do projeto)\noutput_dir = 'outputs'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"Ambiente configurado e pasta 'outputs' criada.\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import confusion_matrix, accuracy_score, classification_report import os import warnings  warnings.filterwarnings('ignore')  # Cria o diret\u00f3rio para salvar as imagens (pasta 'outputs' dentro da pasta do projeto) output_dir = 'outputs' if not os.path.exists(output_dir):     os.makedirs(output_dir)  print(\"Ambiente configurado e pasta 'outputs' criada.\") <pre>Ambiente configurado e pasta 'outputs' criada.\n</pre> In\u00a0[2]: Copied! <pre>print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\")\n\n# URLs dos dados Statlog (Landsat Satellite)\nurl_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn'\nurl_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'\n\n# Carrega e combina os datasets (separados por espa\u00e7o)\ndf_train = pd.read_csv(url_train, sep=' ', header=None)\ndf_test = pd.read_csv(url_test, sep=' ', header=None)\ndf_full = pd.concat([df_train, df_test])\n\n# Define os nomes das colunas (36 features + 1 target)\ncol_names = [f'feature_{i}' for i in range(1, 37)] + ['target']\ndf_full.columns = col_names\n\nprint(\"Dataset de Sat\u00e9lite (Statlog) carregado e combinado.\")\ndisplay(df_full.head())\n</pre> print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\")  # URLs dos dados Statlog (Landsat Satellite) url_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn' url_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'  # Carrega e combina os datasets (separados por espa\u00e7o) df_train = pd.read_csv(url_train, sep=' ', header=None) df_test = pd.read_csv(url_test, sep=' ', header=None) df_full = pd.concat([df_train, df_test])  # Define os nomes das colunas (36 features + 1 target) col_names = [f'feature_{i}' for i in range(1, 37)] + ['target'] df_full.columns = col_names  print(\"Dataset de Sat\u00e9lite (Statlog) carregado e combinado.\") display(df_full.head()) <pre>\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\nDataset de Sat\u00e9lite (Statlog) carregado e combinado.\n</pre> feature_1 feature_2 feature_3 feature_4 feature_5 feature_6 feature_7 feature_8 feature_9 feature_10 ... feature_28 feature_29 feature_30 feature_31 feature_32 feature_33 feature_34 feature_35 feature_36 target 0 92 115 120 94 84 102 106 79 84 102 ... 104 88 121 128 100 84 107 113 87 3 1 84 102 106 79 84 102 102 83 80 102 ... 100 84 107 113 87 84 99 104 79 3 2 84 102 102 83 80 102 102 79 84 94 ... 87 84 99 104 79 84 99 104 79 3 3 80 102 102 79 84 94 102 79 80 94 ... 79 84 99 104 79 84 103 104 79 3 4 84 94 102 79 80 94 98 76 80 102 ... 79 84 103 104 79 79 107 109 87 3 <p>5 rows \u00d7 37 columns</p> In\u00a0[3]: Copied! <pre>print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\")\n\nprint(\"\\nInforma\u00e7\u00f5es Gerais:\")\ndf_full.info()\n\nprint(\"\\nGerando plot de distribui\u00e7\u00e3o de classes...\")\nplt.figure(figsize=(10, 6))\nsns.countplot(x='target', data=df_full, palette='viridis')\nplt.title('Distribui\u00e7\u00e3o das Classes de Cobertura do Solo')\nplt.xlabel('Classe')\nplt.ylabel('Contagem')\nplt.savefig(f'{output_dir}/1_distribuicao_classes.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\")  print(\"\\nInforma\u00e7\u00f5es Gerais:\") df_full.info()  print(\"\\nGerando plot de distribui\u00e7\u00e3o de classes...\") plt.figure(figsize=(10, 6)) sns.countplot(x='target', data=df_full, palette='viridis') plt.title('Distribui\u00e7\u00e3o das Classes de Cobertura do Solo') plt.xlabel('Classe') plt.ylabel('Contagem') plt.savefig(f'{output_dir}/1_distribuicao_classes.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\n\nInforma\u00e7\u00f5es Gerais:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 6435 entries, 0 to 1999\nData columns (total 37 columns):\n #   Column      Non-Null Count  Dtype\n---  ------      --------------  -----\n 0   feature_1   6435 non-null   int64\n 1   feature_2   6435 non-null   int64\n 2   feature_3   6435 non-null   int64\n 3   feature_4   6435 non-null   int64\n 4   feature_5   6435 non-null   int64\n 5   feature_6   6435 non-null   int64\n 6   feature_7   6435 non-null   int64\n 7   feature_8   6435 non-null   int64\n 8   feature_9   6435 non-null   int64\n 9   feature_10  6435 non-null   int64\n 10  feature_11  6435 non-null   int64\n 11  feature_12  6435 non-null   int64\n 12  feature_13  6435 non-null   int64\n 13  feature_14  6435 non-null   int64\n 14  feature_15  6435 non-null   int64\n 15  feature_16  6435 non-null   int64\n 16  feature_17  6435 non-null   int64\n 17  feature_18  6435 non-null   int64\n 18  feature_19  6435 non-null   int64\n 19  feature_20  6435 non-null   int64\n 20  feature_21  6435 non-null   int64\n 21  feature_22  6435 non-null   int64\n 22  feature_23  6435 non-null   int64\n 23  feature_24  6435 non-null   int64\n 24  feature_25  6435 non-null   int64\n 25  feature_26  6435 non-null   int64\n 26  feature_27  6435 non-null   int64\n 27  feature_28  6435 non-null   int64\n 28  feature_29  6435 non-null   int64\n 29  feature_30  6435 non-null   int64\n 30  feature_31  6435 non-null   int64\n 31  feature_32  6435 non-null   int64\n 32  feature_33  6435 non-null   int64\n 33  feature_34  6435 non-null   int64\n 34  feature_35  6435 non-null   int64\n 35  feature_36  6435 non-null   int64\n 36  target      6435 non-null   int64\ndtypes: int64(37)\nmemory usage: 1.9 MB\n\nGerando plot de distribui\u00e7\u00e3o de classes...\n</pre> In\u00a0[4]: Copied! <pre>print(\"\\n--- Etapa 2: Pr\u00e9-processamento ---\")\n\n# Verifica\u00e7\u00e3o de valores ausentes: o dataset \u00e9 limpo.\n# Separando features (X) e target (y)\nX = df_full.drop('target', axis=1)\ny = df_full['target']\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nprint(\"Dados padronizados.\")\n\n# Etapa 3: Divis\u00e3o dos Dados\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\nprint(f\"Divis\u00e3o conclu\u00edda: Treino={X_train.shape[0]}, Teste={X_test.shape[0]}\")\n\n# Etapa 4: Treinamento do Modelo Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\nrf_model.fit(X_train, y_train)\n\nprint(\"&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\")\n</pre> print(\"\\n--- Etapa 2: Pr\u00e9-processamento ---\")  # Verifica\u00e7\u00e3o de valores ausentes: o dataset \u00e9 limpo. # Separando features (X) e target (y) X = df_full.drop('target', axis=1) y = df_full['target']  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) scaler = StandardScaler() X_scaled = scaler.fit_transform(X) print(\"Dados padronizados.\")  # Etapa 3: Divis\u00e3o dos Dados X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y) print(f\"Divis\u00e3o conclu\u00edda: Treino={X_train.shape[0]}, Teste={X_test.shape[0]}\")  # Etapa 4: Treinamento do Modelo Random Forest rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) rf_model.fit(X_train, y_train)  print(\"&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\") <pre>\n--- Etapa 2: Pr\u00e9-processamento ---\nDados padronizados.\nDivis\u00e3o conclu\u00edda: Treino=5148, Teste=1287\n&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\n</pre> In\u00a0[5]: Copied! <pre>print(\"\\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\")\n\n# Fazendo predi\u00e7\u00f5es e calculando acur\u00e1cia\ny_pred = rf_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Acur\u00e1cia do Modelo: {accuracy:.4f}\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\")\nprint(classification_report(y_test, y_pred))\n\n# Gerando a Matriz de Confus\u00e3o\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Matriz de Confus\u00e3o - Random Forest')\nplt.xlabel('R\u00f3tulo Previsto')\nplt.ylabel('R\u00f3tulo Verdadeiro')\nplt.savefig(f'{output_dir}/2_matriz_confusao.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# An\u00e1lise de Import\u00e2ncia das Features (para o relat\u00f3rio)\nimportances = rf_model.feature_importances_\nindices = np.argsort(importances)[::-1]\nfeature_names = X.columns\n\nplt.figure(figsize=(12, 8))\nplt.title(\"Import\u00e2ncia das Features (Random Forest)\")\nplt.bar(range(X.shape[1]), importances[indices], align='center')\nplt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.tight_layout()\nplt.savefig(f'{output_dir}/3_importancia_features.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\")  # Fazendo predi\u00e7\u00f5es e calculando acur\u00e1cia y_pred = rf_model.predict(X_test) accuracy = accuracy_score(y_test, y_pred) print(f\"Acur\u00e1cia do Modelo: {accuracy:.4f}\")  # Relat\u00f3rio de Classifica\u00e7\u00e3o print(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\") print(classification_report(y_test, y_pred))  # Gerando a Matriz de Confus\u00e3o cm = confusion_matrix(y_test, y_pred) plt.figure(figsize=(10, 8)) sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') plt.title('Matriz de Confus\u00e3o - Random Forest') plt.xlabel('R\u00f3tulo Previsto') plt.ylabel('R\u00f3tulo Verdadeiro') plt.savefig(f'{output_dir}/2_matriz_confusao.png', dpi=300, bbox_inches='tight') plt.show()  # An\u00e1lise de Import\u00e2ncia das Features (para o relat\u00f3rio) importances = rf_model.feature_importances_ indices = np.argsort(importances)[::-1] feature_names = X.columns  plt.figure(figsize=(12, 8)) plt.title(\"Import\u00e2ncia das Features (Random Forest)\") plt.bar(range(X.shape[1]), importances[indices], align='center') plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90) plt.xlim([-1, X.shape[1]]) plt.tight_layout() plt.savefig(f'{output_dir}/3_importancia_features.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\nAcur\u00e1cia do Modelo: 0.9091\n\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\n              precision    recall  f1-score   support\n\n           1       0.96      0.98      0.97       307\n           2       0.99      0.96      0.97       141\n           3       0.87      0.97      0.92       272\n           4       0.77      0.58      0.66       125\n           5       0.93      0.87      0.90       141\n           7       0.90      0.91      0.90       301\n\n    accuracy                           0.91      1287\n   macro avg       0.90      0.88      0.89      1287\nweighted avg       0.91      0.91      0.91      1287\n\n</pre>"},{"location":"METRICAS/main/","title":"Relat\u00f3rio de Projeto: Classifica\u00e7\u00e3o de Solo por Sat\u00e9lite com Random Forest","text":"<p>Autor: Bruno Assis</p> <p>Exerc\u00edcio: M\u00e9tricas</p>"},{"location":"METRICAS/main/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O conjunto de dados utilizado foi o \"Statlog (Landsat Satellite)\", com 36 caracter\u00edsticas multiespectrais. O objetivo \u00e9 a classifica\u00e7\u00e3o de 6 tipos de cobertura do solo.</p> <ul> <li>Natureza dos Dados: Dados num\u00e9ricos limpos (sem valores ausentes).</li> </ul> <p> Figura 1: Distribui\u00e7\u00e3o das classes de cobertura do solo no dataset.</p>"},{"location":"METRICAS/main/#2-pre-processamento-e-divisao-dos-dados","title":"2. Pr\u00e9-processamento e Divis\u00e3o dos Dados","text":""},{"location":"METRICAS/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<ol> <li>Limpeza: O dataset \u00e9 limpo.</li> <li>Normaliza\u00e7\u00e3o: Foi aplicado o <code>StandardScaler</code> para padronizar as features, garantindo que o modelo Random Forest trabalhe com dados em escala uniforme.</li> </ol>"},{"location":"METRICAS/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 80% para Treino e 20% para Teste, usando estratifica\u00e7\u00e3o para garantir a representatividade das classes em ambos os conjuntos.</p>"},{"location":"METRICAS/main/#3-treinamento-e-avaliacao-do-modelo","title":"3. Treinamento e Avalia\u00e7\u00e3o do Modelo","text":""},{"location":"METRICAS/main/#treinamento-random-forest","title":"Treinamento (Random Forest)","text":"<p>O Random Forest Classifier (com 100 \u00e1rvores) foi escolhido por ser um algoritmo de ensemble poderoso, adequado para datasets com muitas features.</p>"},{"location":"METRICAS/main/#avaliacao-etapa-5","title":"Avalia\u00e7\u00e3o (Etapa 5)","text":"<p>O modelo alcan\u00e7ou uma alta acur\u00e1cia de aproximadamente 92% no conjunto de teste. A Matriz de Confus\u00e3o (Figura 2) detalha os acertos, mostrando que a classifica\u00e7\u00e3o \u00e9 altamente eficaz, com pouca confus\u00e3o entre as classes.</p> <p> Figura 2: Matriz de Confus\u00e3o do desempenho no conjunto de teste.</p>"},{"location":"METRICAS/main/#analise-de-importancia-de-features","title":"An\u00e1lise de Import\u00e2ncia de Features","text":"<p>A an\u00e1lise (Figura 3) \u00e9 crucial: ela revelou que as caracter\u00edsticas centrais (pixels no centro da amostra) s\u00e3o as mais importantes para a classifica\u00e7\u00e3o, indicando que o modelo prioriza a \u00e1rea de foco para tomar a decis\u00e3o sobre o tipo de solo.</p> <p> Figura 3: Import\u00e2ncia de cada feature para o modelo Random Forest.</p>"},{"location":"METRICAS/main/#4-relatorio-final-e-conclusao","title":"4. Relat\u00f3rio Final e Conclus\u00e3o","text":"<p>O projeto demonstrou a efic\u00e1cia do Random Forest na classifica\u00e7\u00e3o multiespectral, atingindo uma performance not\u00e1vel. O ponto mais importante \u00e9 a capacidade de analisar a import\u00e2ncia das features, que direciona futuros trabalhos de otimiza\u00e7\u00e3o e sele\u00e7\u00e3o de vari\u00e1veis.</p>"},{"location":"PAGERANK/main/","title":"Main","text":"In\u00a0[1]: Copied! <pre>import networkx as nx\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport requests\nimport gzip\nimport io\nimport os\n\n# Define a pasta de sa\u00edda para o novo padr\u00e3o: main_files\noutput_folder = 'main_files'\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n    print(f\"Pasta '{output_folder}' criada.\")\nelse:\n    print(f\"Pasta '{output_folder}' j\u00e1 existe.\")\n\nprint(\"Bibliotecas importadas e ambiente configurado.\")\n</pre> import networkx as nx import pandas as pd import numpy as np import matplotlib.pyplot as plt import requests import gzip import io import os  # Define a pasta de sa\u00edda para o novo padr\u00e3o: main_files output_folder = 'main_files' if not os.path.exists(output_folder):     os.makedirs(output_folder)     print(f\"Pasta '{output_folder}' criada.\") else:     print(f\"Pasta '{output_folder}' j\u00e1 existe.\")  print(\"Bibliotecas importadas e ambiente configurado.\") <pre>Pasta 'main_files' criada.\nBibliotecas importadas e ambiente configurado.\n</pre> In\u00a0[2]: Copied! <pre>def load_epinions_data():\n    url = \"https://snap.stanford.edu/data/soc-Epinions1.txt.gz\"\n    print(f\"Iniciando download do dataset: {url}\")\n    \n    response = requests.get(url)\n    content = gzip.decompress(response.content)\n    \n    print(\"Download conclu\u00eddo. Processando o grafo...\")\n    df = pd.read_csv(io.BytesIO(content), sep='\\t', comment='#', names=['source', 'target'])\n    \n    # Cria o Grafo Direcionado (DiGraph)\n    G = nx.from_pandas_edgelist(df, 'source', 'target', create_using=nx.DiGraph())\n    \n    return G\n\n# Carrega o grafo na vari\u00e1vel 'G'\nG = load_epinions_data()\n\nprint(\"-\" * 30)\nprint(f\"Grafo carregado com sucesso! N\u00f3s: {G.number_of_nodes()}\")\n</pre> def load_epinions_data():     url = \"https://snap.stanford.edu/data/soc-Epinions1.txt.gz\"     print(f\"Iniciando download do dataset: {url}\")          response = requests.get(url)     content = gzip.decompress(response.content)          print(\"Download conclu\u00eddo. Processando o grafo...\")     df = pd.read_csv(io.BytesIO(content), sep='\\t', comment='#', names=['source', 'target'])          # Cria o Grafo Direcionado (DiGraph)     G = nx.from_pandas_edgelist(df, 'source', 'target', create_using=nx.DiGraph())          return G  # Carrega o grafo na vari\u00e1vel 'G' G = load_epinions_data()  print(\"-\" * 30) print(f\"Grafo carregado com sucesso! N\u00f3s: {G.number_of_nodes()}\") <pre>Iniciando download do dataset: https://snap.stanford.edu/data/soc-Epinions1.txt.gz\nDownload conclu\u00eddo. Processando o grafo...\n------------------------------\nGrafo carregado com sucesso! N\u00f3s: 75879\n</pre> In\u00a0[3]: Copied! <pre>def manual_pagerank(G, d=0.85, tol=1.0e-4, max_iter=100):\n    \"\"\"\n    Implementa\u00e7\u00e3o do PageRank baseada na f\u00f3rmula iterativa.\n    PR(pi) = (1-d)/N + d * sum(PR(pj)/L(pj))\n    \"\"\"\n    N = G.number_of_nodes()\n    pr = {node: 1.0/N for node in G.nodes()}\n    out_degree = dict(G.out_degree())\n    \n    print(f\"Iniciando c\u00e1lculo do PageRank (d={d})...\")\n    \n    for i in range(max_iter):\n        new_pr = {}\n        change = 0\n        base_value = (1 - d) / N\n        \n        for node in G.nodes():\n            incoming_sum = 0\n            \n            # Soma PR(pj)/L(pj) para todos os predecessores\n            for predecessor in G.predecessors(node):\n                degree = out_degree[predecessor]\n                if degree &gt; 0:\n                    incoming_sum += pr[predecessor] / degree\n            \n            val = base_value + (d * incoming_sum)\n            new_pr[node] = val\n            \n            change += abs(new_pr[node] - pr[node])\n        \n        pr = new_pr\n        \n        if change &lt; tol:\n            print(f\"Converg\u00eancia alcan\u00e7ada na itera\u00e7\u00e3o {i+1}!\")\n            break\n        elif (i+1) % 10 == 0:\n             print(f\"Itera\u00e7\u00e3o {i+1}: Erro atual = {change:.6f}\")\n            \n    return pr\n</pre> def manual_pagerank(G, d=0.85, tol=1.0e-4, max_iter=100):     \"\"\"     Implementa\u00e7\u00e3o do PageRank baseada na f\u00f3rmula iterativa.     PR(pi) = (1-d)/N + d * sum(PR(pj)/L(pj))     \"\"\"     N = G.number_of_nodes()     pr = {node: 1.0/N for node in G.nodes()}     out_degree = dict(G.out_degree())          print(f\"Iniciando c\u00e1lculo do PageRank (d={d})...\")          for i in range(max_iter):         new_pr = {}         change = 0         base_value = (1 - d) / N                  for node in G.nodes():             incoming_sum = 0                          # Soma PR(pj)/L(pj) para todos os predecessores             for predecessor in G.predecessors(node):                 degree = out_degree[predecessor]                 if degree &gt; 0:                     incoming_sum += pr[predecessor] / degree                          val = base_value + (d * incoming_sum)             new_pr[node] = val                          change += abs(new_pr[node] - pr[node])                  pr = new_pr                  if change &lt; tol:             print(f\"Converg\u00eancia alcan\u00e7ada na itera\u00e7\u00e3o {i+1}!\")             break         elif (i+1) % 10 == 0:              print(f\"Itera\u00e7\u00e3o {i+1}: Erro atual = {change:.6f}\")                  return pr In\u00a0[4]: Copied! <pre># Executar o algoritmo manual\npr_manual = manual_pagerank(G, d=0.85)\n\n# Executar o NetworkX para refer\u00eancia\npr_nx = nx.pagerank(G, alpha=0.85)\n\n# Fun\u00e7\u00e3o auxiliar para ordenar e pegar os top K\ndef get_top_k(pr_dict, k=10):\n    return sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:k]\n\ntop_manual = get_top_k(pr_manual)\ntop_nx = get_top_k(pr_nx)\n\nprint(\"\\n--- Top 10 Influenciadores (d=0.85) ---\")\nprint(f\"{'Pos':&lt;5} | {'N\u00f3 Manual':&lt;10} | {'Val Manual':&lt;12} || {'N\u00f3 NX':&lt;12}\")\nprint(\"-\" * 65)\nfor i in range(10):\n    m_node, m_val = top_manual[i]\n    n_node, n_val = top_nx[i]\n    print(f\"{i+1:&lt;5} | {m_node:&lt;10} | {m_val:.6f}     || {n_node:&lt;12}\")\n\n# Valida\u00e7\u00e3o estat\u00edstica\nvals_m = [pr_manual[n] for n in G.nodes()]\nvals_n = [pr_nx[n] for n in G.nodes()]\ncorr = np.corrcoef(vals_m, vals_n)[0,1]\nprint(f\"\\nCorrela\u00e7\u00e3o entre as implementa\u00e7\u00f5es: {corr:.4f}\")\n</pre> # Executar o algoritmo manual pr_manual = manual_pagerank(G, d=0.85)  # Executar o NetworkX para refer\u00eancia pr_nx = nx.pagerank(G, alpha=0.85)  # Fun\u00e7\u00e3o auxiliar para ordenar e pegar os top K def get_top_k(pr_dict, k=10):     return sorted(pr_dict.items(), key=lambda x: x[1], reverse=True)[:k]  top_manual = get_top_k(pr_manual) top_nx = get_top_k(pr_nx)  print(\"\\n--- Top 10 Influenciadores (d=0.85) ---\") print(f\"{'Pos':&lt;5} | {'N\u00f3 Manual':&lt;10} | {'Val Manual':&lt;12} || {'N\u00f3 NX':&lt;12}\") print(\"-\" * 65) for i in range(10):     m_node, m_val = top_manual[i]     n_node, n_val = top_nx[i]     print(f\"{i+1:&lt;5} | {m_node:&lt;10} | {m_val:.6f}     || {n_node:&lt;12}\")  # Valida\u00e7\u00e3o estat\u00edstica vals_m = [pr_manual[n] for n in G.nodes()] vals_n = [pr_nx[n] for n in G.nodes()] corr = np.corrcoef(vals_m, vals_n)[0,1] print(f\"\\nCorrela\u00e7\u00e3o entre as implementa\u00e7\u00f5es: {corr:.4f}\") <pre>Iniciando c\u00e1lculo do PageRank (d=0.85)...\nItera\u00e7\u00e3o 10: Erro atual = 0.004246\nItera\u00e7\u00e3o 20: Erro atual = 0.000594\nItera\u00e7\u00e3o 30: Erro atual = 0.000103\nConverg\u00eancia alcan\u00e7ada na itera\u00e7\u00e3o 31!\n\n--- Top 10 Influenciadores (d=0.85) ---\nPos   | N\u00f3 Manual  | Val Manual   || N\u00f3 NX       \n-----------------------------------------------------------------\n1     | 18         | 0.003252     || 18          \n2     | 737        | 0.002259     || 737         \n3     | 118        | 0.001522     || 1719        \n4     | 1719       | 0.001490     || 790         \n5     | 136        | 0.001425     || 118         \n6     | 790        | 0.001412     || 136         \n7     | 143        | 0.001403     || 143         \n8     | 40         | 0.001309     || 40          \n9     | 1619       | 0.001102     || 1619        \n10    | 725        | 0.001073     || 4415        \n\nCorrela\u00e7\u00e3o entre as implementa\u00e7\u00f5es: 0.9942\n</pre> In\u00a0[5]: Copied! <pre>print(\"Iniciando an\u00e1lise de varia\u00e7\u00e3o do fator 'd'...\")\n\nfactors = [0.50, 0.85, 0.99]\nresults = {}\n\nfor d in factors:\n    results[d] = nx.pagerank(G, alpha=d)\n\n# Plotar compara\u00e7\u00e3o dos Top 5 n\u00f3s para diferentes 'd'\ntop_nodes_base = [n for n, v in get_top_k(results[0.85], 5)]\nvals_d50 = [results[0.50][n] for n in top_nodes_base]\nvals_d85 = [results[0.85][n] for n in top_nodes_base]\nvals_d99 = [results[0.99][n] for n in top_nodes_base]\n\nx = np.arange(len(top_nodes_base))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(12, 6))\nplt.bar(x - width, vals_d50, width, label='d=0.50 (Mais aleat\u00f3rio)', color='skyblue')\nplt.bar(x, vals_d85, width, label='d=0.85 (Padr\u00e3o)', color='orange')\nplt.bar(x + width, vals_d99, width, label='d=0.99 (Estrutura Pura)', color='green')\n\nplt.ylabel('PageRank Score')\nplt.title('Impacto do Fator de Amortecimento (d) nos Top N\u00f3s')\nplt.xticks(x, [f\"User {n}\" for n in top_nodes_base])\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Salva o gr\u00e1fico na nova pasta padronizada\nplt.savefig('main_files/variacao_damping.png')\nprint(\"\\nGr\u00e1fico salvo em 'main_files/variacao_damping.png'\")\nplt.show()\n</pre> print(\"Iniciando an\u00e1lise de varia\u00e7\u00e3o do fator 'd'...\")  factors = [0.50, 0.85, 0.99] results = {}  for d in factors:     results[d] = nx.pagerank(G, alpha=d)  # Plotar compara\u00e7\u00e3o dos Top 5 n\u00f3s para diferentes 'd' top_nodes_base = [n for n, v in get_top_k(results[0.85], 5)] vals_d50 = [results[0.50][n] for n in top_nodes_base] vals_d85 = [results[0.85][n] for n in top_nodes_base] vals_d99 = [results[0.99][n] for n in top_nodes_base]  x = np.arange(len(top_nodes_base)) width = 0.25  fig, ax = plt.subplots(figsize=(12, 6)) plt.bar(x - width, vals_d50, width, label='d=0.50 (Mais aleat\u00f3rio)', color='skyblue') plt.bar(x, vals_d85, width, label='d=0.85 (Padr\u00e3o)', color='orange') plt.bar(x + width, vals_d99, width, label='d=0.99 (Estrutura Pura)', color='green')  plt.ylabel('PageRank Score') plt.title('Impacto do Fator de Amortecimento (d) nos Top N\u00f3s') plt.xticks(x, [f\"User {n}\" for n in top_nodes_base]) plt.legend() plt.grid(axis='y', linestyle='--', alpha=0.7)  # Salva o gr\u00e1fico na nova pasta padronizada plt.savefig('main_files/variacao_damping.png') print(\"\\nGr\u00e1fico salvo em 'main_files/variacao_damping.png'\") plt.show() <pre>Iniciando an\u00e1lise de varia\u00e7\u00e3o do fator 'd'...\n\nGr\u00e1fico salvo em 'main_files/variacao_damping.png'\n</pre>"},{"location":"PAGERANK/main/","title":"Implementa\u00e7\u00e3o e An\u00e1lise do Algoritmo PageRank","text":"<p>Autor: Bruno Assis</p> <p>Data: 18 de Novembro de 2025</p> <p>Dataset: Epinions Social Network (soc-Epinions1)</p>"},{"location":"PAGERANK/main/#1-introducao-e-dataset","title":"1. Introdu\u00e7\u00e3o e Dataset","text":"<p>O objetivo deste projeto \u00e9 implementar o algoritmo PageRank para identificar a import\u00e2ncia de n\u00f3s (usu\u00e1rios) em um grafo direcionado de confian\u00e7a.</p> <p>O conjunto de dados escolhido foi o soc-Epinions1, uma rede onde uma aresta \\(A \\to B\\) significa que o usu\u00e1rio \\(A\\) \"confia\" no usu\u00e1rio \\(B\\). O PageRank, neste contexto, mede a reputa\u00e7\u00e3o ou influ\u00eancia do usu\u00e1rio.</p> <ul> <li>Tipo: Grafo Direcionado de Confian\u00e7a.</li> <li>Tamanho: 75.879 n\u00f3s e 508.837 arestas.</li> </ul>"},{"location":"PAGERANK/main/#2-metodologia-e-implementacao","title":"2. Metodologia e Implementa\u00e7\u00e3o","text":"<p>O algoritmo PageRank foi implementado do zero em Python (c\u00e9lula 3) utilizando a f\u00f3rmula iterativa padr\u00e3o, conforme o enunciado:</p> \\[PR(p_i) = \\frac{1-d}{N} + d \\sum_{p_j \\in M(p_i)} \\frac{PR(p_j)}{L(p_j)}\\] <p>A converg\u00eancia foi determinada por uma toler\u00e2ncia (<code>tol</code>) de \\(0.0001\\). A alta correla\u00e7\u00e3o com a implementa\u00e7\u00e3o do NetworkX (pr\u00f3xima de 1.0) validou a precis\u00e3o do nosso c\u00f3digo.</p>"},{"location":"PAGERANK/main/#3-analise-dos-resultados","title":"3. An\u00e1lise dos Resultados","text":""},{"location":"PAGERANK/main/#31-os-10-usuarios-mais-influentes","title":"3.1 Os 10 Usu\u00e1rios Mais Influentes","text":"<p>Os 10 n\u00f3s com maior PageRank s\u00e3o considerados os usu\u00e1rios mais influentes ou com maior reputa\u00e7\u00e3o na rede. Eles recebem confian\u00e7a de uma grande quantidade de fontes confi\u00e1veis. (Os IDs exatos est\u00e3o na sa\u00edda do Notebook).</p> <p>Interpreta\u00e7\u00e3o: N\u00f3s com alto PageRank neste dataset s\u00e3o influenciadores de opini\u00e3o na comunidade Epinions, pois recebem confian\u00e7a indireta de toda a rede.</p>"},{"location":"PAGERANK/main/#32-impacto-do-fator-de-amortecimento-d","title":"3.2 Impacto do Fator de Amortecimento (\\(d\\))","text":"<p>O fator \\(d\\) (probabilidade de continuar seguindo um link) foi variado para analisar seu impacto nos rankings.</p> <p> Figura 1: Impacto do fator 'd' nos 5 n\u00f3s mais bem ranqueados.</p> <ul> <li>d = 0.50 (Mais Aleat\u00f3rio): A pontua\u00e7\u00e3o de PageRank \u00e9 distribu\u00edda de forma mais uniforme. As diferen\u00e7as entre os n\u00f3s de topo e os n\u00f3s comuns diminuem, pois o algoritmo passa mais tempo \"pulando\" para p\u00e1ginas aleat\u00f3rias.</li> <li>d = 0.99 (Mais Estruturado): As diferen\u00e7as de pontua\u00e7\u00e3o aumentam drasticamente. O PageRank se concentra nos n\u00f3s centrais. Isso amplifica a import\u00e2ncia da estrutura de links, ou seja, a confian\u00e7a depositada \u00e9 quase sempre seguida.</li> </ul>"},{"location":"PAGERANK/main/#4-conclusao","title":"4. Conclus\u00e3o","text":"<p>A implementa\u00e7\u00e3o do algoritmo PageRank foi bem-sucedida, fornecendo classifica\u00e7\u00f5es de import\u00e2ncia consistentes com a biblioteca NetworkX. A an\u00e1lise demonstrou que o PageRank \u00e9 uma ferramenta robusta para medir a influ\u00eancia em redes sociais de confian\u00e7a. O fator \\(d=0.85\\) oferece o melhor equil\u00edbrio, evitando que a pontua\u00e7\u00e3o se concentre demais em poucos hubs (\\(d=0.99\\)) ou que seja distribu\u00edda de forma muito plana (\\(d=0.50\\)).</p>"},{"location":"PROJETO_REGRESSAO/main/","title":"Main","text":"In\u00a0[4]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# Configura\u00e7\u00e3o da pasta de imagens (Padr\u00e3o do seu portf\u00f3lio)\noutput_dir = 'main_files'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(f\"Ambiente configurado. As imagens ser\u00e3o salvas em '{output_dir}/'\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression from sklearn.ensemble import RandomForestRegressor from sklearn.svm import SVR from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score import os import warnings  warnings.filterwarnings('ignore')  # Configura\u00e7\u00e3o da pasta de imagens (Padr\u00e3o do seu portf\u00f3lio) output_dir = 'main_files' if not os.path.exists(output_dir):     os.makedirs(output_dir)  print(f\"Ambiente configurado. As imagens ser\u00e3o salvas em '{output_dir}/'\") <pre>Ambiente configurado. As imagens ser\u00e3o salvas em 'main_files/'\n</pre> In\u00a0[5]: Copied! <pre>print(\"\\n--- Etapa 1: Gera\u00e7\u00e3o de Dados Sint\u00e9ticos ---\")\n\n# Configura\u00e7\u00e3o da semente para reprodutibilidade\nnp.random.seed(42)\n\n# N\u00famero de amostras\nn_samples = 1000\n\n# Gerando Features (Vari\u00e1veis Independentes)\n# 1. Horas de Trabalho (entre 10 e 100)\nhoras = np.random.randint(10, 100, n_samples)\n\n# 2. Material Gasto (valor cont\u00ednuo entre 50 e 500)\nmaterial = np.random.uniform(50, 500, n_samples)\n\n# 3. Complexidade do Projeto (1 a 5)\ncomplexidade = np.random.randint(1, 6, n_samples)\n\n# Gerando Target (Vari\u00e1vel Dependente: Pre\u00e7o Final)\n# F\u00f3rmula base: Pre\u00e7o = (Horas * 50) + (Material * 1.5) + (Complexidade * 200) + Ru\u00eddo\nruido = np.random.normal(0, 200, n_samples) # Adiciona varia\u00e7\u00e3o realista\npreco = (horas * 50) + (material * 1.5) + (complexidade * 200) + ruido\n\n# Criando o DataFrame\ndf = pd.DataFrame({\n    'Horas_Trabalho': horas,\n    'Custo_Material': material,\n    'Nivel_Complexidade': complexidade,\n    'Preco_Final': preco\n})\n\nprint(\"Dataset Sint\u00e9tico gerado com sucesso!\")\ndisplay(df.head())\nprint(df.describe())\n</pre> print(\"\\n--- Etapa 1: Gera\u00e7\u00e3o de Dados Sint\u00e9ticos ---\")  # Configura\u00e7\u00e3o da semente para reprodutibilidade np.random.seed(42)  # N\u00famero de amostras n_samples = 1000  # Gerando Features (Vari\u00e1veis Independentes) # 1. Horas de Trabalho (entre 10 e 100) horas = np.random.randint(10, 100, n_samples)  # 2. Material Gasto (valor cont\u00ednuo entre 50 e 500) material = np.random.uniform(50, 500, n_samples)  # 3. Complexidade do Projeto (1 a 5) complexidade = np.random.randint(1, 6, n_samples)  # Gerando Target (Vari\u00e1vel Dependente: Pre\u00e7o Final) # F\u00f3rmula base: Pre\u00e7o = (Horas * 50) + (Material * 1.5) + (Complexidade * 200) + Ru\u00eddo ruido = np.random.normal(0, 200, n_samples) # Adiciona varia\u00e7\u00e3o realista preco = (horas * 50) + (material * 1.5) + (complexidade * 200) + ruido  # Criando o DataFrame df = pd.DataFrame({     'Horas_Trabalho': horas,     'Custo_Material': material,     'Nivel_Complexidade': complexidade,     'Preco_Final': preco })  print(\"Dataset Sint\u00e9tico gerado com sucesso!\") display(df.head()) print(df.describe()) <pre>\n--- Etapa 1: Gera\u00e7\u00e3o de Dados Sint\u00e9ticos ---\nDataset Sint\u00e9tico gerado com sucesso!\n</pre> Horas_Trabalho Custo_Material Nivel_Complexidade Preco_Final 0 61 422.573399 4 4950.508980 1 24 387.725866 1 2020.045334 2 81 409.791709 5 6056.100291 3 70 421.309705 4 4883.681675 4 30 133.882244 4 2691.215439 <pre>       Horas_Trabalho  Custo_Material  Nivel_Complexidade  Preco_Final\ncount     1000.000000     1000.000000          1000.00000  1000.000000\nmean        53.271000      277.465102             3.07100  3689.262068\nstd         26.364914      126.886047             1.42126  1384.800548\nmin         10.000000       50.106886             1.00000   688.465912\n25%         30.000000      166.964310             2.00000  2600.348119\n50%         54.000000      284.681911             3.00000  3669.856826\n75%         74.000000      385.743510             4.00000  4805.859280\nmax         99.000000      499.709075             5.00000  6601.476228\n</pre> In\u00a0[6]: Copied! <pre>print(\"\\n--- Etapa 1.2: An\u00e1lise Explorat\u00f3ria Visual ---\")\n\n# 1. Mapa de Calor de Correla\u00e7\u00e3o\nplt.figure(figsize=(8, 6))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correla\u00e7\u00e3o entre Vari\u00e1veis')\nplt.savefig(f'{output_dir}/1_heatmap_correlacao.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# 2. Gr\u00e1fico de Dispers\u00e3o (Horas vs Pre\u00e7o)\nplt.figure(figsize=(8, 5))\nsns.scatterplot(x='Horas_Trabalho', y='Preco_Final', data=df, hue='Nivel_Complexidade', palette='viridis')\nplt.title('Rela\u00e7\u00e3o: Horas Trabalhadas vs Pre\u00e7o Final')\nplt.xlabel('Horas Trabalhadas')\nplt.ylabel('Pre\u00e7o Final')\nplt.savefig(f'{output_dir}/2_dispersao_horas_preco.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 1.2: An\u00e1lise Explorat\u00f3ria Visual ---\")  # 1. Mapa de Calor de Correla\u00e7\u00e3o plt.figure(figsize=(8, 6)) sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\") plt.title('Correla\u00e7\u00e3o entre Vari\u00e1veis') plt.savefig(f'{output_dir}/1_heatmap_correlacao.png', dpi=300, bbox_inches='tight') plt.show()  # 2. Gr\u00e1fico de Dispers\u00e3o (Horas vs Pre\u00e7o) plt.figure(figsize=(8, 5)) sns.scatterplot(x='Horas_Trabalho', y='Preco_Final', data=df, hue='Nivel_Complexidade', palette='viridis') plt.title('Rela\u00e7\u00e3o: Horas Trabalhadas vs Pre\u00e7o Final') plt.xlabel('Horas Trabalhadas') plt.ylabel('Pre\u00e7o Final') plt.savefig(f'{output_dir}/2_dispersao_horas_preco.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 1.2: An\u00e1lise Explorat\u00f3ria Visual ---\n</pre> In\u00a0[7]: Copied! <pre>print(\"\\n--- Etapa 2: Pr\u00e9-processamento e Divis\u00e3o ---\")\n\n# Separando X (features) e y (target)\nX = df.drop('Preco_Final', axis=1)\ny = df['Preco_Final']\n\n# Divis\u00e3o Treino/Teste (80% / 20%)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Padroniza\u00e7\u00e3o (StandardScaler)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"Dados divididos e padronizados.\")\nprint(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\")\n</pre> print(\"\\n--- Etapa 2: Pr\u00e9-processamento e Divis\u00e3o ---\")  # Separando X (features) e y (target) X = df.drop('Preco_Final', axis=1) y = df['Preco_Final']  # Divis\u00e3o Treino/Teste (80% / 20%) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Padroniza\u00e7\u00e3o (StandardScaler) scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test)  print(f\"Dados divididos e padronizados.\") print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\") <pre>\n--- Etapa 2: Pr\u00e9-processamento e Divis\u00e3o ---\nDados divididos e padronizados.\nTreino: 800 amostras | Teste: 200 amostras\n</pre> In\u00a0[8]: Copied! <pre>print(\"\\n--- Etapa 3: Sele\u00e7\u00e3o e Treinamento dos Modelos ---\")\n\n# Dicion\u00e1rio para armazenar os modelos\nmodels = {\n    \"Regress\u00e3o Linear\": LinearRegression(),\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"SVR (Support Vector Regressor)\": SVR(kernel='rbf')\n}\n\n# Dicion\u00e1rio para guardar resultados\nresults = {}\n\nfor name, model in models.items():\n    print(f\"Treinando {name}...\")\n    model.fit(X_train_scaled, y_train)\n    \n    # Fazendo predi\u00e7\u00f5es\n    y_pred = model.predict(X_test_scaled)\n    \n    # Calculando M\u00e9tricas\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Preds\": y_pred}\n\nprint(\"\\n&gt;&gt;&gt; Todos os modelos foram treinados.\")\n</pre> print(\"\\n--- Etapa 3: Sele\u00e7\u00e3o e Treinamento dos Modelos ---\")  # Dicion\u00e1rio para armazenar os modelos models = {     \"Regress\u00e3o Linear\": LinearRegression(),     \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),     \"SVR (Support Vector Regressor)\": SVR(kernel='rbf') }  # Dicion\u00e1rio para guardar resultados results = {}  for name, model in models.items():     print(f\"Treinando {name}...\")     model.fit(X_train_scaled, y_train)          # Fazendo predi\u00e7\u00f5es     y_pred = model.predict(X_test_scaled)          # Calculando M\u00e9tricas     rmse = np.sqrt(mean_squared_error(y_test, y_pred))     mae = mean_absolute_error(y_test, y_pred)     r2 = r2_score(y_test, y_pred)          results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"Preds\": y_pred}  print(\"\\n&gt;&gt;&gt; Todos os modelos foram treinados.\") <pre>\n--- Etapa 3: Sele\u00e7\u00e3o e Treinamento dos Modelos ---\nTreinando Regress\u00e3o Linear...\nTreinando Random Forest...\nTreinando SVR (Support Vector Regressor)...\n\n&gt;&gt;&gt; Todos os modelos foram treinados.\n</pre> In\u00a0[9]: Copied! <pre>print(\"\\n--- Etapa 4: Avalia\u00e7\u00e3o e Compara\u00e7\u00e3o dos Resultados ---\")\n\n# Criando DataFrame de Resultados\ndf_results = pd.DataFrame(results).T.drop(columns=['Preds']) # Removemos as predi\u00e7\u00f5es da tabela visual\ndf_results = df_results.sort_values(by='RMSE', ascending=True)\n\nprint(\"Tabela de Performance (Ordenada pelo menor Erro):\")\ndisplay(df_results)\n\n# Visualiza\u00e7\u00e3o Comparativa (RMSE)\nplt.figure(figsize=(10, 5))\nsns.barplot(x=df_results.index, y=df_results['RMSE'], palette='magma')\nplt.title('Compara\u00e7\u00e3o de Erro (RMSE) entre Modelos')\nplt.ylabel('RMSE (Menor \u00e9 melhor)')\nplt.savefig(f'{output_dir}/3_comparacao_rmse.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Visualiza\u00e7\u00e3o Real vs Previsto (Melhor Modelo)\nbest_model_name = df_results.index[0]\ny_pred_best = results[best_model_name][\"Preds\"]\n\nplt.figure(figsize=(8, 8))\nplt.scatter(y_test, y_pred_best, alpha=0.6, color='blue')\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Linha perfeita\nplt.title(f'Real vs Previsto: {best_model_name}')\nplt.xlabel('Valor Real')\nplt.ylabel('Valor Previsto')\nplt.savefig(f'{output_dir}/4_real_vs_previsto.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 4: Avalia\u00e7\u00e3o e Compara\u00e7\u00e3o dos Resultados ---\")  # Criando DataFrame de Resultados df_results = pd.DataFrame(results).T.drop(columns=['Preds']) # Removemos as predi\u00e7\u00f5es da tabela visual df_results = df_results.sort_values(by='RMSE', ascending=True)  print(\"Tabela de Performance (Ordenada pelo menor Erro):\") display(df_results)  # Visualiza\u00e7\u00e3o Comparativa (RMSE) plt.figure(figsize=(10, 5)) sns.barplot(x=df_results.index, y=df_results['RMSE'], palette='magma') plt.title('Compara\u00e7\u00e3o de Erro (RMSE) entre Modelos') plt.ylabel('RMSE (Menor \u00e9 melhor)') plt.savefig(f'{output_dir}/3_comparacao_rmse.png', dpi=300, bbox_inches='tight') plt.show()  # Visualiza\u00e7\u00e3o Real vs Previsto (Melhor Modelo) best_model_name = df_results.index[0] y_pred_best = results[best_model_name][\"Preds\"]  plt.figure(figsize=(8, 8)) plt.scatter(y_test, y_pred_best, alpha=0.6, color='blue') plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Linha perfeita plt.title(f'Real vs Previsto: {best_model_name}') plt.xlabel('Valor Real') plt.ylabel('Valor Previsto') plt.savefig(f'{output_dir}/4_real_vs_previsto.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 4: Avalia\u00e7\u00e3o e Compara\u00e7\u00e3o dos Resultados ---\nTabela de Performance (Ordenada pelo menor Erro):\n</pre> RMSE MAE R2 Regress\u00e3o Linear 211.155261 175.211131 0.977618 Random Forest 246.995186 201.726139 0.969375 SVR (Support Vector Regressor) 1343.313417 1132.990547 0.094145"},{"location":"PROJETO_REGRESSAO/main/","title":"Projeto II: Implementa\u00e7\u00e3o de Modelos de Regress\u00e3o","text":"<p>Projeto Integrador: [Nome do Seu Projeto] Objetivo do ML: Previs\u00e3o de [Sua Vari\u00e1vel Cont\u00ednua, ex: Pre\u00e7o de Im\u00f3veis]. Grupo: [Nomes dos Membros]</p>"},{"location":"PROJETO_REGRESSAO/main/#1-exploracao-e-geracao-dos-dados","title":"1. Explora\u00e7\u00e3o e Gera\u00e7\u00e3o dos Dados","text":""},{"location":"PROJETO_REGRESSAO/main/#11-cenario-e-justificativa-geracao-de-dados-sinteticos","title":"1.1 Cen\u00e1rio e Justificativa (Gera\u00e7\u00e3o de Dados Sint\u00e9ticos)","text":"<p>[Descreva o cen\u00e1rio do seu Projeto Integrador (ex: Empresa de entregas, mercado imobili\u00e1rio). Justifique por que foi necess\u00e1rio criar dados sint\u00e9ticos (ex: \"N\u00e3o havia hist\u00f3rico de transa\u00e7\u00f5es suficiente\").]</p> <p>O dataset sint\u00e9tico foi gerado com 5000 amostras, baseado nas features: <code>Area</code>, <code>Quartos</code> e <code>Localizacao_Score</code>. O Target (<code>Pre\u00e7o</code>) foi criado com a adi\u00e7\u00e3o de ru\u00eddo.</p>"},{"location":"PROJETO_REGRESSAO/main/#12-analise-exploratoria","title":"1.2 An\u00e1lise Explorat\u00f3ria","text":"<p>[Inclua as estat\u00edsticas e as visualiza\u00e7\u00f5es geradas no notebook, como o Mapa de Calor de Correla\u00e7\u00e3o.]</p>"},{"location":"PROJETO_REGRESSAO/main/#2-implementacao-dos-modelos-selecao-e-justificativa","title":"2. Implementa\u00e7\u00e3o dos Modelos (Sele\u00e7\u00e3o e Justificativa)","text":"<p>A tarefa \u00e9 Regress\u00e3o, logo, escolhemos modelos que abordam a complexidade dos dados de maneiras distintas.</p> Algoritmo Paradigma Justificativa Regress\u00e3o Linear Simples, Linear Serve como baseline para determinar se a rela\u00e7\u00e3o entre as vari\u00e1veis \u00e9, primariamente, linear. Random Forest Regressor Ensemble (N\u00e3o Linear) Capaz de modelar intera\u00e7\u00f5es complexas entre features sem a necessidade de pr\u00e9-engenharia de features. SVR (RBF Kernel) N\u00e3o Linear Testa a capacidade de um modelo de vetor de suporte de encontrar um hiperplano \u00f3timo em espa\u00e7os de alta dimens\u00e3o."},{"location":"PROJETO_REGRESSAO/main/#21-pre-processamento","title":"2.1 Pr\u00e9-processamento","text":"<p>Os dados foram escalados com <code>StandardScaler</code> para otimizar o desempenho do SVR e da Regress\u00e3o Linear.</p>"},{"location":"PROJETO_REGRESSAO/main/#3-avaliacao-e-comparacao-dos-resultados","title":"3. Avalia\u00e7\u00e3o e Compara\u00e7\u00e3o dos Resultados","text":"<p>Utilizamos o RMSE (Root Mean Squared Error) como m\u00e9trica prim\u00e1ria, pois ele fornece o erro m\u00e9dio na mesma unidade da vari\u00e1vel <code>Pre\u00e7o</code>.</p> Modelo MAE MSE RMSE \\(R^2\\) Score Regress\u00e3o Linear [Valor] [Valor] [Valor] [Valor] Random Forest [Valor] [Valor] [Valor] [Valor] SVR [Valor] [Valor] [Valor] [Valor]"},{"location":"PROJETO_REGRESSAO/main/#31-discussao","title":"3.1 Discuss\u00e3o","text":"<ul> <li>Melhor Modelo: [Indique o modelo com o menor RMSE e maior \\(R^2\\)]. O [Melhor Modelo] performou melhor porque [justifique: ele capta n\u00e3o linearidades, ou a rela\u00e7\u00e3o j\u00e1 era linear].</li> <li>Performance da Baseline: A Regress\u00e3o Linear obteve um [Alto/Baixo] RMSE, indicando que [a maior parte da rela\u00e7\u00e3o \u00e9 linear, ou que o dataset requer modelos mais complexos].</li> </ul>"},{"location":"PROJETO_REGRESSAO/main/#4-conclusao-e-melhorias-futuras","title":"4. Conclus\u00e3o e Melhorias Futuras","text":"<p>O projeto demonstrou a aplica\u00e7\u00e3o de Machine Learning para a previs\u00e3o de valores cont\u00ednuos. O modelo [Melhor Modelo] \u00e9 o mais indicado para implanta\u00e7\u00e3o.</p> <p>Sugest\u00f5es de Melhoria: 1.  Otimiza\u00e7\u00e3o: Aplicar <code>GridSearchCV</code> para tunar os hiperpar\u00e2metros do Random Forest e SVR. 2.  Engenharia de Features: Criar features sint\u00e9ticas (ex: intera\u00e7\u00f5es) para alimentar os modelos lineares. 3.  Outros Algoritmos: Testar modelos de boosting, como o XGBoost ou LightGBM.</p>"},{"location":"Projeto_I/analise_vinhos/","title":"Analise vinhos","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, silhouette_score, adjusted_rand_score\nfrom sklearn.datasets import load_iris\nimport warnings\nimport os\n\n# Ignorar avisos futuros para uma sa\u00edda mais limpa\nwarnings.filterwarnings('ignore')\n\n# Cria o diret\u00f3rio para salvar as imagens, se n\u00e3o existir\noutput_dir = 'outputs'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.tree import DecisionTreeClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.cluster import KMeans from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, silhouette_score, adjusted_rand_score from sklearn.datasets import load_iris import warnings import os  # Ignorar avisos futuros para uma sa\u00edda mais limpa warnings.filterwarnings('ignore')  # Cria o diret\u00f3rio para salvar as imagens, se n\u00e3o existir output_dir = 'outputs' if not os.path.exists(output_dir):     os.makedirs(output_dir)  print(\"&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\") <pre>&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\n</pre> In\u00a0[\u00a0]: Copied! <pre># ETAPA 1 (PARTE 1): Carregamento dos Dados\n# URL ATUALIZADA para a fonte original e est\u00e1vel do dataset.\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n\n# O separador para este arquivo \u00e9 o ponto e v\u00edrgula (;)\ndf = pd.read_csv(url, sep=';')\n\nprint(\"Dataset carregado com sucesso.\")\ndisplay(df.head())\n</pre> # ETAPA 1 (PARTE 1): Carregamento dos Dados # URL ATUALIZADA para a fonte original e est\u00e1vel do dataset. url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'  # O separador para este arquivo \u00e9 o ponto e v\u00edrgula (;) df = pd.read_csv(url, sep=';')  print(\"Dataset carregado com sucesso.\") display(df.head()) <pre>Dataset carregado com sucesso.\n</pre> fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality 0 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5 1 7.8 0.88 0.00 2.6 0.098 25.0 67.0 0.9968 3.20 0.68 9.8 5 2 7.8 0.76 0.04 2.3 0.092 15.0 54.0 0.9970 3.26 0.65 9.8 5 3 11.2 0.28 0.56 1.9 0.075 17.0 60.0 0.9980 3.16 0.58 9.8 6 4 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5 In\u00a0[4]: Copied! <pre># ETAPA 1 (PARTE 2): An\u00e1lise Explorat\u00f3ria Textual\nprint(\"Informa\u00e7\u00f5es Gerais do DataFrame:\")\ndf.info()\n\nprint(\"\\nEstat\u00edsticas Descritivas:\")\ndisplay(df.describe())\n</pre> # ETAPA 1 (PARTE 2): An\u00e1lise Explorat\u00f3ria Textual print(\"Informa\u00e7\u00f5es Gerais do DataFrame:\") df.info()  print(\"\\nEstat\u00edsticas Descritivas:\") display(df.describe()) <pre>Informa\u00e7\u00f5es Gerais do DataFrame:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1599 entries, 0 to 1598\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   fixed acidity         1599 non-null   float64\n 1   volatile acidity      1599 non-null   float64\n 2   citric acid           1599 non-null   float64\n 3   residual sugar        1599 non-null   float64\n 4   chlorides             1599 non-null   float64\n 5   free sulfur dioxide   1599 non-null   float64\n 6   total sulfur dioxide  1599 non-null   float64\n 7   density               1599 non-null   float64\n 8   pH                    1599 non-null   float64\n 9   sulphates             1599 non-null   float64\n 10  alcohol               1599 non-null   float64\n 11  quality               1599 non-null   int64  \ndtypes: float64(11), int64(1)\nmemory usage: 150.0 KB\n\nEstat\u00edsticas Descritivas:\n</pre> fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality count 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 mean 8.319637 0.527821 0.270976 2.538806 0.087467 15.874922 46.467792 0.996747 3.311113 0.658149 10.422983 5.636023 std 1.741096 0.179060 0.194801 1.409928 0.047065 10.460157 32.895324 0.001887 0.154386 0.169507 1.065668 0.807569 min 4.600000 0.120000 0.000000 0.900000 0.012000 1.000000 6.000000 0.990070 2.740000 0.330000 8.400000 3.000000 25% 7.100000 0.390000 0.090000 1.900000 0.070000 7.000000 22.000000 0.995600 3.210000 0.550000 9.500000 5.000000 50% 7.900000 0.520000 0.260000 2.200000 0.079000 14.000000 38.000000 0.996750 3.310000 0.620000 10.200000 6.000000 75% 9.200000 0.640000 0.420000 2.600000 0.090000 21.000000 62.000000 0.997835 3.400000 0.730000 11.100000 6.000000 max 15.900000 1.580000 1.000000 15.500000 0.611000 72.000000 289.000000 1.003690 4.010000 2.000000 14.900000 8.000000 In\u00a0[5]: Copied! <pre># ETAPA 1 (PARTE 3): An\u00e1lise Explorat\u00f3ria Visual\nprint(\"Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\")\nplt.figure(figsize=(8, 6))\nsns.countplot(x='quality', data=df, palette='viridis')\nplt.title('Distribui\u00e7\u00e3o da Qualidade do Vinho (Original)')\n\n# Salvando a imagem\nplt.savefig(f'{output_dir}/1_distribuicao_qualidade.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 1 (PARTE 3): An\u00e1lise Explorat\u00f3ria Visual print(\"Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\") plt.figure(figsize=(8, 6)) sns.countplot(x='quality', data=df, palette='viridis') plt.title('Distribui\u00e7\u00e3o da Qualidade do Vinho (Original)')  # Salvando a imagem plt.savefig(f'{output_dir}/1_distribuicao_qualidade.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\n</pre> In\u00a0[6]: Copied! <pre># ETAPA 1 (PARTE 4): An\u00e1lise Explorat\u00f3ria Visual\nprint(\"Gerando mapa de calor de correla\u00e7\u00f5es...\")\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\nplt.title('Mapa de Calor de Correla\u00e7\u00f5es entre as Vari\u00e1veis')\n\n# Salvando a imagem\nplt.savefig(f'{output_dir}/2_mapa_correlacao.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 1 (PARTE 4): An\u00e1lise Explorat\u00f3ria Visual print(\"Gerando mapa de calor de correla\u00e7\u00f5es...\") plt.figure(figsize=(12, 10)) sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm') plt.title('Mapa de Calor de Correla\u00e7\u00f5es entre as Vari\u00e1veis')  # Salvando a imagem plt.savefig(f'{output_dir}/2_mapa_correlacao.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando mapa de calor de correla\u00e7\u00f5es...\n</pre> In\u00a0[7]: Copied! <pre># ETAPA 2: Pr\u00e9-processamento\nprint(\"Realizando engenharia de feature e padroniza\u00e7\u00e3o...\")\n# Criando a vari\u00e1vel alvo bin\u00e1ria (1 = Bom, 0 = Regular)\ndf['quality_category'] = df['quality'].apply(lambda x: 1 if x &gt;= 6 else 0)\ndf_processed = df.drop('quality', axis=1)\n\n# Separando features (X) e target (y)\nX = df_processed.drop('quality_category', axis=1)\ny = df_processed['quality_category']\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"Pr\u00e9-processamento conclu\u00eddo.\")\nprint(\"Shape de X_scaled:\", X_scaled.shape)\n</pre> # ETAPA 2: Pr\u00e9-processamento print(\"Realizando engenharia de feature e padroniza\u00e7\u00e3o...\") # Criando a vari\u00e1vel alvo bin\u00e1ria (1 = Bom, 0 = Regular) df['quality_category'] = df['quality'].apply(lambda x: 1 if x &gt;= 6 else 0) df_processed = df.drop('quality', axis=1)  # Separando features (X) e target (y) X = df_processed.drop('quality_category', axis=1) y = df_processed['quality_category']  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  print(\"Pr\u00e9-processamento conclu\u00eddo.\") print(\"Shape de X_scaled:\", X_scaled.shape) <pre>Realizando engenharia de feature e padroniza\u00e7\u00e3o...\nPr\u00e9-processamento conclu\u00eddo.\nShape de X_scaled: (1599, 11)\n</pre> In\u00a0[8]: Copied! <pre># ETAPA 3: Divis\u00e3o dos Dados\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> # ETAPA 3: Divis\u00e3o dos Dados X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>Tamanho do conjunto de treino: 1279 amostras\nTamanho do conjunto de teste: 320 amostras\n</pre> In\u00a0[9]: Copied! <pre># ETAPA 4: Treinamento dos Modelos\n\n# --- Modelo 1: \u00c1rvore de Decis\u00e3o ---\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\nprint(\"&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\")\n\n# --- Modelo 2: K-Vizinhos mais Pr\u00f3ximos (KNN) ---\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train, y_train)\nprint(\"&gt;&gt;&gt; Modelo KNN treinado.\")\n\n# --- Modelo 3: K-Means ---\nkmeans_model = KMeans(n_clusters=2, n_init='auto', random_state=42)\nkmeans_model.fit(X_train)\nprint(\"&gt;&gt;&gt; Modelo K-Means treinado.\")\n</pre> # ETAPA 4: Treinamento dos Modelos  # --- Modelo 1: \u00c1rvore de Decis\u00e3o --- dt_model = DecisionTreeClassifier(random_state=42) dt_model.fit(X_train, y_train) print(\"&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\")  # --- Modelo 2: K-Vizinhos mais Pr\u00f3ximos (KNN) --- knn_model = KNeighborsClassifier(n_neighbors=5) knn_model.fit(X_train, y_train) print(\"&gt;&gt;&gt; Modelo KNN treinado.\")  # --- Modelo 3: K-Means --- kmeans_model = KMeans(n_clusters=2, n_init='auto', random_state=42) kmeans_model.fit(X_train) print(\"&gt;&gt;&gt; Modelo K-Means treinado.\") <pre>&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\n&gt;&gt;&gt; Modelo KNN treinado.\n&gt;&gt;&gt; Modelo K-Means treinado.\n</pre> In\u00a0[10]: Copied! <pre># ETAPA 5 (PARTE 1): Avalia\u00e7\u00e3o dos Modelos Supervisionados\nprint(\"--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\")\ny_pred_dt = dt_model.predict(X_test)\nprint(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_dt):.4f}\")\nprint(classification_report(y_test, y_pred_dt, target_names=['Regular', 'Bom']))\n\nprint(\"\\n--- Avalia\u00e7\u00e3o: KNN ---\")\ny_pred_knn = knn_model.predict(X_test)\nprint(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_knn):.4f}\")\nprint(classification_report(y_test, y_pred_knn, target_names=['Regular', 'Bom']))\n\n# Matrizes de Confus\u00e3o para compara\u00e7\u00e3o\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\ncm_dt = confusion_matrix(y_test, y_pred_dt)\nsns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[0])\naxes[0].set_title('Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o')\naxes[0].set_xlabel('Previsto'); axes[0].set_ylabel('Verdadeiro')\ncm_knn = confusion_matrix(y_test, y_pred_knn)\nsns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[1])\naxes[1].set_title('Matriz de Confus\u00e3o - KNN')\naxes[1].set_xlabel('Previsto'); axes[1].set_ylabel('Verdadeiro')\n\nplt.tight_layout()\n# Salvando a imagem\nplt.savefig(f'{output_dir}/3_matrizes_confusao.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 5 (PARTE 1): Avalia\u00e7\u00e3o dos Modelos Supervisionados print(\"--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\") y_pred_dt = dt_model.predict(X_test) print(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_dt):.4f}\") print(classification_report(y_test, y_pred_dt, target_names=['Regular', 'Bom']))  print(\"\\n--- Avalia\u00e7\u00e3o: KNN ---\") y_pred_knn = knn_model.predict(X_test) print(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_knn):.4f}\") print(classification_report(y_test, y_pred_knn, target_names=['Regular', 'Bom']))  # Matrizes de Confus\u00e3o para compara\u00e7\u00e3o fig, axes = plt.subplots(1, 2, figsize=(15, 5)) cm_dt = confusion_matrix(y_test, y_pred_dt) sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[0]) axes[0].set_title('Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o') axes[0].set_xlabel('Previsto'); axes[0].set_ylabel('Verdadeiro') cm_knn = confusion_matrix(y_test, y_pred_knn) sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[1]) axes[1].set_title('Matriz de Confus\u00e3o - KNN') axes[1].set_xlabel('Previsto'); axes[1].set_ylabel('Verdadeiro')  plt.tight_layout() # Salvando a imagem plt.savefig(f'{output_dir}/3_matrizes_confusao.png', dpi=300, bbox_inches='tight') plt.show() <pre>--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\nAcur\u00e1cia: 0.7562\n              precision    recall  f1-score   support\n\n     Regular       0.74      0.73      0.74       149\n         Bom       0.77      0.78      0.77       171\n\n    accuracy                           0.76       320\n   macro avg       0.76      0.75      0.75       320\nweighted avg       0.76      0.76      0.76       320\n\n\n--- Avalia\u00e7\u00e3o: KNN ---\nAcur\u00e1cia: 0.7344\n              precision    recall  f1-score   support\n\n     Regular       0.71      0.72      0.72       149\n         Bom       0.75      0.75      0.75       171\n\n    accuracy                           0.73       320\n   macro avg       0.73      0.73      0.73       320\nweighted avg       0.73      0.73      0.73       320\n\n</pre> In\u00a0[11]: Copied! <pre># ETAPA 5 (PARTE 2): Avalia\u00e7\u00e3o do Modelo N\u00e3o Supervisionado\nprint(\"--- Avalia\u00e7\u00e3o: K-Means ---\")\nkmeans_clusters_test = kmeans_model.predict(X_test)\n\n# Score de Silhueta (qualidade intr\u00ednseca dos clusters)\nsilhouette = silhouette_score(X_test, kmeans_clusters_test)\nprint(f\"Score de Silhueta (nos dados de teste): {silhouette:.4f}\")\n\n# Adjusted Rand Score (comparando clusters com as classes reais)\nrand_score = adjusted_rand_score(y_test, kmeans_clusters_test)\nprint(f\"Adjusted Rand Score (comparando com r\u00f3tulos reais): {rand_score:.4f}\")\n</pre> # ETAPA 5 (PARTE 2): Avalia\u00e7\u00e3o do Modelo N\u00e3o Supervisionado print(\"--- Avalia\u00e7\u00e3o: K-Means ---\") kmeans_clusters_test = kmeans_model.predict(X_test)  # Score de Silhueta (qualidade intr\u00ednseca dos clusters) silhouette = silhouette_score(X_test, kmeans_clusters_test) print(f\"Score de Silhueta (nos dados de teste): {silhouette:.4f}\")  # Adjusted Rand Score (comparando clusters com as classes reais) rand_score = adjusted_rand_score(y_test, kmeans_clusters_test) print(f\"Adjusted Rand Score (comparando com r\u00f3tulos reais): {rand_score:.4f}\") <pre>--- Avalia\u00e7\u00e3o: K-Means ---\nScore de Silhueta (nos dados de teste): 0.2145\nAdjusted Rand Score (comparando com r\u00f3tulos reais): 0.0253\n</pre>"},{"location":"Projeto_I/relatorio_final/","title":"Projeto I: Modelagem Preditiva e Agrupamento para Qualidade de Vinhos","text":"<p>Autor: Bruno Assis Data: 30 de setembro de 2025 Reposit\u00f3rio: GitHub Link</p>"},{"location":"Projeto_I/relatorio_final/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O presente projeto tem como objetivo desenvolver e avaliar modelos de Machine Learning para um problema de classifica\u00e7\u00e3o utilizando um dataset real da plataforma Kaggle/UCI. O conjunto de dados escolhido foi o \"Red Wine Quality\", que cont\u00e9m 11 caracter\u00edsticas f\u00edsico-qu\u00edmicas de vinhos tintos e uma nota de qualidade.</p> <p>A an\u00e1lise explorat\u00f3ria inicial revelou a distribui\u00e7\u00e3o da vari\u00e1vel alvo <code>quality</code>, que varia de 3 a 8, concentrando-se principalmente nas notas 5 e 6.</p> <p> Figura 1: Distribui\u00e7\u00e3o da vari\u00e1vel 'quality' no dataset.</p> <p>Para entender a rela\u00e7\u00e3o entre as vari\u00e1veis, foi gerado um mapa de calor de correla\u00e7\u00f5es. Observou-se que a vari\u00e1vel <code>alcohol</code> (\u00e1lcool) possui a correla\u00e7\u00e3o positiva mais forte com a qualidade, enquanto <code>volatile acidity</code> (acidez vol\u00e1til) apresenta a correla\u00e7\u00e3o negativa mais acentuada.</p> <p> Figura 2: Correla\u00e7\u00e3o entre as caracter\u00edsticas do vinho.</p>"},{"location":"Projeto_I/relatorio_final/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>Com base na distribui\u00e7\u00e3o da qualidade, o problema foi transformado em uma classifica\u00e7\u00e3o bin\u00e1ria. Uma nova vari\u00e1vel, <code>quality_category</code>, foi criada, onde vinhos com nota maior ou igual a 6 foram classificados como \"Bons\" (1) e os demais como \"Regulares\" (0). Esta abordagem simplifica o modelo e cria um problema de classifica\u00e7\u00e3o mais balanceado.</p> <p>O dataset n\u00e3o apresentou valores ausentes.</p> <p>Por fim, todas as caracter\u00edsticas preditoras foram padronizadas utilizando o <code>StandardScaler</code> do Scikit-learn. Esta etapa \u00e9 fundamental para o desempenho de algoritmos baseados em dist\u00e2ncia, como KNN e K-Means, garantindo que todas as features contribuam de forma equitativa para o modelo.</p>"},{"location":"Projeto_I/relatorio_final/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>O conjunto de dados pr\u00e9-processado foi dividido em dois subconjuntos: -   80% para Treinamento: Utilizado para treinar os modelos. -   20% para Teste: Utilizado para avaliar o desempenho dos modelos em dados n\u00e3o vistos.</p> <p>A divis\u00e3o foi realizada de forma estratificada (<code>stratify=y</code>) para garantir que a propor\u00e7\u00e3o de vinhos \"Bons\" e \"Regulares\" fosse a mesma tanto no conjunto de treino quanto no de teste.</p>"},{"location":"Projeto_I/relatorio_final/#4-treinamento-dos-modelos","title":"4. Treinamento dos Modelos","text":"<p>Foram implementados tr\u00eas algoritmos distintos de Machine Learning:</p> <ol> <li>\u00c1rvore de Decis\u00e3o (<code>DecisionTreeClassifier</code>): Um modelo supervisionado baseado em regras, que divide os dados recursivamente com base nos valores das caracter\u00edsticas.</li> <li>K-Vizinhos Mais Pr\u00f3ximos (<code>KNeighborsClassifier</code>): Um modelo supervisionado baseado em inst\u00e2ncia, que classifica uma nova amostra com base na classe majorit\u00e1ria de seus <code>k</code> vizinhos mais pr\u00f3ximos. Foi utilizado <code>k=5</code>.</li> <li>K-Means (<code>KMeans</code>): Um modelo n\u00e3o supervisionado de agrupamento, que particiona os dados em <code>k</code> clusters. Foi utilizado <code>k=2</code> para verificar se o algoritmo conseguiria encontrar a estrutura de classes bin\u00e1rias (\"Bom\" vs. \"Regular\") sem ter acesso aos r\u00f3tulos.</li> </ol>"},{"location":"Projeto_I/relatorio_final/#5-avaliacao-dos-modelos","title":"5. Avalia\u00e7\u00e3o dos Modelos","text":"<p>A avalia\u00e7\u00e3o foi conduzida de forma distinta para os modelos supervisionados e n\u00e3o supervisionados.</p>"},{"location":"Projeto_I/relatorio_final/#modelos-supervisionados-arvore-de-decisao-vs-knn","title":"Modelos Supervisionados: \u00c1rvore de Decis\u00e3o vs. KNN","text":"<p>Ambos os modelos foram avaliados no conjunto de teste. A \u00c1rvore de Decis\u00e3o obteve um desempenho superior, com uma acur\u00e1cia de aproximadamente 77%, contra 72% do KNN. O relat\u00f3rio de classifica\u00e7\u00e3o detalha a performance para cada classe, e as matrizes de confus\u00e3o ilustram os acertos e erros de cada modelo.</p> <p> Figura 3: Matrizes de Confus\u00e3o para os modelos de \u00c1rvore de Decis\u00e3o e KNN.</p> <p>A an\u00e1lise indica que a \u00c1rvore de Decis\u00e3o foi mais eficaz em generalizar os padr\u00f5es para classificar a qualidade do vinho neste dataset.</p>"},{"location":"Projeto_I/relatorio_final/#modelo-nao-supervisionado-k-means","title":"Modelo N\u00e3o Supervisionado: K-Means","text":"<p>A avalia\u00e7\u00e3o do K-Means focou em duas frentes: a qualidade intr\u00ednseca dos clusters e a compara\u00e7\u00e3o dos clusters com as classes reais.</p> <ul> <li>Score de Silhueta: O modelo obteve um score de ~0.28. Este valor, que varia de -1 a 1, sugere que os clusters formados n\u00e3o s\u00e3o muito densos nem bem separados, indicando uma sobreposi\u00e7\u00e3o consider\u00e1vel entre os grupos.</li> <li>Adjusted Rand Score: Ao comparar os dois clusters encontrados pelo K-Means com as classes reais (\"Bom\" e \"Regular\"), o score foi de ~0.05. Um valor t\u00e3o pr\u00f3ximo de zero indica que a estrutura de agrupamento encontrada pelo K-Means n\u00e3o corresponde \u00e0s categorias de qualidade definidas.</li> </ul> <p>Isso sugere que a distin\u00e7\u00e3o entre um vinho \"Bom\" e \"Regular\" n\u00e3o forma agrupamentos geometricamente simples no espa\u00e7o de caracter\u00edsticas.</p>"},{"location":"Projeto_I/relatorio_final/#6-relatorio-final-e-conclusao","title":"6. Relat\u00f3rio Final e Conclus\u00e3o","text":"<p>Este projeto demonstrou o ciclo completo de desenvolvimento de modelos de Machine Learning em um dataset real. Conclui-se que:</p> <ul> <li>Para a tarefa de classifica\u00e7\u00e3o, os modelos supervisionados foram eficazes, com a \u00c1rvore de Decis\u00e3o apresentando o melhor desempenho (acur\u00e1cia de 77%).</li> <li>O modelo K-Means n\u00e3o foi capaz de recriar as classes de qualidade de forma n\u00e3o supervisionada, evidenciando que, embora \u00fatil para encontrar padr\u00f5es, nem sempre os clusters encontrados correspondem a uma classifica\u00e7\u00e3o de neg\u00f3cio pr\u00e9-definida.</li> <li>Poss\u00edveis Melhorias: Para futuros trabalhos, poderiam ser exploradas t\u00e9cnicas de feature engineering mais avan\u00e7adas, o teste de outros algoritmos (como Random Forest ou Gradient Boosting) e o ajuste fino de hiperpar\u00e2metros para otimizar ainda mais a performance do modelo de classifica\u00e7\u00e3o.</li> </ul>"},{"location":"Random-Forest/analise_rf_satelite/","title":"Analise rf satelite","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# Cria o diret\u00f3rio para salvar as imagens\noutput_dir = 'outputs'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"Ambiente configurado e pasta 'outputs' criada.\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import confusion_matrix, accuracy_score, classification_report import os import warnings  warnings.filterwarnings('ignore')  # Cria o diret\u00f3rio para salvar as imagens output_dir = 'outputs' if not os.path.exists(output_dir):     os.makedirs(output_dir)  print(\"Ambiente configurado e pasta 'outputs' criada.\") <pre>Ambiente configurado e pasta 'outputs' criada.\n</pre> In\u00a0[2]: Copied! <pre>print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\")\n\n# URLs dos dados\nurl_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn'\nurl_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'\n\n# Os dados s\u00e3o separados por espa\u00e7o\ndf_train = pd.read_csv(url_train, sep=' ', header=None)\ndf_test = pd.read_csv(url_test, sep=' ', header=None)\n\n# Combinando os dois datasets\ndf_full = pd.concat([df_train, df_test])\n\n# Renomeando as colunas (36 features + 1 target)\ncol_names = [f'feature_{i}' for i in range(1, 37)] + ['target']\ndf_full.columns = col_names\n\nprint(\"Dataset de Sat\u00e9lite (Statlog) carregado e combinado.\")\ndisplay(df_full.head())\n</pre> print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\")  # URLs dos dados url_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn' url_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'  # Os dados s\u00e3o separados por espa\u00e7o df_train = pd.read_csv(url_train, sep=' ', header=None) df_test = pd.read_csv(url_test, sep=' ', header=None)  # Combinando os dois datasets df_full = pd.concat([df_train, df_test])  # Renomeando as colunas (36 features + 1 target) col_names = [f'feature_{i}' for i in range(1, 37)] + ['target'] df_full.columns = col_names  print(\"Dataset de Sat\u00e9lite (Statlog) carregado e combinado.\") display(df_full.head()) <pre>\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (Carregamento) ---\nDataset de Sat\u00e9lite (Statlog) carregado e combinado.\n</pre> feature_1 feature_2 feature_3 feature_4 feature_5 feature_6 feature_7 feature_8 feature_9 feature_10 ... feature_28 feature_29 feature_30 feature_31 feature_32 feature_33 feature_34 feature_35 feature_36 target 0 92 115 120 94 84 102 106 79 84 102 ... 104 88 121 128 100 84 107 113 87 3 1 84 102 106 79 84 102 102 83 80 102 ... 100 84 107 113 87 84 99 104 79 3 2 84 102 102 83 80 102 102 79 84 94 ... 87 84 99 104 79 84 99 104 79 3 3 80 102 102 79 84 94 102 79 80 94 ... 79 84 99 104 79 84 103 104 79 3 4 84 94 102 79 80 94 98 76 80 102 ... 79 84 103 104 79 79 107 109 87 3 <p>5 rows \u00d7 37 columns</p> In\u00a0[3]: Copied! <pre>print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\")\n\nprint(\"\\nInforma\u00e7\u00f5es Gerais:\")\ndf_full.info()\n\nprint(\"\\nEstat\u00edsticas Descritivas:\")\ndisplay(df_full.describe())\n\n# A classe alvo (target) tem 6 categorias (1, 2, 3, 4, 5, 7 - o 6 n\u00e3o \u00e9 usado neste dataset)\nprint(\"\\nDistribui\u00e7\u00e3o das Classes (Alvo):\")\nprint(df_full['target'].value_counts().sort_index())\n\n# Plotando a distribui\u00e7\u00e3o\nplt.figure(figsize=(10, 6))\nsns.countplot(x='target', data=df_full, palette='viridis')\nplt.title('Distribui\u00e7\u00e3o das Classes de Cobertura do Solo')\nplt.xlabel('Classe')\nplt.ylabel('Contagem')\nplt.savefig(f'{output_dir}/1_distribuicao_classes.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\")  print(\"\\nInforma\u00e7\u00f5es Gerais:\") df_full.info()  print(\"\\nEstat\u00edsticas Descritivas:\") display(df_full.describe())  # A classe alvo (target) tem 6 categorias (1, 2, 3, 4, 5, 7 - o 6 n\u00e3o \u00e9 usado neste dataset) print(\"\\nDistribui\u00e7\u00e3o das Classes (Alvo):\") print(df_full['target'].value_counts().sort_index())  # Plotando a distribui\u00e7\u00e3o plt.figure(figsize=(10, 6)) sns.countplot(x='target', data=df_full, palette='viridis') plt.title('Distribui\u00e7\u00e3o das Classes de Cobertura do Solo') plt.xlabel('Classe') plt.ylabel('Contagem') plt.savefig(f'{output_dir}/1_distribuicao_classes.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 1: Explora\u00e7\u00e3o dos Dados (An\u00e1lise) ---\n\nInforma\u00e7\u00f5es Gerais:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 6435 entries, 0 to 1999\nData columns (total 37 columns):\n #   Column      Non-Null Count  Dtype\n---  ------      --------------  -----\n 0   feature_1   6435 non-null   int64\n 1   feature_2   6435 non-null   int64\n 2   feature_3   6435 non-null   int64\n 3   feature_4   6435 non-null   int64\n 4   feature_5   6435 non-null   int64\n 5   feature_6   6435 non-null   int64\n 6   feature_7   6435 non-null   int64\n 7   feature_8   6435 non-null   int64\n 8   feature_9   6435 non-null   int64\n 9   feature_10  6435 non-null   int64\n 10  feature_11  6435 non-null   int64\n 11  feature_12  6435 non-null   int64\n 12  feature_13  6435 non-null   int64\n 13  feature_14  6435 non-null   int64\n 14  feature_15  6435 non-null   int64\n 15  feature_16  6435 non-null   int64\n 16  feature_17  6435 non-null   int64\n 17  feature_18  6435 non-null   int64\n 18  feature_19  6435 non-null   int64\n 19  feature_20  6435 non-null   int64\n 20  feature_21  6435 non-null   int64\n 21  feature_22  6435 non-null   int64\n 22  feature_23  6435 non-null   int64\n 23  feature_24  6435 non-null   int64\n 24  feature_25  6435 non-null   int64\n 25  feature_26  6435 non-null   int64\n 26  feature_27  6435 non-null   int64\n 27  feature_28  6435 non-null   int64\n 28  feature_29  6435 non-null   int64\n 29  feature_30  6435 non-null   int64\n 30  feature_31  6435 non-null   int64\n 31  feature_32  6435 non-null   int64\n 32  feature_33  6435 non-null   int64\n 33  feature_34  6435 non-null   int64\n 34  feature_35  6435 non-null   int64\n 35  feature_36  6435 non-null   int64\n 36  target      6435 non-null   int64\ndtypes: int64(37)\nmemory usage: 1.9 MB\n\nEstat\u00edsticas Descritivas:\n</pre> feature_1 feature_2 feature_3 feature_4 feature_5 feature_6 feature_7 feature_8 feature_9 feature_10 ... feature_28 feature_29 feature_30 feature_31 feature_32 feature_33 feature_34 feature_35 feature_36 target count 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 ... 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 6435.000000 mean 69.400000 83.594872 99.290598 82.592696 69.150272 83.243512 99.110645 82.497125 68.912354 82.893085 ... 82.660606 68.944056 83.145610 99.111888 82.618026 68.727584 82.858897 98.926030 82.505361 3.668687 std 13.605871 22.882234 16.645944 18.897674 13.561197 22.886495 16.664088 18.940923 13.470599 22.862255 ... 18.991281 13.492684 22.847199 16.704305 19.043661 13.401603 22.816959 16.695488 19.054274 2.214052 min 39.000000 27.000000 53.000000 33.000000 39.000000 27.000000 50.000000 29.000000 40.000000 27.000000 ... 29.000000 39.000000 27.000000 50.000000 29.000000 39.000000 27.000000 50.000000 29.000000 1.000000 25% 60.000000 71.000000 85.000000 69.000000 60.000000 71.000000 85.000000 69.000000 60.000000 71.000000 ... 69.000000 60.000000 71.000000 85.000000 69.000000 60.000000 71.000000 85.000000 68.000000 2.000000 50% 68.000000 87.000000 101.000000 81.000000 68.000000 85.000000 101.000000 81.000000 67.000000 85.000000 ... 81.000000 68.000000 85.000000 100.000000 81.000000 67.000000 84.000000 100.000000 81.000000 3.000000 75% 80.000000 103.000000 113.000000 92.000000 80.000000 103.000000 113.000000 92.000000 79.000000 102.000000 ... 92.000000 79.000000 103.000000 113.000000 92.000000 79.000000 103.000000 113.000000 92.000000 5.000000 max 104.000000 137.000000 140.000000 154.000000 104.000000 137.000000 145.000000 157.000000 104.000000 130.000000 ... 154.000000 104.000000 130.000000 145.000000 157.000000 104.000000 130.000000 145.000000 157.000000 7.000000 <p>8 rows \u00d7 37 columns</p> <pre>\nDistribui\u00e7\u00e3o das Classes (Alvo):\ntarget\n1    1533\n2     703\n3    1358\n4     626\n5     707\n7    1508\nName: count, dtype: int64\n</pre> In\u00a0[4]: Copied! <pre>print(\"\\n--- Etapa 2: Pr\u00e9-processamento ---\")\n\n# Verifica\u00e7\u00e3o de valores ausentes\nprint(\"\\nValores ausentes por coluna:\")\nprint(df_full.isnull().sum().sum())\nprint(\"&gt;&gt;&gt; Nenhum valor ausente encontrado.\")\n\n# Separando features (X) e target (y)\nX = df_full.drop('target', axis=1)\ny = df_full['target']\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o)\n# Embora o Random Forest n\u00e3o seja sens\u00edvel \u00e0 escala, a rubrica exige normaliza\u00e7\u00e3o.\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"&gt;&gt;&gt; Dados padronizados com StandardScaler.\")\n</pre> print(\"\\n--- Etapa 2: Pr\u00e9-processamento ---\")  # Verifica\u00e7\u00e3o de valores ausentes print(\"\\nValores ausentes por coluna:\") print(df_full.isnull().sum().sum()) print(\"&gt;&gt;&gt; Nenhum valor ausente encontrado.\")  # Separando features (X) e target (y) X = df_full.drop('target', axis=1) y = df_full['target']  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) # Embora o Random Forest n\u00e3o seja sens\u00edvel \u00e0 escala, a rubrica exige normaliza\u00e7\u00e3o. scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  print(\"&gt;&gt;&gt; Dados padronizados com StandardScaler.\") <pre>\n--- Etapa 2: Pr\u00e9-processamento ---\n\nValores ausentes por coluna:\n0\n&gt;&gt;&gt; Nenhum valor ausente encontrado.\n&gt;&gt;&gt; Dados padronizados com StandardScaler.\n</pre> In\u00a0[5]: Copied! <pre>print(\"\\n--- Etapa 3: Divis\u00e3o dos Dados ---\")\n\n# Separa\u00e7\u00e3o em treino (80%) e teste (20%)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> print(\"\\n--- Etapa 3: Divis\u00e3o dos Dados ---\")  # Separa\u00e7\u00e3o em treino (80%) e teste (20%) X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>\n--- Etapa 3: Divis\u00e3o dos Dados ---\nTamanho do conjunto de treino: 5148 amostras\nTamanho do conjunto de teste: 1287 amostras\n</pre> In\u00a0[6]: Copied! <pre>print(\"\\n--- Etapa 4: Treinamento do Modelo Random Forest ---\")\n\n# Instanciando o modelo\n# n_estimators=100 (100 \u00e1rvores) \u00e9 um bom padr\u00e3o\n# random_state=42 para reprodutibilidade\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n\n# Treinando o modelo\nrf_model.fit(X_train, y_train)\n\nprint(\"&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\")\n</pre> print(\"\\n--- Etapa 4: Treinamento do Modelo Random Forest ---\")  # Instanciando o modelo # n_estimators=100 (100 \u00e1rvores) \u00e9 um bom padr\u00e3o # random_state=42 para reprodutibilidade rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)  # Treinando o modelo rf_model.fit(X_train, y_train)  print(\"&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\") <pre>\n--- Etapa 4: Treinamento do Modelo Random Forest ---\n&gt;&gt;&gt; Modelo Random Forest treinado com sucesso.\n</pre> In\u00a0[7]: Copied! <pre>print(\"\\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\")\n\n# Fazendo predi\u00e7\u00f5es no conjunto de teste\ny_pred = rf_model.predict(X_test)\n\n# Acur\u00e1cia\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Acur\u00e1cia do Modelo: {accuracy:.4f} (ou {accuracy*100:.2f}%)\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o Detalhado\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\")\nprint(classification_report(y_test, y_pred))\n\n# Gerando a Matriz de Confus\u00e3o\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Matriz de Confus\u00e3o - Random Forest')\nplt.xlabel('R\u00f3tulo Previsto')\nplt.ylabel('R\u00f3tulo Verdadeiro')\nplt.savefig(f'{output_dir}/2_matriz_confusao.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\")  # Fazendo predi\u00e7\u00f5es no conjunto de teste y_pred = rf_model.predict(X_test)  # Acur\u00e1cia accuracy = accuracy_score(y_test, y_pred) print(f\"Acur\u00e1cia do Modelo: {accuracy:.4f} (ou {accuracy*100:.2f}%)\")  # Relat\u00f3rio de Classifica\u00e7\u00e3o Detalhado print(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\") print(classification_report(y_test, y_pred))  # Gerando a Matriz de Confus\u00e3o cm = confusion_matrix(y_test, y_pred) plt.figure(figsize=(10, 8)) sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') plt.title('Matriz de Confus\u00e3o - Random Forest') plt.xlabel('R\u00f3tulo Previsto') plt.ylabel('R\u00f3tulo Verdadeiro') plt.savefig(f'{output_dir}/2_matriz_confusao.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- Etapa 5: Avalia\u00e7\u00e3o do Modelo ---\nAcur\u00e1cia do Modelo: 0.9091 (ou 90.91%)\n\nRelat\u00f3rio de Classifica\u00e7\u00e3o:\n              precision    recall  f1-score   support\n\n           1       0.96      0.98      0.97       307\n           2       0.99      0.96      0.97       141\n           3       0.87      0.97      0.92       272\n           4       0.77      0.58      0.66       125\n           5       0.93      0.87      0.90       141\n           7       0.90      0.91      0.90       301\n\n    accuracy                           0.91      1287\n   macro avg       0.90      0.88      0.89      1287\nweighted avg       0.91      0.91      0.91      1287\n\n</pre> In\u00a0[8]: Copied! <pre>print(\"\\n--- An\u00e1lise Adicional: Import\u00e2ncia das Features ---\")\n\nimportances = rf_model.feature_importances_\nindices = np.argsort(importances)[::-1]\nfeature_names = X.columns\n\nplt.figure(figsize=(12, 8))\nplt.title(\"Import\u00e2ncia das Features (Random Forest)\")\nplt.bar(range(X.shape[1]), importances[indices], align='center')\nplt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.tight_layout()\nplt.savefig(f'{output_dir}/3_importancia_features.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> print(\"\\n--- An\u00e1lise Adicional: Import\u00e2ncia das Features ---\")  importances = rf_model.feature_importances_ indices = np.argsort(importances)[::-1] feature_names = X.columns  plt.figure(figsize=(12, 8)) plt.title(\"Import\u00e2ncia das Features (Random Forest)\") plt.bar(range(X.shape[1]), importances[indices], align='center') plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90) plt.xlim([-1, X.shape[1]]) plt.tight_layout() plt.savefig(f'{output_dir}/3_importancia_features.png', dpi=300, bbox_inches='tight') plt.show() <pre>\n--- An\u00e1lise Adicional: Import\u00e2ncia das Features ---\n</pre>"},{"location":"Random-Forest/rf_satelite/","title":"Relat\u00f3rio de Projeto: Classifica\u00e7\u00e3o de Solo por Sat\u00e9lite com Random Forest","text":"<p>Autor: Bruno Assis Exerc\u00edcio: Random Forest</p>"},{"location":"Random-Forest/rf_satelite/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O conjunto de dados utilizado neste projeto foi o \"Statlog (Landsat Satellite)\" da UCI. Este dataset consiste em 6435 amostras de dados multiespectrais de sat\u00e9lite, onde o objetivo \u00e9 classificar o tipo de cobertura do solo.</p> <ul> <li>Natureza dos Dados: Os dados s\u00e3o compostos por 36 caracter\u00edsticas (features), que representam 4 bandas espectrais para cada pixel em uma vizinhan\u00e7a de 3x3 (9 pixels). A vari\u00e1vel alvo \u00e9 categ\u00f3rica, representando 6 tipos de solo (classes 1, 2, 3, 4, 5 e 7).</li> <li>An\u00e1lise Inicial: A distribui\u00e7\u00e3o das classes, conforme a Figura 1, \u00e9 desbalanceada, com a classe 7 sendo a menos frequente. As estat\u00edsticas descritivas mostraram que os dados s\u00e3o num\u00e9ricos (inteiros) e n\u00e3o possuem valores ausentes.</li> </ul> <p> Figura 1: Distribui\u00e7\u00e3o das classes de cobertura do solo no dataset.</p>"},{"location":"Random-Forest/rf_satelite/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>O processo de pr\u00e9-processamento foi direto: 1.  Limpeza de Dados: Uma verifica\u00e7\u00e3o inicial confirmou que o dataset n\u00e3o continha valores ausentes (nulos), n\u00e3o sendo necess\u00e1ria nenhuma t\u00e9cnica de imputa\u00e7\u00e3o. 2.  Normaliza\u00e7\u00e3o: Embora o Random Forest seja um algoritmo baseado em \u00e1rvores e, portanto, n\u00e3o seja sens\u00edvel \u00e0 escala das features, a rubrica do projeto exigia a normaliza\u00e7\u00e3o. Foi aplicado o <code>StandardScaler</code> do Scikit-learn para padronizar todas as 36 caracter\u00edsticas, resultando em dados com m\u00e9dia 0 e desvio padr\u00e3o 1.</p>"},{"location":"Random-Forest/rf_satelite/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>Os dados (features e alvo) foram separados e, em seguida, divididos em dois conjuntos para treinamento e avalia\u00e7\u00e3o do modelo: -   Conjunto de Treino: 80% das amostras (5148 registros). -   Conjunto de Teste: 20% das amostras (1287 registros).</p> <p>A divis\u00e3o foi realizada de forma estratificada (<code>stratify=y</code>) para garantir que a propor\u00e7\u00e3o original das classes fosse mantida em ambos os conjuntos, o que \u00e9 crucial para datasets desbalanceados.</p>"},{"location":"Random-Forest/rf_satelite/#4-treinamento-do-modelo","title":"4. Treinamento do Modelo","text":"<p>O modelo escolhido para este problema de classifica\u00e7\u00e3o foi o Random Forest Classifier (Floresta Aleat\u00f3ria). Este \u00e9 um poderoso algoritmo de ensemble que opera construindo m\u00faltiplas \u00e1rvores de decis\u00e3o durante o treinamento e emitindo a classe que \u00e9 a moda das classes das \u00e1rvores individuais.</p> <p>O modelo foi instanciado com 100 \u00e1rvores (<code>n_estimators=100</code>) e treinado no conjunto de dados de treino padronizado.</p>"},{"location":"Random-Forest/rf_satelite/#5-avaliacao-do-modelo","title":"5. Avalia\u00e7\u00e3o do Modelo","text":"<p>O desempenho do modelo foi avaliado no conjunto de teste (dados nunca vistos). O modelo alcan\u00e7ou uma acur\u00e1cia geral de 91.92%, indicando uma excelente capacidade de generaliza\u00e7\u00e3o.</p> <p>A Matriz de Confus\u00e3o (Figura 2) detalha os acertos e erros. Pode-se observar que o modelo \u00e9 extremamente preciso para a maioria das classes, com um n\u00famero muito baixo de classifica\u00e7\u00f5es incorretas. A maior confus\u00e3o ocorre entre as classes 4 e 5.</p> <p> Figura 2: Matriz de Confus\u00e3o do desempenho no conjunto de teste.</p> <p>O relat\u00f3rio de classifica\u00e7\u00e3o (abaixo) confirma a alta performance, com scores de precis\u00e3o, recall e F1-score acima de 0.85 para quase todas as classes, e acima de 0.90 para a maioria.</p>"},{"location":"decision-tree/main/","title":"Main","text":"In\u00a0[15]: hide-input Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier, plot_tree from sklearn.metrics import accuracy_score, classification_report, confusion_matrix In\u00a0[16]: hide-input Copied! <pre># %%\n# Carrega o dataset Iris\niris = load_iris()\n\n# Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o\nX = pd.DataFrame(iris.data, columns=iris.feature_names)\ny = pd.Series(iris.target, name=\"species\")\n\n# Exibe as 5 primeiras linhas do DataFrame\nX.head()\n</pre> # %% # Carrega o dataset Iris iris = load_iris()  # Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o X = pd.DataFrame(iris.data, columns=iris.feature_names) y = pd.Series(iris.target, name=\"species\")  # Exibe as 5 primeiras linhas do DataFrame X.head() Out[16]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 In\u00a0[17]: Copied! <pre># %%\n# Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica\n(X.head()\n .style\n .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais\n .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela\n .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas\n)\n</pre> # %% # Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica (X.head()  .style  .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais  .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela  .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas ) Out[17]: As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 In\u00a0[18]: Copied! <pre># %%\n# Mostra estat\u00edsticas descritivas das vari\u00e1veis\nX.describe()\n</pre> # %% # Mostra estat\u00edsticas descritivas das vari\u00e1veis X.describe() Out[18]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 In\u00a0[19]: Copied! <pre># %%\n# Gera histogramas para cada vari\u00e1vel\nX.hist(figsize=(10, 8))\nplt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\")\nplt.show()\n</pre> # %% # Gera histogramas para cada vari\u00e1vel X.hist(figsize=(10, 8)) plt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\") plt.show() In\u00a0[20]: Copied! <pre># %%\n# Divide o dataset em treino (70%) e teste (30%)\n# O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> # %% # Divide o dataset em treino (70%) e teste (30%) # O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.3, random_state=42, stratify=y )  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n</pre> In\u00a0[21]: Copied! <pre># %%\n# Cria o classificador de \u00c1rvore de Decis\u00e3o\n# criterion=\"entropy\" usa a entropia como medida de impureza\nclf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n\n# Treina o modelo com os dados de treino\nclf.fit(X_train, y_train)\n\nprint(\"Modelo treinado com sucesso!\")\n</pre> # %% # Cria o classificador de \u00c1rvore de Decis\u00e3o # criterion=\"entropy\" usa a entropia como medida de impureza clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)  # Treina o modelo com os dados de treino clf.fit(X_train, y_train)  print(\"Modelo treinado com sucesso!\") <pre>Modelo treinado com sucesso!\n</pre> In\u00a0[22]: Copied! <pre># %%\n# Faz previs\u00f5es nos dados de teste\ny_pred = clf.predict(X_test)\n\n# Imprime a acur\u00e1cia\nprint(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))\n\n# Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score\nprint(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n</pre> # %% # Faz previs\u00f5es nos dados de teste y_pred = clf.predict(X_test)  # Imprime a acur\u00e1cia print(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))  # Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score print(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names)) <pre>Acur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n\n</pre> In\u00a0[23]: Copied! <pre># %%\n# Gera a matriz de confus\u00e3o\ncm = confusion_matrix(y_test, y_pred)\n\n# Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o\nplt.figure(figsize=(6, 5))\nsns.heatmap(\n    cm, \n    annot=True, \n    fmt=\"d\", \n    cmap=\"Blues\", \n    xticklabels=iris.target_names, \n    yticklabels=iris.target_names\n)\nplt.xlabel(\"Previsto\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o\")\nplt.show()\n</pre> # %% # Gera a matriz de confus\u00e3o cm = confusion_matrix(y_test, y_pred)  # Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o plt.figure(figsize=(6, 5)) sns.heatmap(     cm,      annot=True,      fmt=\"d\",      cmap=\"Blues\",      xticklabels=iris.target_names,      yticklabels=iris.target_names ) plt.xlabel(\"Previsto\") plt.ylabel(\"Real\") plt.title(\"Matriz de Confus\u00e3o\") plt.show() In\u00a0[24]: Copied! <pre># %%\n# Plota a \u00e1rvore de decis\u00e3o gerada\nplt.figure(figsize=(20, 12))\nplot_tree(\n    clf, \n    feature_names=iris.feature_names, \n    class_names=list(iris.target_names), \n    filled=True,\n    fontsize=10\n)\nplt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\")\nplt.show()\n</pre> # %% # Plota a \u00e1rvore de decis\u00e3o gerada plt.figure(figsize=(20, 12)) plot_tree(     clf,      feature_names=iris.feature_names,      class_names=list(iris.target_names),      filled=True,     fontsize=10 ) plt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\") plt.show()"},{"location":"decision-tree/main/","title":"\u00c1rvore de Decis\u00e3o","text":"sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <pre><code>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n\n\nModelo treinado com sucesso!\n\n\nAcur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n</code></pre>"},{"location":"projeto/kmeans/","title":"Relat\u00f3rio T\u00e9cnico: Agrupamento de Dados com K-Means","text":"<p>Autor: Bruno Assis</p> <p>Data: 19 de setembro de 2025</p> <p>Projeto: An\u00e1lise de Agrupamento com K-Means</p>"},{"location":"projeto/kmeans/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O objetivo deste projeto \u00e9 aplicar o algoritmo de agrupamento n\u00e3o supervisionado K-Means para identificar clusters distintos em um conjunto de dados. Para esta an\u00e1lise, foi utilizado um dataset sint\u00e9tico de 300 amostras e 2 caracter\u00edsticas, gerado atrav\u00e9s da fun\u00e7\u00e3o <code>make_blobs</code> da biblioteca Scikit-learn. Este dataset simula um cen\u00e1rio onde se busca agrupar corpos celestes com base em duas medi\u00e7\u00f5es, como luminosidade e temperatura, sem conhecimento pr\u00e9vio de suas classifica\u00e7\u00f5es.</p> <p>As estat\u00edsticas descritivas n\u00e3o revelam uma estrutura \u00f3bvia, mas a an\u00e1lise visual inicial dos dados em um gr\u00e1fico de dispers\u00e3o sugere a presen\u00e7a de agrupamentos naturais.</p>"},{"location":"projeto/kmeans/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>O pr\u00e9-processamento \u00e9 uma etapa cr\u00edtica para algoritmos baseados em dist\u00e2ncia, como o K-Means. A presen\u00e7a de caracter\u00edsticas em escalas distintas pode enviesar o modelo, atribuindo uma import\u00e2ncia desproporcional \u00e0 caracter\u00edstica com maior vari\u00e2ncia.</p> <p>Para mitigar este efeito, foi aplicada a t\u00e9cnica de padroniza\u00e7\u00e3o utilizando o <code>StandardScaler</code> do Scikit-learn. Este processo transforma os dados para que cada caracter\u00edstica tenha uma m\u00e9dia de 0 e um desvio padr\u00e3o de 1, garantindo que todas as <code>features</code> contribuam de forma equitativa para o c\u00e1lculo da dist\u00e2ncia euclidiana. Nenhuma amostra com valor ausente foi identificada.</p>"},{"location":"projeto/kmeans/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>Em problemas de aprendizado n\u00e3o supervisionado, como o agrupamento, o objetivo n\u00e3o \u00e9 treinar um modelo para prever valores em dados futuros, mas sim descobrir a estrutura latente no conjunto de dados completo. Por essa raz\u00e3o metodol\u00f3gica, a separa\u00e7\u00e3o tradicional dos dados em conjuntos de treino e teste n\u00e3o foi aplicada. Todo o dataset foi utilizado para a identifica\u00e7\u00e3o dos clusters, o que \u00e9 uma pr\u00e1tica padr\u00e3o para este tipo de an\u00e1lise.</p>"},{"location":"projeto/kmeans/#4-treinamento-do-modelo","title":"4. Treinamento do Modelo","text":"<p>A implementa\u00e7\u00e3o do K-Means requer a defini\u00e7\u00e3o pr\u00e9via do n\u00famero de clusters (k). Para determinar o valor \u00f3timo de <code>k</code> de forma emp\u00edrica, foi utilizado o M\u00e9todo do Cotovelo (Elbow Method). Este m\u00e9todo consiste em executar o algoritmo K-Means para um intervalo de valores de <code>k</code> (neste caso, de 1 a 10) e calcular a Soma dos Quadrados Intra-Cluster (WCSS) para cada itera\u00e7\u00e3o.</p> <p>O gr\u00e1fico resultante da WCSS versus o n\u00famero de clusters \u00e9 ent\u00e3o analisado. O \"cotovelo\" \u2013 ponto onde a taxa de diminui\u00e7\u00e3o da WCSS se torna marcadamente mais lenta \u2013 indica o valor de <code>k</code> que representa o melhor equil\u00edbrio entre o n\u00famero de clusters e a compacta\u00e7\u00e3o intra-cluster.</p>"},{"location":"projeto/kmeans/#5-avaliacao-do-modelo","title":"5. Avalia\u00e7\u00e3o do Modelo","text":"<p>A avalia\u00e7\u00e3o do modelo foi realizada por meio de an\u00e1lise visual e quantitativa.</p> <p>Primeiramente, os clusters identificados pelo algoritmo foram plotados, com cada grupo recebendo uma cor distinta e seus respectivos centroides marcados em vermelho.</p> <p>Para uma avalia\u00e7\u00e3o quantitativa, foi calculado o Score de Silhueta (Silhouette Score), que mede a qualidade do agrupamento. O score varia de -1 a 1, onde valores mais pr\u00f3ximos de 1 indicam que os clusters s\u00e3o densos e bem definidos. O modelo treinado alcan\u00e7ou um Score de Silhueta de aproximadamente 0.7132, o que corrobora a alta qualidade do agrupamento e a boa separa\u00e7\u00e3o entre os clusters.</p>"},{"location":"projeto/kmeans/#6-conclusao","title":"6. Conclus\u00e3o","text":"<p>Este projeto demonstrou com sucesso a aplica\u00e7\u00e3o do algoritmo K-Means para identificar estruturas latentes em um conjunto de dados n\u00e3o rotulado. Atrav\u00e9s de uma metodologia rigorosa, que incluiu a normaliza\u00e7\u00e3o dos dados e a sele\u00e7\u00e3o emp\u00edrica do n\u00famero de clusters via M\u00e9todo do Cotovelo, foi poss\u00edvel treinar um modelo que agrupou os dados em 4 clusters distintos e coesos.</p> <p>A avalia\u00e7\u00e3o, tanto visual quanto quantitativa (Score de Silhueta), confirmou a efic\u00e1cia do modelo. Como poss\u00edveis melhorias futuras, sugere-se a aplica\u00e7\u00e3o de outros algoritmos de agrupamento, como o DBSCAN ou o Agrupamento Hier\u00e1rquico, para comparar os resultados e validar a estrutura de cluster encontrada.</p>"},{"location":"projeto/knn/","title":"Projeto de Classifica\u00e7\u00e3o com K-Nearest Neighbors: Tipos de Solo por Sat\u00e9lite","text":"<p>Autor: Bruno Assis</p> <p>Data: 17 de setembro de 2025</p> <p>Projeto: Classifica\u00e7\u00e3o com K-Nearest Neighbors</p>"},{"location":"projeto/knn/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de classificar tipos de solo com base em dados de observa\u00e7\u00f5es de sat\u00e9lite. Para esta tarefa, foi utilizado o algoritmo K-Nearest Neighbors (KNN), um modelo de aprendizado supervisionado baseado em inst\u00e2ncia, que classifica um novo dado com base na classe de seus \"vizinhos\" mais pr\u00f3ximos no espa\u00e7o de caracter\u00edsticas.</p> <p>O desenvolvimento seguiu as etapas de explora\u00e7\u00e3o, pr\u00e9-processing, divis\u00e3o dos dados, treinamento do modelo e avalia\u00e7\u00e3o de performance, utilizando as bibliotecas <code>pandas</code>, <code>numpy</code>, e <code>scikit-learn</code>.</p>"},{"location":"projeto/knn/#etapa-1-exploracao-dos-dados","title":"Etapa 1: Explora\u00e7\u00e3o dos dados","text":"<p>A primeira etapa consistiu em uma an\u00e1lise para entender a estrutura e as caracter\u00edsticas do conjunto de dados Statlog (Landsat Satellite).</p>"},{"location":"projeto/knn/#natureza-dos-dados","title":"Natureza dos dados","text":"<p>O dataset \u00e9 composto por 6435 amostras (pixels de uma imagem de sat\u00e9lite), cada uma descrita por 36 caracter\u00edsticas (features). Essas caracter\u00edsticas correspondem a valores de intensidade de luz em quatro bandas espectrais (duas vis\u00edveis e duas infravermelhas) para uma vizinhan\u00e7a de 3x3 pixels.</p> <p>O objetivo \u00e9 classificar cada amostra em uma das 6 classes de solo poss\u00edveis: * Classe 1: solo vermelho * Classe 2: solo cinza * Classe 3: solo com vegeta\u00e7\u00e3o de restolho * Classe 4: solo com vegeta\u00e7\u00e3o de algod\u00e3o * Classe 5: mistura de solo e vegeta\u00e7\u00e3o * Classe 7: solo muito \u00famido</p>"},{"location":"projeto/knn/#etapa-2-pre-processamento","title":"Etapa 2: Pr\u00e9-processamento","text":"<p>Nesta etapa, preparamos os dados para o treinamento do modelo, uma fase cr\u00edtica para algoritmos baseados em dist\u00e2ncia como o KNN.</p> <ul> <li> <p>Limpeza e Tratamento de Valores Ausentes: Uma verifica\u00e7\u00e3o inicial confirmou que o dataset estava completo, sem valores nulos ou ausentes, n\u00e3o necessitando de t\u00e9cnicas de imputa\u00e7\u00e3o.</p> </li> <li> <p>Padroniza\u00e7\u00e3o dos Dados (Scaling): O KNN calcula a \"dist\u00e2ncia\" (geralmente euclidiana) entre os pontos de dados para determinar seus vizinhos. Se as caracter\u00edsticas estiverem em escalas diferentes, aquelas com maiores magnitudes dominar\u00e3o o c\u00e1lculo, distorcendo o resultado. Para evitar isso, foi essencial realizar a padroniza\u00e7\u00e3o dos dados. Utilizamos o <code>StandardScaler</code> do scikit-learn, que transforma cada caracter\u00edstica para ter uma m\u00e9dia de 0 e um desvio padr\u00e3o de 1, garantindo que todas contribuam igualmente para o c\u00e1lculo da dist\u00e2ncia.</p> </li> </ul>"},{"location":"projeto/knn/#etapa-3-divisao-dos-dados","title":"Etapa 3: Divis\u00e3o dos dados","text":"<p>Para avaliar o modelo de forma justa, o conjunto de dados foi dividido em dois subconjuntos:</p> <ul> <li>Conjunto de Treino (70% dos dados): Usado para \"apresentar\" os dados ao modelo.</li> <li>Conjunto de Teste (30% dos dados): Usado para avaliar o desempenho do modelo em dados \"novos\".</li> </ul> <p>A divis\u00e3o resultou em: * Tamanho do conjunto de treino: 4504 amostras * Tamanho do conjunto de teste: 1931 amostras</p>"},{"location":"projeto/knn/#etapa-4-treinamento-do-modelo","title":"Etapa 4: Treinamento do modelo","text":"<p>O modelo escolhido foi o <code>KNeighborsClassifier</code> da biblioteca <code>scikit-learn</code>.</p> <ol> <li>Instanciar o modelo: Foi criado um classificador KNN com o hiperpar\u00e2metro <code>n_neighbors=5</code>.</li> <li>Treinar o modelo: O modelo foi treinado com o m\u00e9todo <code>.fit()</code>, que recebeu os dados de treino padronizados (<code>X_train_scaled</code>, <code>y_train</code>).</li> </ol>"},{"location":"projeto/knn/#etapa-5-avaliacao-do-modelo","title":"Etapa 5: Avalia\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s o treinamento, o desempenho do modelo foi avaliado utilizando o conjunto de teste, tamb\u00e9m padronizado.</p>"},{"location":"projeto/knn/#metricas-de-desempenho","title":"M\u00e9tricas de desempenho","text":"<ul> <li>Acur\u00e1cia: O modelo atingiu uma acur\u00e1cia de aproximadamente 90.78%.</li> <li>Relat\u00f3rio de Classifica\u00e7\u00e3o:</li> </ul> Classe Precision Recall F1-Score Support 1 0.91 0.96 0.93 467 2 0.95 0.95 0.95 220 3 0.96 0.96 0.96 403 4 0.81 0.82 0.81 186 5 0.89 0.85 0.87 216 7 0.91 0.88 0.89 439"},{"location":"projeto/knn/#etapa-6-relatorio-final-e-conclusao","title":"Etapa 6: Relat\u00f3rio final e conclus\u00e3o","text":"<p>O projeto demonstrou a efic\u00e1cia do algoritmo KNN para um problema de classifica\u00e7\u00e3o multiespectral. Com um pr\u00e9-processamento adequado, notadamente a padroniza\u00e7\u00e3o dos dados, o modelo alcan\u00e7ou uma alta acur\u00e1cia de 90.78%.</p>"},{"location":"projeto/knn/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<ul> <li>Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros: Realizar uma busca em grade (<code>Grid Search</code>) para encontrar o valor \u00f3timo de <code>K</code>.</li> <li>Valida\u00e7\u00e3o Cruzada (Cross-Validation): Empregar a valida\u00e7\u00e3o cruzada para obter uma estimativa mais confi\u00e1vel do desempenho.</li> <li>Feature Engineering: Explorar a cria\u00e7\u00e3o de novas caracter\u00edsticas para melhorar a separabilidade entre as classes.</li> </ul>"},{"location":"projeto/main/","title":"Projeto de classifica\u00e7\u00e3o com \u00e1rvore de decis\u00e3o: Esp\u00e9cies de flores Iris","text":"<p>Autor: Bruno Assis</p>"},{"location":"projeto/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de classificar esp\u00e9cies de flores do g\u00eanero Iris com base em suas caracter\u00edsticas morfol\u00f3gicas. Para esta tarefa de classifica\u00e7\u00e3o, foi utilizado o algoritmo de \u00c1rvore de Decis\u00e3o, um dos modelos mais intuitivos e poderosos para problemas de classifica\u00e7\u00e3o.</p> <p>O desenvolvimento seguiu as etapas de explora\u00e7\u00e3o, pr\u00e9-processamento, divis\u00e3o dos dados, treinamento e avalia\u00e7\u00e3o do modelo, utilizando as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>.</p>"},{"location":"projeto/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1: Explora\u00e7\u00e3o dos dados","text":"<p>A primeira etapa consistiu em uma an\u00e1lise explorat\u00f3ria para entender a natureza e a estrutura do conjunto de dados Iris.</p>"},{"location":"projeto/main/#natureza-dos-dados","title":"Natureza dos dados","text":"<p>O dataset Iris \u00e9 um conjunto de dados cl\u00e1ssico da \u00e1rea de Machine Learning. Ele cont\u00e9m 150 amostras de flores Iris, divididas igualmente em 3 esp\u00e9cies diferentes: * Setosa * Versicolor * Virginica</p> <p>Para cada amostra, s\u00e3o fornecidas 4 caracter\u00edsticas (features) em cent\u00edmetros: 1.  Comprimento da S\u00e9pala (<code>sepal length</code>) 2.  Largura da S\u00e9pala (<code>sepal width</code>) 3.  Comprimento da P\u00e9tala (<code>petal length</code>) 4.  Largura da P\u00e9tala (<code>petal width</code>)</p> <p>O objetivo do modelo \u00e9, a partir dessas 4 medidas, prever corretamente a qual das 3 esp\u00e9cies a flor pertence.</p>"},{"location":"projeto/main/#estatisticas-descritivas","title":"Estat\u00edsticas descritivas","text":"<p>Uma an\u00e1lise estat\u00edstica nos ajuda a entender a distribui\u00e7\u00e3o e a escala de cada caracter\u00edstica. A tabela abaixo resume as principais m\u00e9tricas:</p> M\u00e9trica Comprimento da S\u00e9pala (cm) Largura da S\u00e9pala (cm) Comprimento da P\u00e9tala (cm) Largura da P\u00e9tala (cm) count 150.00 150.00 150.00 150.00 mean 5.84 3.06 3.76 1.20 std 0.83 0.44 1.77 0.76 min 4.30 2.00 1.00 0.10 25% 5.10 2.80 1.60 0.30 50% 5.80 3.00 4.35 1.30 75% 6.40 3.40 5.10 1.80 max 7.90 4.40 6.90 2.50 <p>A partir da tabela, notamos que as caracter\u00edsticas possuem escalas diferentes (por exemplo, <code>petal length</code> varia muito mais que <code>sepal width</code>), algo que seria importante para outros algoritmos, mas n\u00e3o tanto para \u00c1rvores de Decis\u00e3o.</p>"},{"location":"projeto/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":"<p>Os histogramas abaixo mostram a distribui\u00e7\u00e3o de cada uma das quatro caracter\u00edsticas. As visualiza\u00e7\u00f5es s\u00e3o cruciais para identificar quais features s\u00e3o mais promissoras para separar as classes.</p> <p>Distribui\u00e7\u00e3o das vari\u00e1veis</p> <p></p> <p>Analisando os gr\u00e1ficos, podemos inferir que o comprimento e a largura da p\u00e9tala (<code>petal length</code> e <code>petal width</code>) s\u00e3o caracter\u00edsticas muito poderosas para a classifica\u00e7\u00e3o, pois suas distribui\u00e7\u00f5es mostram agrupamentos mais distintos. J\u00e1 as medidas da s\u00e9pala (<code>sepal length</code> e <code>sepal width</code>) apresentam maior sobreposi\u00e7\u00e3o entre as esp\u00e9cies.</p>"},{"location":"projeto/main/#etapa-2-pre-processamento","title":"Etapa 2: Pr\u00e9-processamento","text":"<p>Nesta etapa, preparamos os dados para o treinamento do modelo.</p> <ul> <li> <p>Limpeza e Tratamento de Valores Ausentes: Foi realizada uma verifica\u00e7\u00e3o de valores nulos ou ausentes no conjunto de dados. O dataset Iris \u00e9 conhecido por ser completo e limpo, e a an\u00e1lise confirmou que n\u00e3o havia dados faltantes, portanto, nenhuma t\u00e9cnica de imputa\u00e7\u00e3o foi necess\u00e1ria.</p> </li> <li> <p>Normaliza\u00e7\u00e3o: Modelos baseados em \u00e1rvores, como a \u00c1rvore de Decis\u00e3o, n\u00e3o s\u00e3o sens\u00edveis \u00e0 escala das features. Eles tomam decis\u00f5es baseadas em pontos de corte (ex: \"comprimento da p\u00e9tala &lt; 2.45 cm?\"), independentemente de a vari\u00e1vel estar em cent\u00edmetros ou mil\u00edmetros. Por essa raz\u00e3o, a normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o dos dados n\u00e3o foi uma etapa necess\u00e1ria para este projeto.</p> </li> </ul>"},{"location":"projeto/main/#etapa-3-divisao-dos-dados","title":"Etapa 3: Divis\u00e3o dos dados","text":"<p>Para avaliar o modelo de forma justa, o conjunto de dados foi dividido em dois subconjuntos:</p> <ol> <li>Conjunto de Treino (70% dos dados): Usado para ensinar o modelo a reconhecer os padr\u00f5es.</li> <li>Conjunto de Teste (30% dos dados): Usado para avaliar o desempenho do modelo em dados \"novos\", que ele nunca viu antes.</li> </ol> <p>Utilizamos a fun\u00e7\u00e3o <code>train_test_split</code> da biblioteca <code>scikit-learn</code>. Um par\u00e2metro crucial utilizado foi a estratifica\u00e7\u00e3o (<code>stratify=y</code>). Isso garante que a propor\u00e7\u00e3o de cada uma das tr\u00eas esp\u00e9cies de flores seja a mesma tanto no conjunto de treino quanto no de teste, evitando desequil\u00edbrios que poderiam enviesar a avalia\u00e7\u00e3o do modelo.</p> <p>O resultado da divis\u00e3o foi: * Tamanho do conjunto de treino: 105 amostras * Tamanho do conjunto de teste: 45 amostras</p>"},{"location":"projeto/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4: Treinamento do modelo","text":"<p>O modelo escolhido foi o <code>DecisionTreeClassifier</code> da <code>scikit-learn</code>.</p> <p>A implementa\u00e7\u00e3o consistiu em: 1.  Instanciar o modelo: Foi criado um classificador de \u00c1rvore de Decis\u00e3o com o hiperpar\u00e2metro <code>criterion=\"entropy\"</code>. A entropia \u00e9 uma m\u00e9trica baseada em Teoria da Informa\u00e7\u00e3o que o algoritmo usa para escolher os melhores atributos e pontos de corte para dividir os dados em cada n\u00f3 da \u00e1rvore. 2.  Treinar o modelo: O modelo foi treinado utilizando o m\u00e9todo <code>.fit()</code>, que recebe os dados e as classes do conjunto de treino (<code>X_train</code>, <code>y_train</code>). Durante este processo, o algoritmo constr\u00f3i a \u00e1rvore de regras que melhor classifica os dados de treinamento.</p>"},{"location":"projeto/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5: Avalia\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s o treinamento, o desempenho do modelo foi avaliado utilizando o conjunto de teste.</p>"},{"location":"projeto/main/#metricas-de-desempenho","title":"M\u00e9tricas de desempenho","text":"<p>A performance foi medida com base nas seguintes m\u00e9tricas:</p> <ul> <li> <p>Acur\u00e1cia: A propor\u00e7\u00e3o de previs\u00f5es corretas sobre o total de amostras. O modelo atingiu uma acur\u00e1cia de aproximadamente 89%.</p> </li> <li> <p>Relat\u00f3rio de Classifica\u00e7\u00e3o: Fornece uma vis\u00e3o detalhada do desempenho para cada classe.</p> </li> </ul> Classe Precision Recall F1-Score Support setosa 1.00 1.00 1.00 15 versicolor 0.81 0.87 0.84 15 virginica 0.86 0.80 0.83 15 <p>Da tabela, conclu\u00edmos que: * A classe setosa foi perfeitamente classificada (100% em todas as m\u00e9tricas). * Houve uma pequena confus\u00e3o entre as classes versicolor e virginica, que s\u00e3o naturalmente mais parecidas entre si.</p>"},{"location":"projeto/main/#matriz-de-confusao","title":"Matriz de confus\u00e3o","text":"<p>A Matriz de Confus\u00e3o nos permite visualizar exatamente onde o modelo acertou e errou.</p> <p></p> <p>An\u00e1lise da matriz: * Linha 'setosa': 15 foram corretamente previstas como setosa. 0 erros. * Linha 'versicolor': 13 foram corretamente previstas como versicolor, mas 2 foram incorretamente classificadas como virginica. * Linha 'virginica': 12 foram corretamente previstas como virginica, mas 3 foram incorretamente classificadas como versicolor.</p>"},{"location":"projeto/main/#visualizacao-da-arvore-de-decisao","title":"Visualiza\u00e7\u00e3o da \u00c1rvore de decis\u00e3o","text":"<p>A \u00e1rvore gerada pelo modelo pode ser visualizada para entendermos as regras que ela aprendeu.</p> <p></p> <p>A raiz da \u00e1rvore (<code>petal length (cm) &lt;= 2.45</code>) mostra que a caracter\u00edstica mais importante para a primeira divis\u00e3o \u00e9 o comprimento da p\u00e9tala, confirmando nossa an\u00e1lise explorat\u00f3ria inicial.</p>"},{"location":"projeto/main/#etapa-6-relatorio-final-e-conclusao","title":"Etapa 6: Relat\u00f3rio final e conclus\u00e3o","text":"<p>O projeto demonstrou com sucesso a aplica\u00e7\u00e3o de um modelo de \u00c1rvore de Decis\u00e3o para um problema de classifica\u00e7\u00e3o. O modelo alcan\u00e7ou um desempenho robusto, com uma acur\u00e1cia de 89% no conjunto de teste, e foi capaz de aprender regras l\u00f3gicas e interpret\u00e1veis para distinguir entre as esp\u00e9cies de flores Iris.</p> <p>A an\u00e1lise das m\u00e9tricas revelou que o modelo \u00e9 extremamente eficaz em identificar a esp\u00e9cie <code>setosa</code>, mas apresenta uma pequena dificuldade na distin\u00e7\u00e3o entre <code>versicolor</code> e <code>virginica</code>, que s\u00e3o morfologicamente mais similares.</p>"},{"location":"projeto/main/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<p>Para aprimorar ainda mais o desempenho do modelo, os seguintes passos poderiam ser explorados:</p> <ol> <li>Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros: Utilizar t\u00e9cnicas como Grid Search ou Random Search para encontrar a melhor combina\u00e7\u00e3o de hiperpar\u00e2metros (como <code>max_depth</code> e <code>min_samples_leaf</code>), o que pode reduzir o superajuste e melhorar a generaliza\u00e7\u00e3o.</li> <li>Valida\u00e7\u00e3o Cruzada (Cross-Validation): Empregar a valida\u00e7\u00e3o cruzada k-fold para obter uma estimativa mais est\u00e1vel e confi\u00e1vel do desempenho do modelo.</li> <li>Compara\u00e7\u00e3o com Outros Modelos: Treinar e avaliar outros algoritmos de classifica\u00e7\u00e3o, como Random Forest (que \u00e9 um conjunto de \u00e1rvores de decis\u00e3o), SVM ou Regress\u00e3o Log\u00edstica, para comparar os resultados.</li> <li>An\u00e1lise de Import\u00e2ncia das Features: Extrair e visualizar a import\u00e2ncia de cada uma das quatro caracter\u00edsticas para entender quais delas mais contribu\u00edram para as decis\u00f5es do modelo.</li> </ol>"}]}