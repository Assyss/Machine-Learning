{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projetos","text":"<p>Por Bruno Assis</p> <p>Este portf\u00f3lio apresenta uma cole\u00e7\u00e3o de projetos onde aplico compet\u00eancias em Machine Learning, an\u00e1lise de dados e engenharia de dados para resolver desafios complexos. Cada projeto detalha uma abordagem end-to-end: desde a coleta e o pr\u00e9-processamento dos dados at\u00e9 a implementa\u00e7\u00e3o de modelos e a extra\u00e7\u00e3o de insights acion\u00e1veis.</p>"},{"location":"#projetos-disponiveis","title":"Projetos dispon\u00edveis","text":"<ul> <li> <p>Clusteriza\u00e7\u00e3o de Dados com K-Means</p> <p>Um projeto de aprendizado n\u00e3o supervisionado utilizando o algoritmo K-Means para identificar grupos (clusters) naturais em um conjunto de dados. A an\u00e1lise inclui a determina\u00e7\u00e3o do n\u00famero ideal de clusters atrav\u00e9s do M\u00e9todo do Cotovelo e a avalia\u00e7\u00e3o da qualidade do agrupamento.</p> <p> Ver Projeto</p> </li> </ul> <ul> <li> <p>Classifica\u00e7\u00e3o de Qualidade de Vinhos</p> <p>Um projeto completo de classifica\u00e7\u00e3o para prever a qualidade de vinhos com base em suas caracter\u00edsticas f\u00edsico-qu\u00edmicas. O estudo compara o desempenho de tr\u00eas algoritmos distintos: \u00c1rvore de Decis\u00e3o, KNN e o m\u00e9todo n\u00e3o supervisionado K-Means.</p> <p> Ver Projeto</p> </li> <li> <p>Classifica\u00e7\u00e3o de solo por sat\u00e9lite</p> <p>Um projeto de classifica\u00e7\u00e3o para determinar o tipo de solo a partir de dados multiespectrais de sat\u00e9lite, utilizando o algoritmo K-Nearest Neighbors (KNN). O processo inclui pr\u00e9-processamento, padroniza\u00e7\u00e3o de features e avalia\u00e7\u00e3o de performance.</p> <p> Ver Projeto</p> </li> </ul> <ul> <li> <p>Classifica\u00e7\u00e3o de flores iris</p> <p>Um estudo de caso cl\u00e1ssico utilizando o algoritmo de \u00c1rvore de Decis\u00e3o para classificar esp\u00e9cies de flores. Inclui a an\u00e1lise explorat\u00f3ria em notebook Jupyter e o relat\u00f3rio t\u00e9cnico completo do processo.</p> <p> Ver Projeto</p> </li> </ul>"},{"location":"K-MEANS/main/","title":"Main","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport seaborn as sns\n\nprint(\"Bibliotecas importadas com sucesso.\")\n</pre> import matplotlib.pyplot as plt import pandas as pd from sklearn.datasets import make_blobs from sklearn.preprocessing import StandardScaler from sklearn.cluster import KMeans from sklearn.metrics import silhouette_score import seaborn as sns  print(\"Bibliotecas importadas com sucesso.\") <pre>Bibliotecas importadas com sucesso.\n</pre> In\u00a0[2]: Copied! <pre># ETAPA 1: EXPLORA\u00c7\u00c3O DOS DADOS\n\n# Gera\u00e7\u00e3o de um conjunto de dados sint\u00e9tico para simular dados de sat\u00e9lites\nX, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.80, random_state=42)\n\n# Convertendo para um DataFrame do Pandas\ndf = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])\n\nprint(\"Cabe\u00e7alho do DataFrame:\")\ndisplay(df.head())\n\nprint(\"\\nEstat\u00edsticas Descritivas:\")\ndisplay(df.describe())\n</pre> # ETAPA 1: EXPLORA\u00c7\u00c3O DOS DADOS  # Gera\u00e7\u00e3o de um conjunto de dados sint\u00e9tico para simular dados de sat\u00e9lites X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.80, random_state=42)  # Convertendo para um DataFrame do Pandas df = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])  print(\"Cabe\u00e7alho do DataFrame:\") display(df.head())  print(\"\\nEstat\u00edsticas Descritivas:\") display(df.describe()) <pre>Cabe\u00e7alho do DataFrame:\n</pre> Feature_1 Feature_2 0 -9.205816 6.643647 1 -9.526658 7.015878 2 -1.851162 8.037611 3 -7.053772 -6.001088 4 -10.468827 6.517054 <pre>\nEstat\u00edsticas Descritivas:\n</pre> Feature_1 Feature_2 count 300.000000 300.000000 mean -3.402433 2.847806 std 5.253569 6.209243 min -10.815643 -8.511495 25% -7.953934 -0.992925 50% -4.866389 5.268670 75% -0.238470 8.042539 max 6.491606 10.984880 In\u00a0[10]: Copied! <pre># Visualiza\u00e7\u00e3o inicial dos dados n\u00e3o rotulados\nprint(\"Gerando visualiza\u00e7\u00e3o dos dados brutos...\")\nplt.figure(figsize=(10, 7))\nsns.scatterplot(x='Feature_1', y='Feature_2', data=df, s=50)\nplt.title('Visualiza\u00e7\u00e3o do Conjunto de Dados Sint\u00e9tico (N\u00e3o Rotulado)')\nplt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)')\nplt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)')\nplt.grid(True)\nplt.savefig('main_files/visualizacao_inicial.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # Visualiza\u00e7\u00e3o inicial dos dados n\u00e3o rotulados print(\"Gerando visualiza\u00e7\u00e3o dos dados brutos...\") plt.figure(figsize=(10, 7)) sns.scatterplot(x='Feature_1', y='Feature_2', data=df, s=50) plt.title('Visualiza\u00e7\u00e3o do Conjunto de Dados Sint\u00e9tico (N\u00e3o Rotulado)') plt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)') plt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)') plt.grid(True) plt.savefig('main_files/visualizacao_inicial.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando visualiza\u00e7\u00e3o dos dados brutos...\n</pre> In\u00a0[5]: Copied! <pre># ETAPA 2: PR\u00c9-PROCESSAMENTO\n\n# Verifica\u00e7\u00e3o de valores ausentes (embora saibamos que n\u00e3o h\u00e1 neste caso)\nprint(\"Verifica\u00e7\u00e3o de valores ausentes:\")\nprint(df.isnull().sum())\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados\nprint(\"\\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\")\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"Dados padronizados com sucesso.\")\n</pre> # ETAPA 2: PR\u00c9-PROCESSAMENTO  # Verifica\u00e7\u00e3o de valores ausentes (embora saibamos que n\u00e3o h\u00e1 neste caso) print(\"Verifica\u00e7\u00e3o de valores ausentes:\") print(df.isnull().sum())  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados print(\"\\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\") scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  print(\"Dados padronizados com sucesso.\") <pre>Verifica\u00e7\u00e3o de valores ausentes:\nFeature_1    0\nFeature_2    0\ndtype: int64\n\n&gt;&gt;&gt; Aplicando padroniza\u00e7\u00e3o (StandardScaler) aos dados...\nDados padronizados com sucesso.\n</pre> In\u00a0[11]: Copied! <pre># ETAPA 4 (PARTE 1): Descoberta do 'k' \u00f3timo\n\n# Calculando a in\u00e9rcia (WCSS) para diferentes valores de k\nwcss = []\nk_range = range(1, 11)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)\n    kmeans.fit(X_scaled)\n    wcss.append(kmeans.inertia_)\n\n# Plotando o gr\u00e1fico do M\u00e9todo do Cotovelo\nprint(\"Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\")\nplt.figure(figsize=(10, 7))\nplt.plot(k_range, wcss, marker='o', linestyle='--')\nplt.title('M\u00e9todo do Cotovelo (Elbow Method)')\nplt.xlabel('N\u00famero de Clusters (k)')\nplt.ylabel('WCSS (In\u00e9rcia)')\nplt.xticks(k_range)\nplt.grid(True)\nplt.savefig('main_files/metodo_cotovelo.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 4 (PARTE 1): Descoberta do 'k' \u00f3timo  # Calculando a in\u00e9rcia (WCSS) para diferentes valores de k wcss = [] k_range = range(1, 11)  for k in k_range:     kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)     kmeans.fit(X_scaled)     wcss.append(kmeans.inertia_)  # Plotando o gr\u00e1fico do M\u00e9todo do Cotovelo print(\"Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\") plt.figure(figsize=(10, 7)) plt.plot(k_range, wcss, marker='o', linestyle='--') plt.title('M\u00e9todo do Cotovelo (Elbow Method)') plt.xlabel('N\u00famero de Clusters (k)') plt.ylabel('WCSS (In\u00e9rcia)') plt.xticks(k_range) plt.grid(True) plt.savefig('main_files/metodo_cotovelo.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando gr\u00e1fico do M\u00e9todo do Cotovelo...\n</pre> In\u00a0[8]: Copied! <pre># ETAPA 4 (PARTE 2): Treinamento do modelo final\n\n# Definindo o k \u00f3timo com base no gr\u00e1fico anterior\nk_otimo = 4\nprint(f\"O n\u00famero \u00f3timo de clusters escolhido foi k = {k_otimo}.\")\n\n# Treinando o modelo final\nkmeans_final = KMeans(n_clusters=k_otimo, n_init='auto', random_state=42)\nkmeans_final.fit(X_scaled)\n\n# Capturando os r\u00f3tulos e os centroides\ncluster_labels = kmeans_final.labels_\ncentroids = kmeans_final.cluster_centers_\n\n# Adicionando os r\u00f3tulos dos clusters ao DataFrame\ndf['cluster'] = cluster_labels\n\nprint(\"Modelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\")\n</pre> # ETAPA 4 (PARTE 2): Treinamento do modelo final  # Definindo o k \u00f3timo com base no gr\u00e1fico anterior k_otimo = 4 print(f\"O n\u00famero \u00f3timo de clusters escolhido foi k = {k_otimo}.\")  # Treinando o modelo final kmeans_final = KMeans(n_clusters=k_otimo, n_init='auto', random_state=42) kmeans_final.fit(X_scaled)  # Capturando os r\u00f3tulos e os centroides cluster_labels = kmeans_final.labels_ centroids = kmeans_final.cluster_centers_  # Adicionando os r\u00f3tulos dos clusters ao DataFrame df['cluster'] = cluster_labels  print(\"Modelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\") <pre>O n\u00famero \u00f3timo de clusters escolhido foi k = 4.\nModelo K-Means treinado e r\u00f3tulos dos clusters atribu\u00eddos.\n</pre> In\u00a0[12]: Copied! <pre># ETAPA 5: AVALIA\u00c7\u00c3O DO MODELO\n\n# Visualiza\u00e7\u00e3o dos clusters encontrados pelo algoritmo\nprint(\"Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\")\nplt.figure(figsize=(10, 7))\nsns.scatterplot(x='Feature_1', y='Feature_2', hue='cluster', data=df, palette='viridis', s=50, legend='full')\n\n# Plotando os centroides (des-escalados para a escala original dos dados)\ncentroids_original_scale = scaler.inverse_transform(centroids)\nplt.scatter(centroids_original_scale[:, 0], centroids_original_scale[:, 1], s=200, c='red', marker='X', label='Centroides')\n\nplt.title(f'Clusters Encontrados pelo K-Means (k={k_otimo})')\nplt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)')\nplt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)')\nplt.legend()\nplt.grid(True)\nplt.savefig('main_files/clusters_finais.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n# Avalia\u00e7\u00e3o Quantitativa: Score de Silhueta (Silhouette Score)\nsilhouette_avg = silhouette_score(X_scaled, cluster_labels)\nprint(f\"\\nO Score de Silhueta para k={k_otimo} \u00e9: {silhouette_avg:.4f}\")\n</pre> # ETAPA 5: AVALIA\u00c7\u00c3O DO MODELO  # Visualiza\u00e7\u00e3o dos clusters encontrados pelo algoritmo print(\"Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\") plt.figure(figsize=(10, 7)) sns.scatterplot(x='Feature_1', y='Feature_2', hue='cluster', data=df, palette='viridis', s=50, legend='full')  # Plotando os centroides (des-escalados para a escala original dos dados) centroids_original_scale = scaler.inverse_transform(centroids) plt.scatter(centroids_original_scale[:, 0], centroids_original_scale[:, 1], s=200, c='red', marker='X', label='Centroides')  plt.title(f'Clusters Encontrados pelo K-Means (k={k_otimo})') plt.xlabel('Caracter\u00edstica 1 (ex: Luminosidade)') plt.ylabel('Caracter\u00edstica 2 (ex: Temperatura)') plt.legend() plt.grid(True) plt.savefig('main_files/clusters_finais.png', dpi=300, bbox_inches='tight') plt.show()   # Avalia\u00e7\u00e3o Quantitativa: Score de Silhueta (Silhouette Score) silhouette_avg = silhouette_score(X_scaled, cluster_labels) print(f\"\\nO Score de Silhueta para k={k_otimo} \u00e9: {silhouette_avg:.4f}\") <pre>Gerando visualiza\u00e7\u00e3o dos clusters encontrados...\n</pre> <pre>\nO Score de Silhueta para k=4 \u00e9: 0.8386\n</pre>"},{"location":"K-MEANS/main/","title":"An\u00e1lise Visual do Agrupamento K-Means","text":"<p>A seguir, s\u00e3o apresentados os resultados visuais chave do processo de clusteriza\u00e7\u00e3o, desde a explora\u00e7\u00e3o inicial dos dados at\u00e9 a avalia\u00e7\u00e3o final do modelo.</p>"},{"location":"K-MEANS/main/#1-visualizacao-inicial-dos-dados","title":"1. Visualiza\u00e7\u00e3o Inicial dos Dados","text":"<p>Gr\u00e1fico de dispers\u00e3o do conjunto de dados antes da aplica\u00e7\u00e3o de qualquer algoritmo. A distribui\u00e7\u00e3o sugere a presen\u00e7a de agrupamentos naturais, que buscaremos identificar.</p> <p></p>"},{"location":"K-MEANS/main/#2-determinacao-do-numero-de-clusters-metodo-do-cotovelo","title":"2. Determina\u00e7\u00e3o do N\u00famero de Clusters (M\u00e9todo do Cotovelo)","text":"<p>A curva de in\u00e9rcia (WCSS) foi plotada para diferentes valores de <code>k</code>. O \"cotovelo\" formado no gr\u00e1fico aponta <code>k=4</code> como o n\u00famero \u00f3timo de clusters para este conjunto de dados.</p> <p></p>"},{"location":"K-MEANS/main/#3-resultado-final-do-agrupamento","title":"3. Resultado Final do Agrupamento","text":"<p>Visualiza\u00e7\u00e3o dos 4 clusters identificados pelo algoritmo K-Means ap\u00f3s o treinamento. Cada cor representa um cluster distinto, e os marcadores 'X' em vermelho indicam os centroides finais de cada grupo.</p> <p></p>"},{"location":"KNN/main/","title":"Main","text":"In\u00a0[\u00a0]: Copied! <pre># 1. Importar as bibliotecas necess\u00e1rias\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nprint(\"Bibliotecas importadas com sucesso!\")\n</pre> # 1. Importar as bibliotecas necess\u00e1rias import numpy as np from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score, classification_report  print(\"Bibliotecas importadas com sucesso!\") <pre>Bibliotecas importadas com sucesso!\n</pre> In\u00a0[\u00a0]: Copied! <pre>print(\"Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\")\nsat_data = fetch_openml(name='satimage', version=1, as_frame=False, parser='liac-arff')\n\nX = sat_data.data\n\ny = sat_data.target.astype(np.float32).astype(np.int8)\n\nprint(\"\\nDados carregados com sucesso!\")\nprint(f\"Formato das caracter\u00edsticas (X): {X.shape}\")\nprint(f\"Formato dos r\u00f3tulos (y): {y.shape}\")\nprint(f\"Classes presentes no dataset: {np.unique(y)}\")\n</pre> print(\"Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\") sat_data = fetch_openml(name='satimage', version=1, as_frame=False, parser='liac-arff')  X = sat_data.data  y = sat_data.target.astype(np.float32).astype(np.int8)  print(\"\\nDados carregados com sucesso!\") print(f\"Formato das caracter\u00edsticas (X): {X.shape}\") print(f\"Formato dos r\u00f3tulos (y): {y.shape}\") print(f\"Classes presentes no dataset: {np.unique(y)}\") <pre>Carregando o dataset de sat\u00e9lite... Isso pode levar um momento.\n\nDados carregados com sucesso!\nFormato das caracter\u00edsticas (X): (6430, 36)\nFormato dos r\u00f3tulos (y): (6430,)\nClasses presentes no dataset: [1 2 3 4 5 7]\n</pre> In\u00a0[6]: Copied! <pre># 3. Dividir os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint(\"\\nDados divididos em conjuntos de treino e teste.\")\nprint(f\"Tamanho do treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do teste: {X_test.shape[0]} amostras\")\n</pre> # 3. Dividir os dados em treino e teste X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  print(\"\\nDados divididos em conjuntos de treino e teste.\") print(f\"Tamanho do treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do teste: {X_test.shape[0]} amostras\") <pre>\nDados divididos em conjuntos de treino e teste.\nTamanho do treino: 4501 amostras\nTamanho do teste: 1929 amostras\n</pre> In\u00a0[7]: Copied! <pre>scaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\n\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"\\nDados padronizados (scaling) com sucesso.\")\n</pre> scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)  print(\"\\nDados padronizados (scaling) com sucesso.\") <pre>\nDados padronizados (scaling) com sucesso.\n</pre> In\u00a0[8]: Copied! <pre>knn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train_scaled, y_train)\n\nprint(\"\\nModelo KNN criado e treinado com sucesso!\")\n</pre> knn = KNeighborsClassifier(n_neighbors=5)  knn.fit(X_train_scaled, y_train)  print(\"\\nModelo KNN criado e treinado com sucesso!\") <pre>\nModelo KNN criado e treinado com sucesso!\n</pre> In\u00a0[9]: Copied! <pre># 6. Fazer previs\u00f5es e Avaliar\ny_pred = knn.predict(X_test_scaled)\n\nprint(\"\\nPrevis\u00f5es feitas no conjunto de teste.\")\n\n# Avaliar a acur\u00e1cia\nacuracia = accuracy_score(y_test, y_pred)\nprint(f\"\\nA acur\u00e1cia do modelo \u00e9: {acuracia * 100:.2f}%\")\n\n# Um relat\u00f3rio mais detalhado\nprint(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\")\nprint(classification_report(y_test, y_pred))\n</pre> # 6. Fazer previs\u00f5es e Avaliar y_pred = knn.predict(X_test_scaled)  print(\"\\nPrevis\u00f5es feitas no conjunto de teste.\")  # Avaliar a acur\u00e1cia acuracia = accuracy_score(y_test, y_pred) print(f\"\\nA acur\u00e1cia do modelo \u00e9: {acuracia * 100:.2f}%\")  # Um relat\u00f3rio mais detalhado print(\"\\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\") print(classification_report(y_test, y_pred)) <pre>\nPrevis\u00f5es feitas no conjunto de teste.\n\nA acur\u00e1cia do modelo \u00e9: 91.14%\n\nRelat\u00f3rio de Classifica\u00e7\u00e3o Detalhado:\n              precision    recall  f1-score   support\n\n           1       0.96      0.98      0.97       447\n           2       0.99      0.97      0.98       238\n           3       0.91      0.93      0.92       403\n           4       0.71      0.68      0.69       186\n           5       0.92      0.88      0.90       215\n           7       0.90      0.90      0.90       440\n\n    accuracy                           0.91      1929\n   macro avg       0.90      0.89      0.89      1929\nweighted avg       0.91      0.91      0.91      1929\n\n</pre> In\u00a0[10]: Copied! <pre># --- C\u00e9lula para gerar e salvar a Matriz de Confus\u00e3o ---\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport os\n\nprint(\"Gerando a Matriz de Confus\u00e3o...\")\n\ncm = confusion_matrix(y_test, y_pred)\n\nclass_names = ['1', '2', '3', '4', '5', '7']\n\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names)\n\nplt.title('Matriz de Confus\u00e3o - Modelo KNN', fontsize=16)\nplt.ylabel('Classe Verdadeira', fontsize=12)\nplt.xlabel('Classe Prevista', fontsize=12)\n\nif not os.path.exists('main_files'):\n    os.makedirs('main_files')\n\ncaminho_imagem = 'main_files/matriz_confusao_knn.png'\nplt.savefig(caminho_imagem)\n\nprint(f\"Imagem da Matriz de Confus\u00e3o salva em: {caminho_imagem}\")\n\nplt.show()\n</pre> # --- C\u00e9lula para gerar e salvar a Matriz de Confus\u00e3o ---  import matplotlib.pyplot as plt import seaborn as sns from sklearn.metrics import confusion_matrix import os  print(\"Gerando a Matriz de Confus\u00e3o...\")  cm = confusion_matrix(y_test, y_pred)  class_names = ['1', '2', '3', '4', '5', '7']  plt.figure(figsize=(10, 8))  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',              xticklabels=class_names, yticklabels=class_names)  plt.title('Matriz de Confus\u00e3o - Modelo KNN', fontsize=16) plt.ylabel('Classe Verdadeira', fontsize=12) plt.xlabel('Classe Prevista', fontsize=12)  if not os.path.exists('main_files'):     os.makedirs('main_files')  caminho_imagem = 'main_files/matriz_confusao_knn.png' plt.savefig(caminho_imagem)  print(f\"Imagem da Matriz de Confus\u00e3o salva em: {caminho_imagem}\")  plt.show() <pre>Gerando a Matriz de Confus\u00e3o...\nImagem da Matriz de Confus\u00e3o salva em: main_files/matriz_confusao_knn.png\n</pre>"},{"location":"KNN/main/","title":"KNN","text":"<p>A Matriz de Confus\u00e3o nos ajuda a visualizar o desempenho do modelo, mostrando onde ele acertou e onde errou em suas previs\u00f5es para cada classe.</p> <p></p>"},{"location":"Projeto_I/analise_vinhos/","title":"Analise vinhos","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, silhouette_score, adjusted_rand_score\nfrom sklearn.datasets import load_iris\nimport warnings\nimport os\n\n# Ignorar avisos futuros para uma sa\u00edda mais limpa\nwarnings.filterwarnings('ignore')\n\n# Cria o diret\u00f3rio para salvar as imagens, se n\u00e3o existir\noutput_dir = 'outputs'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nprint(\"&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.tree import DecisionTreeClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.cluster import KMeans from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, silhouette_score, adjusted_rand_score from sklearn.datasets import load_iris import warnings import os  # Ignorar avisos futuros para uma sa\u00edda mais limpa warnings.filterwarnings('ignore')  # Cria o diret\u00f3rio para salvar as imagens, se n\u00e3o existir output_dir = 'outputs' if not os.path.exists(output_dir):     os.makedirs(output_dir)  print(\"&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\") <pre>&gt;&gt;&gt; Ambiente configurado. Bibliotecas importadas e pasta 'outputs' garantida.\n</pre> In\u00a0[\u00a0]: Copied! <pre># ETAPA 1 (PARTE 1): Carregamento dos Dados\n# URL ATUALIZADA para a fonte original e est\u00e1vel do dataset.\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n\n# O separador para este arquivo \u00e9 o ponto e v\u00edrgula (;)\ndf = pd.read_csv(url, sep=';')\n\nprint(\"Dataset carregado com sucesso.\")\ndisplay(df.head())\n</pre> # ETAPA 1 (PARTE 1): Carregamento dos Dados # URL ATUALIZADA para a fonte original e est\u00e1vel do dataset. url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'  # O separador para este arquivo \u00e9 o ponto e v\u00edrgula (;) df = pd.read_csv(url, sep=';')  print(\"Dataset carregado com sucesso.\") display(df.head()) <pre>Dataset carregado com sucesso.\n</pre> fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality 0 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5 1 7.8 0.88 0.00 2.6 0.098 25.0 67.0 0.9968 3.20 0.68 9.8 5 2 7.8 0.76 0.04 2.3 0.092 15.0 54.0 0.9970 3.26 0.65 9.8 5 3 11.2 0.28 0.56 1.9 0.075 17.0 60.0 0.9980 3.16 0.58 9.8 6 4 7.4 0.70 0.00 1.9 0.076 11.0 34.0 0.9978 3.51 0.56 9.4 5 In\u00a0[4]: Copied! <pre># ETAPA 1 (PARTE 2): An\u00e1lise Explorat\u00f3ria Textual\nprint(\"Informa\u00e7\u00f5es Gerais do DataFrame:\")\ndf.info()\n\nprint(\"\\nEstat\u00edsticas Descritivas:\")\ndisplay(df.describe())\n</pre> # ETAPA 1 (PARTE 2): An\u00e1lise Explorat\u00f3ria Textual print(\"Informa\u00e7\u00f5es Gerais do DataFrame:\") df.info()  print(\"\\nEstat\u00edsticas Descritivas:\") display(df.describe()) <pre>Informa\u00e7\u00f5es Gerais do DataFrame:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1599 entries, 0 to 1598\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   fixed acidity         1599 non-null   float64\n 1   volatile acidity      1599 non-null   float64\n 2   citric acid           1599 non-null   float64\n 3   residual sugar        1599 non-null   float64\n 4   chlorides             1599 non-null   float64\n 5   free sulfur dioxide   1599 non-null   float64\n 6   total sulfur dioxide  1599 non-null   float64\n 7   density               1599 non-null   float64\n 8   pH                    1599 non-null   float64\n 9   sulphates             1599 non-null   float64\n 10  alcohol               1599 non-null   float64\n 11  quality               1599 non-null   int64  \ndtypes: float64(11), int64(1)\nmemory usage: 150.0 KB\n\nEstat\u00edsticas Descritivas:\n</pre> fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality count 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 1599.000000 mean 8.319637 0.527821 0.270976 2.538806 0.087467 15.874922 46.467792 0.996747 3.311113 0.658149 10.422983 5.636023 std 1.741096 0.179060 0.194801 1.409928 0.047065 10.460157 32.895324 0.001887 0.154386 0.169507 1.065668 0.807569 min 4.600000 0.120000 0.000000 0.900000 0.012000 1.000000 6.000000 0.990070 2.740000 0.330000 8.400000 3.000000 25% 7.100000 0.390000 0.090000 1.900000 0.070000 7.000000 22.000000 0.995600 3.210000 0.550000 9.500000 5.000000 50% 7.900000 0.520000 0.260000 2.200000 0.079000 14.000000 38.000000 0.996750 3.310000 0.620000 10.200000 6.000000 75% 9.200000 0.640000 0.420000 2.600000 0.090000 21.000000 62.000000 0.997835 3.400000 0.730000 11.100000 6.000000 max 15.900000 1.580000 1.000000 15.500000 0.611000 72.000000 289.000000 1.003690 4.010000 2.000000 14.900000 8.000000 In\u00a0[5]: Copied! <pre># ETAPA 1 (PARTE 3): An\u00e1lise Explorat\u00f3ria Visual\nprint(\"Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\")\nplt.figure(figsize=(8, 6))\nsns.countplot(x='quality', data=df, palette='viridis')\nplt.title('Distribui\u00e7\u00e3o da Qualidade do Vinho (Original)')\n\n# Salvando a imagem\nplt.savefig(f'{output_dir}/1_distribuicao_qualidade.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 1 (PARTE 3): An\u00e1lise Explorat\u00f3ria Visual print(\"Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\") plt.figure(figsize=(8, 6)) sns.countplot(x='quality', data=df, palette='viridis') plt.title('Distribui\u00e7\u00e3o da Qualidade do Vinho (Original)')  # Salvando a imagem plt.savefig(f'{output_dir}/1_distribuicao_qualidade.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando gr\u00e1fico da distribui\u00e7\u00e3o da qualidade do vinho...\n</pre> In\u00a0[6]: Copied! <pre># ETAPA 1 (PARTE 4): An\u00e1lise Explorat\u00f3ria Visual\nprint(\"Gerando mapa de calor de correla\u00e7\u00f5es...\")\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\nplt.title('Mapa de Calor de Correla\u00e7\u00f5es entre as Vari\u00e1veis')\n\n# Salvando a imagem\nplt.savefig(f'{output_dir}/2_mapa_correlacao.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 1 (PARTE 4): An\u00e1lise Explorat\u00f3ria Visual print(\"Gerando mapa de calor de correla\u00e7\u00f5es...\") plt.figure(figsize=(12, 10)) sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm') plt.title('Mapa de Calor de Correla\u00e7\u00f5es entre as Vari\u00e1veis')  # Salvando a imagem plt.savefig(f'{output_dir}/2_mapa_correlacao.png', dpi=300, bbox_inches='tight') plt.show() <pre>Gerando mapa de calor de correla\u00e7\u00f5es...\n</pre> In\u00a0[7]: Copied! <pre># ETAPA 2: Pr\u00e9-processamento\nprint(\"Realizando engenharia de feature e padroniza\u00e7\u00e3o...\")\n# Criando a vari\u00e1vel alvo bin\u00e1ria (1 = Bom, 0 = Regular)\ndf['quality_category'] = df['quality'].apply(lambda x: 1 if x &gt;= 6 else 0)\ndf_processed = df.drop('quality', axis=1)\n\n# Separando features (X) e target (y)\nX = df_processed.drop('quality_category', axis=1)\ny = df_processed['quality_category']\n\n# Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"Pr\u00e9-processamento conclu\u00eddo.\")\nprint(\"Shape de X_scaled:\", X_scaled.shape)\n</pre> # ETAPA 2: Pr\u00e9-processamento print(\"Realizando engenharia de feature e padroniza\u00e7\u00e3o...\") # Criando a vari\u00e1vel alvo bin\u00e1ria (1 = Bom, 0 = Regular) df['quality_category'] = df['quality'].apply(lambda x: 1 if x &gt;= 6 else 0) df_processed = df.drop('quality', axis=1)  # Separando features (X) e target (y) X = df_processed.drop('quality_category', axis=1) y = df_processed['quality_category']  # Normaliza\u00e7\u00e3o (Padroniza\u00e7\u00e3o) dos dados scaler = StandardScaler() X_scaled = scaler.fit_transform(X)  print(\"Pr\u00e9-processamento conclu\u00eddo.\") print(\"Shape de X_scaled:\", X_scaled.shape) <pre>Realizando engenharia de feature e padroniza\u00e7\u00e3o...\nPr\u00e9-processamento conclu\u00eddo.\nShape de X_scaled: (1599, 11)\n</pre> In\u00a0[8]: Copied! <pre># ETAPA 3: Divis\u00e3o dos Dados\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> # ETAPA 3: Divis\u00e3o dos Dados X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>Tamanho do conjunto de treino: 1279 amostras\nTamanho do conjunto de teste: 320 amostras\n</pre> In\u00a0[9]: Copied! <pre># ETAPA 4: Treinamento dos Modelos\n\n# --- Modelo 1: \u00c1rvore de Decis\u00e3o ---\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\nprint(\"&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\")\n\n# --- Modelo 2: K-Vizinhos mais Pr\u00f3ximos (KNN) ---\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train, y_train)\nprint(\"&gt;&gt;&gt; Modelo KNN treinado.\")\n\n# --- Modelo 3: K-Means ---\nkmeans_model = KMeans(n_clusters=2, n_init='auto', random_state=42)\nkmeans_model.fit(X_train)\nprint(\"&gt;&gt;&gt; Modelo K-Means treinado.\")\n</pre> # ETAPA 4: Treinamento dos Modelos  # --- Modelo 1: \u00c1rvore de Decis\u00e3o --- dt_model = DecisionTreeClassifier(random_state=42) dt_model.fit(X_train, y_train) print(\"&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\")  # --- Modelo 2: K-Vizinhos mais Pr\u00f3ximos (KNN) --- knn_model = KNeighborsClassifier(n_neighbors=5) knn_model.fit(X_train, y_train) print(\"&gt;&gt;&gt; Modelo KNN treinado.\")  # --- Modelo 3: K-Means --- kmeans_model = KMeans(n_clusters=2, n_init='auto', random_state=42) kmeans_model.fit(X_train) print(\"&gt;&gt;&gt; Modelo K-Means treinado.\") <pre>&gt;&gt;&gt; Modelo \u00c1rvore de Decis\u00e3o treinado.\n&gt;&gt;&gt; Modelo KNN treinado.\n&gt;&gt;&gt; Modelo K-Means treinado.\n</pre> In\u00a0[10]: Copied! <pre># ETAPA 5 (PARTE 1): Avalia\u00e7\u00e3o dos Modelos Supervisionados\nprint(\"--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\")\ny_pred_dt = dt_model.predict(X_test)\nprint(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_dt):.4f}\")\nprint(classification_report(y_test, y_pred_dt, target_names=['Regular', 'Bom']))\n\nprint(\"\\n--- Avalia\u00e7\u00e3o: KNN ---\")\ny_pred_knn = knn_model.predict(X_test)\nprint(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_knn):.4f}\")\nprint(classification_report(y_test, y_pred_knn, target_names=['Regular', 'Bom']))\n\n# Matrizes de Confus\u00e3o para compara\u00e7\u00e3o\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\ncm_dt = confusion_matrix(y_test, y_pred_dt)\nsns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[0])\naxes[0].set_title('Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o')\naxes[0].set_xlabel('Previsto'); axes[0].set_ylabel('Verdadeiro')\ncm_knn = confusion_matrix(y_test, y_pred_knn)\nsns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[1])\naxes[1].set_title('Matriz de Confus\u00e3o - KNN')\naxes[1].set_xlabel('Previsto'); axes[1].set_ylabel('Verdadeiro')\n\nplt.tight_layout()\n# Salvando a imagem\nplt.savefig(f'{output_dir}/3_matrizes_confusao.png', dpi=300, bbox_inches='tight')\nplt.show()\n</pre> # ETAPA 5 (PARTE 1): Avalia\u00e7\u00e3o dos Modelos Supervisionados print(\"--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\") y_pred_dt = dt_model.predict(X_test) print(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_dt):.4f}\") print(classification_report(y_test, y_pred_dt, target_names=['Regular', 'Bom']))  print(\"\\n--- Avalia\u00e7\u00e3o: KNN ---\") y_pred_knn = knn_model.predict(X_test) print(f\"Acur\u00e1cia: {accuracy_score(y_test, y_pred_knn):.4f}\") print(classification_report(y_test, y_pred_knn, target_names=['Regular', 'Bom']))  # Matrizes de Confus\u00e3o para compara\u00e7\u00e3o fig, axes = plt.subplots(1, 2, figsize=(15, 5)) cm_dt = confusion_matrix(y_test, y_pred_dt) sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[0]) axes[0].set_title('Matriz de Confus\u00e3o - \u00c1rvore de Decis\u00e3o') axes[0].set_xlabel('Previsto'); axes[0].set_ylabel('Verdadeiro') cm_knn = confusion_matrix(y_test, y_pred_knn) sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens', xticklabels=['Regular', 'Bom'], yticklabels=['Regular', 'Bom'], ax=axes[1]) axes[1].set_title('Matriz de Confus\u00e3o - KNN') axes[1].set_xlabel('Previsto'); axes[1].set_ylabel('Verdadeiro')  plt.tight_layout() # Salvando a imagem plt.savefig(f'{output_dir}/3_matrizes_confusao.png', dpi=300, bbox_inches='tight') plt.show() <pre>--- Avalia\u00e7\u00e3o: \u00c1rvore de Decis\u00e3o ---\nAcur\u00e1cia: 0.7562\n              precision    recall  f1-score   support\n\n     Regular       0.74      0.73      0.74       149\n         Bom       0.77      0.78      0.77       171\n\n    accuracy                           0.76       320\n   macro avg       0.76      0.75      0.75       320\nweighted avg       0.76      0.76      0.76       320\n\n\n--- Avalia\u00e7\u00e3o: KNN ---\nAcur\u00e1cia: 0.7344\n              precision    recall  f1-score   support\n\n     Regular       0.71      0.72      0.72       149\n         Bom       0.75      0.75      0.75       171\n\n    accuracy                           0.73       320\n   macro avg       0.73      0.73      0.73       320\nweighted avg       0.73      0.73      0.73       320\n\n</pre> In\u00a0[11]: Copied! <pre># ETAPA 5 (PARTE 2): Avalia\u00e7\u00e3o do Modelo N\u00e3o Supervisionado\nprint(\"--- Avalia\u00e7\u00e3o: K-Means ---\")\nkmeans_clusters_test = kmeans_model.predict(X_test)\n\n# Score de Silhueta (qualidade intr\u00ednseca dos clusters)\nsilhouette = silhouette_score(X_test, kmeans_clusters_test)\nprint(f\"Score de Silhueta (nos dados de teste): {silhouette:.4f}\")\n\n# Adjusted Rand Score (comparando clusters com as classes reais)\nrand_score = adjusted_rand_score(y_test, kmeans_clusters_test)\nprint(f\"Adjusted Rand Score (comparando com r\u00f3tulos reais): {rand_score:.4f}\")\n</pre> # ETAPA 5 (PARTE 2): Avalia\u00e7\u00e3o do Modelo N\u00e3o Supervisionado print(\"--- Avalia\u00e7\u00e3o: K-Means ---\") kmeans_clusters_test = kmeans_model.predict(X_test)  # Score de Silhueta (qualidade intr\u00ednseca dos clusters) silhouette = silhouette_score(X_test, kmeans_clusters_test) print(f\"Score de Silhueta (nos dados de teste): {silhouette:.4f}\")  # Adjusted Rand Score (comparando clusters com as classes reais) rand_score = adjusted_rand_score(y_test, kmeans_clusters_test) print(f\"Adjusted Rand Score (comparando com r\u00f3tulos reais): {rand_score:.4f}\") <pre>--- Avalia\u00e7\u00e3o: K-Means ---\nScore de Silhueta (nos dados de teste): 0.2145\nAdjusted Rand Score (comparando com r\u00f3tulos reais): 0.0253\n</pre>"},{"location":"Projeto_I/relatorio_final/","title":"Projeto I: Modelagem Preditiva e Agrupamento para Qualidade de Vinhos","text":"<p>Autor: Bruno Assis Data: 30 de setembro de 2025 Reposit\u00f3rio: GitHub Link</p>"},{"location":"Projeto_I/relatorio_final/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O presente projeto tem como objetivo desenvolver e avaliar modelos de Machine Learning para um problema de classifica\u00e7\u00e3o utilizando um dataset real da plataforma Kaggle/UCI. O conjunto de dados escolhido foi o \"Red Wine Quality\", que cont\u00e9m 11 caracter\u00edsticas f\u00edsico-qu\u00edmicas de vinhos tintos e uma nota de qualidade.</p> <p>A an\u00e1lise explorat\u00f3ria inicial revelou a distribui\u00e7\u00e3o da vari\u00e1vel alvo <code>quality</code>, que varia de 3 a 8, concentrando-se principalmente nas notas 5 e 6.</p> <p> Figura 1: Distribui\u00e7\u00e3o da vari\u00e1vel 'quality' no dataset.</p> <p>Para entender a rela\u00e7\u00e3o entre as vari\u00e1veis, foi gerado um mapa de calor de correla\u00e7\u00f5es. Observou-se que a vari\u00e1vel <code>alcohol</code> (\u00e1lcool) possui a correla\u00e7\u00e3o positiva mais forte com a qualidade, enquanto <code>volatile acidity</code> (acidez vol\u00e1til) apresenta a correla\u00e7\u00e3o negativa mais acentuada.</p> <p> Figura 2: Correla\u00e7\u00e3o entre as caracter\u00edsticas do vinho.</p>"},{"location":"Projeto_I/relatorio_final/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>Com base na distribui\u00e7\u00e3o da qualidade, o problema foi transformado em uma classifica\u00e7\u00e3o bin\u00e1ria. Uma nova vari\u00e1vel, <code>quality_category</code>, foi criada, onde vinhos com nota maior ou igual a 6 foram classificados como \"Bons\" (1) e os demais como \"Regulares\" (0). Esta abordagem simplifica o modelo e cria um problema de classifica\u00e7\u00e3o mais balanceado.</p> <p>O dataset n\u00e3o apresentou valores ausentes.</p> <p>Por fim, todas as caracter\u00edsticas preditoras foram padronizadas utilizando o <code>StandardScaler</code> do Scikit-learn. Esta etapa \u00e9 fundamental para o desempenho de algoritmos baseados em dist\u00e2ncia, como KNN e K-Means, garantindo que todas as features contribuam de forma equitativa para o modelo.</p>"},{"location":"Projeto_I/relatorio_final/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>O conjunto de dados pr\u00e9-processado foi dividido em dois subconjuntos: -   80% para Treinamento: Utilizado para treinar os modelos. -   20% para Teste: Utilizado para avaliar o desempenho dos modelos em dados n\u00e3o vistos.</p> <p>A divis\u00e3o foi realizada de forma estratificada (<code>stratify=y</code>) para garantir que a propor\u00e7\u00e3o de vinhos \"Bons\" e \"Regulares\" fosse a mesma tanto no conjunto de treino quanto no de teste.</p>"},{"location":"Projeto_I/relatorio_final/#4-treinamento-dos-modelos","title":"4. Treinamento dos Modelos","text":"<p>Foram implementados tr\u00eas algoritmos distintos de Machine Learning:</p> <ol> <li>\u00c1rvore de Decis\u00e3o (<code>DecisionTreeClassifier</code>): Um modelo supervisionado baseado em regras, que divide os dados recursivamente com base nos valores das caracter\u00edsticas.</li> <li>K-Vizinhos Mais Pr\u00f3ximos (<code>KNeighborsClassifier</code>): Um modelo supervisionado baseado em inst\u00e2ncia, que classifica uma nova amostra com base na classe majorit\u00e1ria de seus <code>k</code> vizinhos mais pr\u00f3ximos. Foi utilizado <code>k=5</code>.</li> <li>K-Means (<code>KMeans</code>): Um modelo n\u00e3o supervisionado de agrupamento, que particiona os dados em <code>k</code> clusters. Foi utilizado <code>k=2</code> para verificar se o algoritmo conseguiria encontrar a estrutura de classes bin\u00e1rias (\"Bom\" vs. \"Regular\") sem ter acesso aos r\u00f3tulos.</li> </ol>"},{"location":"Projeto_I/relatorio_final/#5-avaliacao-dos-modelos","title":"5. Avalia\u00e7\u00e3o dos Modelos","text":"<p>A avalia\u00e7\u00e3o foi conduzida de forma distinta para os modelos supervisionados e n\u00e3o supervisionados.</p>"},{"location":"Projeto_I/relatorio_final/#modelos-supervisionados-arvore-de-decisao-vs-knn","title":"Modelos Supervisionados: \u00c1rvore de Decis\u00e3o vs. KNN","text":"<p>Ambos os modelos foram avaliados no conjunto de teste. A \u00c1rvore de Decis\u00e3o obteve um desempenho superior, com uma acur\u00e1cia de aproximadamente 77%, contra 72% do KNN. O relat\u00f3rio de classifica\u00e7\u00e3o detalha a performance para cada classe, e as matrizes de confus\u00e3o ilustram os acertos e erros de cada modelo.</p> <p> Figura 3: Matrizes de Confus\u00e3o para os modelos de \u00c1rvore de Decis\u00e3o e KNN.</p> <p>A an\u00e1lise indica que a \u00c1rvore de Decis\u00e3o foi mais eficaz em generalizar os padr\u00f5es para classificar a qualidade do vinho neste dataset.</p>"},{"location":"Projeto_I/relatorio_final/#modelo-nao-supervisionado-k-means","title":"Modelo N\u00e3o Supervisionado: K-Means","text":"<p>A avalia\u00e7\u00e3o do K-Means focou em duas frentes: a qualidade intr\u00ednseca dos clusters e a compara\u00e7\u00e3o dos clusters com as classes reais.</p> <ul> <li>Score de Silhueta: O modelo obteve um score de ~0.28. Este valor, que varia de -1 a 1, sugere que os clusters formados n\u00e3o s\u00e3o muito densos nem bem separados, indicando uma sobreposi\u00e7\u00e3o consider\u00e1vel entre os grupos.</li> <li>Adjusted Rand Score: Ao comparar os dois clusters encontrados pelo K-Means com as classes reais (\"Bom\" e \"Regular\"), o score foi de ~0.05. Um valor t\u00e3o pr\u00f3ximo de zero indica que a estrutura de agrupamento encontrada pelo K-Means n\u00e3o corresponde \u00e0s categorias de qualidade definidas.</li> </ul> <p>Isso sugere que a distin\u00e7\u00e3o entre um vinho \"Bom\" e \"Regular\" n\u00e3o forma agrupamentos geometricamente simples no espa\u00e7o de caracter\u00edsticas.</p>"},{"location":"Projeto_I/relatorio_final/#6-relatorio-final-e-conclusao","title":"6. Relat\u00f3rio Final e Conclus\u00e3o","text":"<p>Este projeto demonstrou o ciclo completo de desenvolvimento de modelos de Machine Learning em um dataset real. Conclui-se que:</p> <ul> <li>Para a tarefa de classifica\u00e7\u00e3o, os modelos supervisionados foram eficazes, com a \u00c1rvore de Decis\u00e3o apresentando o melhor desempenho (acur\u00e1cia de 77%).</li> <li>O modelo K-Means n\u00e3o foi capaz de recriar as classes de qualidade de forma n\u00e3o supervisionada, evidenciando que, embora \u00fatil para encontrar padr\u00f5es, nem sempre os clusters encontrados correspondem a uma classifica\u00e7\u00e3o de neg\u00f3cio pr\u00e9-definida.</li> <li>Poss\u00edveis Melhorias: Para futuros trabalhos, poderiam ser exploradas t\u00e9cnicas de feature engineering mais avan\u00e7adas, o teste de outros algoritmos (como Random Forest ou Gradient Boosting) e o ajuste fino de hiperpar\u00e2metros para otimizar ainda mais a performance do modelo de classifica\u00e7\u00e3o.</li> </ul>"},{"location":"decision-tree/main/","title":"Main","text":"In\u00a0[15]: hide-input Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier, plot_tree from sklearn.metrics import accuracy_score, classification_report, confusion_matrix In\u00a0[16]: hide-input Copied! <pre># %%\n# Carrega o dataset Iris\niris = load_iris()\n\n# Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o\nX = pd.DataFrame(iris.data, columns=iris.feature_names)\ny = pd.Series(iris.target, name=\"species\")\n\n# Exibe as 5 primeiras linhas do DataFrame\nX.head()\n</pre> # %% # Carrega o dataset Iris iris = load_iris()  # Converte para DataFrame do Pandas para facilitar a manipula\u00e7\u00e3o X = pd.DataFrame(iris.data, columns=iris.feature_names) y = pd.Series(iris.target, name=\"species\")  # Exibe as 5 primeiras linhas do DataFrame X.head() Out[16]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 In\u00a0[17]: Copied! <pre># %%\n# Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica\n(X.head()\n .style\n .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais\n .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela\n .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas\n)\n</pre> # %% # Estilizando a tabela para uma apresenta\u00e7\u00e3o mais rica (X.head()  .style  .format(\"{:.2f}\")  # Formata todos os n\u00fameros para terem 2 casas decimais  .set_caption(\"As 5 Primeiras Amostras do Conjunto de Dados Iris\")  # Adiciona um t\u00edtulo \u00e0 tabela  .background_gradient(cmap='Blues', axis=0)  # Cria um gradiente de cor azul nas colunas ) Out[17]: As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 In\u00a0[18]: Copied! <pre># %%\n# Mostra estat\u00edsticas descritivas das vari\u00e1veis\nX.describe()\n</pre> # %% # Mostra estat\u00edsticas descritivas das vari\u00e1veis X.describe() Out[18]: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 In\u00a0[19]: Copied! <pre># %%\n# Gera histogramas para cada vari\u00e1vel\nX.hist(figsize=(10, 8))\nplt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\")\nplt.show()\n</pre> # %% # Gera histogramas para cada vari\u00e1vel X.hist(figsize=(10, 8)) plt.suptitle(\"Distribui\u00e7\u00e3o das vari\u00e1veis\") plt.show() In\u00a0[20]: Copied! <pre># %%\n# Divide o dataset em treino (70%) e teste (30%)\n# O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\n</pre> # %% # Divide o dataset em treino (70%) e teste (30%) # O stratify=y garante que a propor\u00e7\u00e3o das classes seja a mesma nos dois conjuntos X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.3, random_state=42, stratify=y )  print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\") print(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\") <pre>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n</pre> In\u00a0[21]: Copied! <pre># %%\n# Cria o classificador de \u00c1rvore de Decis\u00e3o\n# criterion=\"entropy\" usa a entropia como medida de impureza\nclf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n\n# Treina o modelo com os dados de treino\nclf.fit(X_train, y_train)\n\nprint(\"Modelo treinado com sucesso!\")\n</pre> # %% # Cria o classificador de \u00c1rvore de Decis\u00e3o # criterion=\"entropy\" usa a entropia como medida de impureza clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)  # Treina o modelo com os dados de treino clf.fit(X_train, y_train)  print(\"Modelo treinado com sucesso!\") <pre>Modelo treinado com sucesso!\n</pre> In\u00a0[22]: Copied! <pre># %%\n# Faz previs\u00f5es nos dados de teste\ny_pred = clf.predict(X_test)\n\n# Imprime a acur\u00e1cia\nprint(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))\n\n# Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score\nprint(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n</pre> # %% # Faz previs\u00f5es nos dados de teste y_pred = clf.predict(X_test)  # Imprime a acur\u00e1cia print(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))  # Imprime o relat\u00f3rio de classifica\u00e7\u00e3o com precis\u00e3o, recall e f1-score print(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names)) <pre>Acur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n\n</pre> In\u00a0[23]: Copied! <pre># %%\n# Gera a matriz de confus\u00e3o\ncm = confusion_matrix(y_test, y_pred)\n\n# Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o\nplt.figure(figsize=(6, 5))\nsns.heatmap(\n    cm, \n    annot=True, \n    fmt=\"d\", \n    cmap=\"Blues\", \n    xticklabels=iris.target_names, \n    yticklabels=iris.target_names\n)\nplt.xlabel(\"Previsto\")\nplt.ylabel(\"Real\")\nplt.title(\"Matriz de Confus\u00e3o\")\nplt.show()\n</pre> # %% # Gera a matriz de confus\u00e3o cm = confusion_matrix(y_test, y_pred)  # Plota a matriz de confus\u00e3o usando um heatmap para melhor visualiza\u00e7\u00e3o plt.figure(figsize=(6, 5)) sns.heatmap(     cm,      annot=True,      fmt=\"d\",      cmap=\"Blues\",      xticklabels=iris.target_names,      yticklabels=iris.target_names ) plt.xlabel(\"Previsto\") plt.ylabel(\"Real\") plt.title(\"Matriz de Confus\u00e3o\") plt.show() In\u00a0[24]: Copied! <pre># %%\n# Plota a \u00e1rvore de decis\u00e3o gerada\nplt.figure(figsize=(20, 12))\nplot_tree(\n    clf, \n    feature_names=iris.feature_names, \n    class_names=list(iris.target_names), \n    filled=True,\n    fontsize=10\n)\nplt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\")\nplt.show()\n</pre> # %% # Plota a \u00e1rvore de decis\u00e3o gerada plt.figure(figsize=(20, 12)) plot_tree(     clf,      feature_names=iris.feature_names,      class_names=list(iris.target_names),      filled=True,     fontsize=10 ) plt.title(\"\u00c1rvore de Decis\u00e3o - Dataset Iris\") plt.show()"},{"location":"decision-tree/main/","title":"\u00c1rvore de Decis\u00e3o","text":"sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 As 5 Primeiras Amostras do Conjunto de Dados Iris sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.10 3.50 1.40 0.20 1 4.90 3.00 1.40 0.20 2 4.70 3.20 1.30 0.20 3 4.60 3.10 1.50 0.20 4 5.00 3.60 1.40 0.20 sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 <pre><code>Tamanho do conjunto de treino: 105 amostras\nTamanho do conjunto de teste: 45 amostras\n\n\nModelo treinado com sucesso!\n\n\nAcur\u00e1cia: 0.8888888888888888\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        15\n  versicolor       0.81      0.87      0.84        15\n   virginica       0.86      0.80      0.83        15\n\n    accuracy                           0.89        45\n   macro avg       0.89      0.89      0.89        45\nweighted avg       0.89      0.89      0.89        45\n</code></pre>"},{"location":"projeto/kmeans/","title":"Relat\u00f3rio T\u00e9cnico: Agrupamento de Dados com K-Means","text":"<p>Autor: Bruno Assis</p> <p>Data: 19 de setembro de 2025</p> <p>Projeto: An\u00e1lise de Agrupamento com K-Means</p>"},{"location":"projeto/kmeans/#1-exploracao-dos-dados","title":"1. Explora\u00e7\u00e3o dos Dados","text":"<p>O objetivo deste projeto \u00e9 aplicar o algoritmo de agrupamento n\u00e3o supervisionado K-Means para identificar clusters distintos em um conjunto de dados. Para esta an\u00e1lise, foi utilizado um dataset sint\u00e9tico de 300 amostras e 2 caracter\u00edsticas, gerado atrav\u00e9s da fun\u00e7\u00e3o <code>make_blobs</code> da biblioteca Scikit-learn. Este dataset simula um cen\u00e1rio onde se busca agrupar corpos celestes com base em duas medi\u00e7\u00f5es, como luminosidade e temperatura, sem conhecimento pr\u00e9vio de suas classifica\u00e7\u00f5es.</p> <p>As estat\u00edsticas descritivas n\u00e3o revelam uma estrutura \u00f3bvia, mas a an\u00e1lise visual inicial dos dados em um gr\u00e1fico de dispers\u00e3o sugere a presen\u00e7a de agrupamentos naturais.</p>"},{"location":"projeto/kmeans/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>O pr\u00e9-processamento \u00e9 uma etapa cr\u00edtica para algoritmos baseados em dist\u00e2ncia, como o K-Means. A presen\u00e7a de caracter\u00edsticas em escalas distintas pode enviesar o modelo, atribuindo uma import\u00e2ncia desproporcional \u00e0 caracter\u00edstica com maior vari\u00e2ncia.</p> <p>Para mitigar este efeito, foi aplicada a t\u00e9cnica de padroniza\u00e7\u00e3o utilizando o <code>StandardScaler</code> do Scikit-learn. Este processo transforma os dados para que cada caracter\u00edstica tenha uma m\u00e9dia de 0 e um desvio padr\u00e3o de 1, garantindo que todas as <code>features</code> contribuam de forma equitativa para o c\u00e1lculo da dist\u00e2ncia euclidiana. Nenhuma amostra com valor ausente foi identificada.</p>"},{"location":"projeto/kmeans/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>Em problemas de aprendizado n\u00e3o supervisionado, como o agrupamento, o objetivo n\u00e3o \u00e9 treinar um modelo para prever valores em dados futuros, mas sim descobrir a estrutura latente no conjunto de dados completo. Por essa raz\u00e3o metodol\u00f3gica, a separa\u00e7\u00e3o tradicional dos dados em conjuntos de treino e teste n\u00e3o foi aplicada. Todo o dataset foi utilizado para a identifica\u00e7\u00e3o dos clusters, o que \u00e9 uma pr\u00e1tica padr\u00e3o para este tipo de an\u00e1lise.</p>"},{"location":"projeto/kmeans/#4-treinamento-do-modelo","title":"4. Treinamento do Modelo","text":"<p>A implementa\u00e7\u00e3o do K-Means requer a defini\u00e7\u00e3o pr\u00e9via do n\u00famero de clusters (k). Para determinar o valor \u00f3timo de <code>k</code> de forma emp\u00edrica, foi utilizado o M\u00e9todo do Cotovelo (Elbow Method). Este m\u00e9todo consiste em executar o algoritmo K-Means para um intervalo de valores de <code>k</code> (neste caso, de 1 a 10) e calcular a Soma dos Quadrados Intra-Cluster (WCSS) para cada itera\u00e7\u00e3o.</p> <p>O gr\u00e1fico resultante da WCSS versus o n\u00famero de clusters \u00e9 ent\u00e3o analisado. O \"cotovelo\" \u2013 ponto onde a taxa de diminui\u00e7\u00e3o da WCSS se torna marcadamente mais lenta \u2013 indica o valor de <code>k</code> que representa o melhor equil\u00edbrio entre o n\u00famero de clusters e a compacta\u00e7\u00e3o intra-cluster.</p>"},{"location":"projeto/kmeans/#5-avaliacao-do-modelo","title":"5. Avalia\u00e7\u00e3o do Modelo","text":"<p>A avalia\u00e7\u00e3o do modelo foi realizada por meio de an\u00e1lise visual e quantitativa.</p> <p>Primeiramente, os clusters identificados pelo algoritmo foram plotados, com cada grupo recebendo uma cor distinta e seus respectivos centroides marcados em vermelho.</p> <p>Para uma avalia\u00e7\u00e3o quantitativa, foi calculado o Score de Silhueta (Silhouette Score), que mede a qualidade do agrupamento. O score varia de -1 a 1, onde valores mais pr\u00f3ximos de 1 indicam que os clusters s\u00e3o densos e bem definidos. O modelo treinado alcan\u00e7ou um Score de Silhueta de aproximadamente 0.7132, o que corrobora a alta qualidade do agrupamento e a boa separa\u00e7\u00e3o entre os clusters.</p>"},{"location":"projeto/kmeans/#6-conclusao","title":"6. Conclus\u00e3o","text":"<p>Este projeto demonstrou com sucesso a aplica\u00e7\u00e3o do algoritmo K-Means para identificar estruturas latentes em um conjunto de dados n\u00e3o rotulado. Atrav\u00e9s de uma metodologia rigorosa, que incluiu a normaliza\u00e7\u00e3o dos dados e a sele\u00e7\u00e3o emp\u00edrica do n\u00famero de clusters via M\u00e9todo do Cotovelo, foi poss\u00edvel treinar um modelo que agrupou os dados em 4 clusters distintos e coesos.</p> <p>A avalia\u00e7\u00e3o, tanto visual quanto quantitativa (Score de Silhueta), confirmou a efic\u00e1cia do modelo. Como poss\u00edveis melhorias futuras, sugere-se a aplica\u00e7\u00e3o de outros algoritmos de agrupamento, como o DBSCAN ou o Agrupamento Hier\u00e1rquico, para comparar os resultados e validar a estrutura de cluster encontrada.</p>"},{"location":"projeto/knn/","title":"Projeto de Classifica\u00e7\u00e3o com K-Nearest Neighbors: Tipos de Solo por Sat\u00e9lite","text":"<p>Autor: Bruno Assis</p> <p>Data: 17 de setembro de 2025</p> <p>Projeto: Classifica\u00e7\u00e3o com K-Nearest Neighbors</p>"},{"location":"projeto/knn/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de classificar tipos de solo com base em dados de observa\u00e7\u00f5es de sat\u00e9lite. Para esta tarefa, foi utilizado o algoritmo K-Nearest Neighbors (KNN), um modelo de aprendizado supervisionado baseado em inst\u00e2ncia, que classifica um novo dado com base na classe de seus \"vizinhos\" mais pr\u00f3ximos no espa\u00e7o de caracter\u00edsticas.</p> <p>O desenvolvimento seguiu as etapas de explora\u00e7\u00e3o, pr\u00e9-processing, divis\u00e3o dos dados, treinamento do modelo e avalia\u00e7\u00e3o de performance, utilizando as bibliotecas <code>pandas</code>, <code>numpy</code>, e <code>scikit-learn</code>.</p>"},{"location":"projeto/knn/#etapa-1-exploracao-dos-dados","title":"Etapa 1: Explora\u00e7\u00e3o dos dados","text":"<p>A primeira etapa consistiu em uma an\u00e1lise para entender a estrutura e as caracter\u00edsticas do conjunto de dados Statlog (Landsat Satellite).</p>"},{"location":"projeto/knn/#natureza-dos-dados","title":"Natureza dos dados","text":"<p>O dataset \u00e9 composto por 6435 amostras (pixels de uma imagem de sat\u00e9lite), cada uma descrita por 36 caracter\u00edsticas (features). Essas caracter\u00edsticas correspondem a valores de intensidade de luz em quatro bandas espectrais (duas vis\u00edveis e duas infravermelhas) para uma vizinhan\u00e7a de 3x3 pixels.</p> <p>O objetivo \u00e9 classificar cada amostra em uma das 6 classes de solo poss\u00edveis: * Classe 1: solo vermelho * Classe 2: solo cinza * Classe 3: solo com vegeta\u00e7\u00e3o de restolho * Classe 4: solo com vegeta\u00e7\u00e3o de algod\u00e3o * Classe 5: mistura de solo e vegeta\u00e7\u00e3o * Classe 7: solo muito \u00famido</p>"},{"location":"projeto/knn/#etapa-2-pre-processamento","title":"Etapa 2: Pr\u00e9-processamento","text":"<p>Nesta etapa, preparamos os dados para o treinamento do modelo, uma fase cr\u00edtica para algoritmos baseados em dist\u00e2ncia como o KNN.</p> <ul> <li> <p>Limpeza e Tratamento de Valores Ausentes: Uma verifica\u00e7\u00e3o inicial confirmou que o dataset estava completo, sem valores nulos ou ausentes, n\u00e3o necessitando de t\u00e9cnicas de imputa\u00e7\u00e3o.</p> </li> <li> <p>Padroniza\u00e7\u00e3o dos Dados (Scaling): O KNN calcula a \"dist\u00e2ncia\" (geralmente euclidiana) entre os pontos de dados para determinar seus vizinhos. Se as caracter\u00edsticas estiverem em escalas diferentes, aquelas com maiores magnitudes dominar\u00e3o o c\u00e1lculo, distorcendo o resultado. Para evitar isso, foi essencial realizar a padroniza\u00e7\u00e3o dos dados. Utilizamos o <code>StandardScaler</code> do scikit-learn, que transforma cada caracter\u00edstica para ter uma m\u00e9dia de 0 e um desvio padr\u00e3o de 1, garantindo que todas contribuam igualmente para o c\u00e1lculo da dist\u00e2ncia.</p> </li> </ul>"},{"location":"projeto/knn/#etapa-3-divisao-dos-dados","title":"Etapa 3: Divis\u00e3o dos dados","text":"<p>Para avaliar o modelo de forma justa, o conjunto de dados foi dividido em dois subconjuntos:</p> <ul> <li>Conjunto de Treino (70% dos dados): Usado para \"apresentar\" os dados ao modelo.</li> <li>Conjunto de Teste (30% dos dados): Usado para avaliar o desempenho do modelo em dados \"novos\".</li> </ul> <p>A divis\u00e3o resultou em: * Tamanho do conjunto de treino: 4504 amostras * Tamanho do conjunto de teste: 1931 amostras</p>"},{"location":"projeto/knn/#etapa-4-treinamento-do-modelo","title":"Etapa 4: Treinamento do modelo","text":"<p>O modelo escolhido foi o <code>KNeighborsClassifier</code> da biblioteca <code>scikit-learn</code>.</p> <ol> <li>Instanciar o modelo: Foi criado um classificador KNN com o hiperpar\u00e2metro <code>n_neighbors=5</code>.</li> <li>Treinar o modelo: O modelo foi treinado com o m\u00e9todo <code>.fit()</code>, que recebeu os dados de treino padronizados (<code>X_train_scaled</code>, <code>y_train</code>).</li> </ol>"},{"location":"projeto/knn/#etapa-5-avaliacao-do-modelo","title":"Etapa 5: Avalia\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s o treinamento, o desempenho do modelo foi avaliado utilizando o conjunto de teste, tamb\u00e9m padronizado.</p>"},{"location":"projeto/knn/#metricas-de-desempenho","title":"M\u00e9tricas de desempenho","text":"<ul> <li>Acur\u00e1cia: O modelo atingiu uma acur\u00e1cia de aproximadamente 90.78%.</li> <li>Relat\u00f3rio de Classifica\u00e7\u00e3o:</li> </ul> Classe Precision Recall F1-Score Support 1 0.91 0.96 0.93 467 2 0.95 0.95 0.95 220 3 0.96 0.96 0.96 403 4 0.81 0.82 0.81 186 5 0.89 0.85 0.87 216 7 0.91 0.88 0.89 439"},{"location":"projeto/knn/#etapa-6-relatorio-final-e-conclusao","title":"Etapa 6: Relat\u00f3rio final e conclus\u00e3o","text":"<p>O projeto demonstrou a efic\u00e1cia do algoritmo KNN para um problema de classifica\u00e7\u00e3o multiespectral. Com um pr\u00e9-processamento adequado, notadamente a padroniza\u00e7\u00e3o dos dados, o modelo alcan\u00e7ou uma alta acur\u00e1cia de 90.78%.</p>"},{"location":"projeto/knn/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<ul> <li>Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros: Realizar uma busca em grade (<code>Grid Search</code>) para encontrar o valor \u00f3timo de <code>K</code>.</li> <li>Valida\u00e7\u00e3o Cruzada (Cross-Validation): Empregar a valida\u00e7\u00e3o cruzada para obter uma estimativa mais confi\u00e1vel do desempenho.</li> <li>Feature Engineering: Explorar a cria\u00e7\u00e3o de novas caracter\u00edsticas para melhorar a separabilidade entre as classes.</li> </ul>"},{"location":"projeto/main/","title":"Projeto de classifica\u00e7\u00e3o com \u00e1rvore de decis\u00e3o: Esp\u00e9cies de flores Iris","text":"<p>Autor: Bruno Assis</p>"},{"location":"projeto/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de classificar esp\u00e9cies de flores do g\u00eanero Iris com base em suas caracter\u00edsticas morfol\u00f3gicas. Para esta tarefa de classifica\u00e7\u00e3o, foi utilizado o algoritmo de \u00c1rvore de Decis\u00e3o, um dos modelos mais intuitivos e poderosos para problemas de classifica\u00e7\u00e3o.</p> <p>O desenvolvimento seguiu as etapas de explora\u00e7\u00e3o, pr\u00e9-processamento, divis\u00e3o dos dados, treinamento e avalia\u00e7\u00e3o do modelo, utilizando as bibliotecas <code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> e <code>scikit-learn</code>.</p>"},{"location":"projeto/main/#etapa-1-exploracao-dos-dados","title":"Etapa 1: Explora\u00e7\u00e3o dos dados","text":"<p>A primeira etapa consistiu em uma an\u00e1lise explorat\u00f3ria para entender a natureza e a estrutura do conjunto de dados Iris.</p>"},{"location":"projeto/main/#natureza-dos-dados","title":"Natureza dos dados","text":"<p>O dataset Iris \u00e9 um conjunto de dados cl\u00e1ssico da \u00e1rea de Machine Learning. Ele cont\u00e9m 150 amostras de flores Iris, divididas igualmente em 3 esp\u00e9cies diferentes: * Setosa * Versicolor * Virginica</p> <p>Para cada amostra, s\u00e3o fornecidas 4 caracter\u00edsticas (features) em cent\u00edmetros: 1.  Comprimento da S\u00e9pala (<code>sepal length</code>) 2.  Largura da S\u00e9pala (<code>sepal width</code>) 3.  Comprimento da P\u00e9tala (<code>petal length</code>) 4.  Largura da P\u00e9tala (<code>petal width</code>)</p> <p>O objetivo do modelo \u00e9, a partir dessas 4 medidas, prever corretamente a qual das 3 esp\u00e9cies a flor pertence.</p>"},{"location":"projeto/main/#estatisticas-descritivas","title":"Estat\u00edsticas descritivas","text":"<p>Uma an\u00e1lise estat\u00edstica nos ajuda a entender a distribui\u00e7\u00e3o e a escala de cada caracter\u00edstica. A tabela abaixo resume as principais m\u00e9tricas:</p> M\u00e9trica Comprimento da S\u00e9pala (cm) Largura da S\u00e9pala (cm) Comprimento da P\u00e9tala (cm) Largura da P\u00e9tala (cm) count 150.00 150.00 150.00 150.00 mean 5.84 3.06 3.76 1.20 std 0.83 0.44 1.77 0.76 min 4.30 2.00 1.00 0.10 25% 5.10 2.80 1.60 0.30 50% 5.80 3.00 4.35 1.30 75% 6.40 3.40 5.10 1.80 max 7.90 4.40 6.90 2.50 <p>A partir da tabela, notamos que as caracter\u00edsticas possuem escalas diferentes (por exemplo, <code>petal length</code> varia muito mais que <code>sepal width</code>), algo que seria importante para outros algoritmos, mas n\u00e3o tanto para \u00c1rvores de Decis\u00e3o.</p>"},{"location":"projeto/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":"<p>Os histogramas abaixo mostram a distribui\u00e7\u00e3o de cada uma das quatro caracter\u00edsticas. As visualiza\u00e7\u00f5es s\u00e3o cruciais para identificar quais features s\u00e3o mais promissoras para separar as classes.</p> <p>Distribui\u00e7\u00e3o das vari\u00e1veis</p> <p></p> <p>Analisando os gr\u00e1ficos, podemos inferir que o comprimento e a largura da p\u00e9tala (<code>petal length</code> e <code>petal width</code>) s\u00e3o caracter\u00edsticas muito poderosas para a classifica\u00e7\u00e3o, pois suas distribui\u00e7\u00f5es mostram agrupamentos mais distintos. J\u00e1 as medidas da s\u00e9pala (<code>sepal length</code> e <code>sepal width</code>) apresentam maior sobreposi\u00e7\u00e3o entre as esp\u00e9cies.</p>"},{"location":"projeto/main/#etapa-2-pre-processamento","title":"Etapa 2: Pr\u00e9-processamento","text":"<p>Nesta etapa, preparamos os dados para o treinamento do modelo.</p> <ul> <li> <p>Limpeza e Tratamento de Valores Ausentes: Foi realizada uma verifica\u00e7\u00e3o de valores nulos ou ausentes no conjunto de dados. O dataset Iris \u00e9 conhecido por ser completo e limpo, e a an\u00e1lise confirmou que n\u00e3o havia dados faltantes, portanto, nenhuma t\u00e9cnica de imputa\u00e7\u00e3o foi necess\u00e1ria.</p> </li> <li> <p>Normaliza\u00e7\u00e3o: Modelos baseados em \u00e1rvores, como a \u00c1rvore de Decis\u00e3o, n\u00e3o s\u00e3o sens\u00edveis \u00e0 escala das features. Eles tomam decis\u00f5es baseadas em pontos de corte (ex: \"comprimento da p\u00e9tala &lt; 2.45 cm?\"), independentemente de a vari\u00e1vel estar em cent\u00edmetros ou mil\u00edmetros. Por essa raz\u00e3o, a normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o dos dados n\u00e3o foi uma etapa necess\u00e1ria para este projeto.</p> </li> </ul>"},{"location":"projeto/main/#etapa-3-divisao-dos-dados","title":"Etapa 3: Divis\u00e3o dos dados","text":"<p>Para avaliar o modelo de forma justa, o conjunto de dados foi dividido em dois subconjuntos:</p> <ol> <li>Conjunto de Treino (70% dos dados): Usado para ensinar o modelo a reconhecer os padr\u00f5es.</li> <li>Conjunto de Teste (30% dos dados): Usado para avaliar o desempenho do modelo em dados \"novos\", que ele nunca viu antes.</li> </ol> <p>Utilizamos a fun\u00e7\u00e3o <code>train_test_split</code> da biblioteca <code>scikit-learn</code>. Um par\u00e2metro crucial utilizado foi a estratifica\u00e7\u00e3o (<code>stratify=y</code>). Isso garante que a propor\u00e7\u00e3o de cada uma das tr\u00eas esp\u00e9cies de flores seja a mesma tanto no conjunto de treino quanto no de teste, evitando desequil\u00edbrios que poderiam enviesar a avalia\u00e7\u00e3o do modelo.</p> <p>O resultado da divis\u00e3o foi: * Tamanho do conjunto de treino: 105 amostras * Tamanho do conjunto de teste: 45 amostras</p>"},{"location":"projeto/main/#etapa-4-treinamento-do-modelo","title":"Etapa 4: Treinamento do modelo","text":"<p>O modelo escolhido foi o <code>DecisionTreeClassifier</code> da <code>scikit-learn</code>.</p> <p>A implementa\u00e7\u00e3o consistiu em: 1.  Instanciar o modelo: Foi criado um classificador de \u00c1rvore de Decis\u00e3o com o hiperpar\u00e2metro <code>criterion=\"entropy\"</code>. A entropia \u00e9 uma m\u00e9trica baseada em Teoria da Informa\u00e7\u00e3o que o algoritmo usa para escolher os melhores atributos e pontos de corte para dividir os dados em cada n\u00f3 da \u00e1rvore. 2.  Treinar o modelo: O modelo foi treinado utilizando o m\u00e9todo <code>.fit()</code>, que recebe os dados e as classes do conjunto de treino (<code>X_train</code>, <code>y_train</code>). Durante este processo, o algoritmo constr\u00f3i a \u00e1rvore de regras que melhor classifica os dados de treinamento.</p>"},{"location":"projeto/main/#etapa-5-avaliacao-do-modelo","title":"Etapa 5: Avalia\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s o treinamento, o desempenho do modelo foi avaliado utilizando o conjunto de teste.</p>"},{"location":"projeto/main/#metricas-de-desempenho","title":"M\u00e9tricas de desempenho","text":"<p>A performance foi medida com base nas seguintes m\u00e9tricas:</p> <ul> <li> <p>Acur\u00e1cia: A propor\u00e7\u00e3o de previs\u00f5es corretas sobre o total de amostras. O modelo atingiu uma acur\u00e1cia de aproximadamente 89%.</p> </li> <li> <p>Relat\u00f3rio de Classifica\u00e7\u00e3o: Fornece uma vis\u00e3o detalhada do desempenho para cada classe.</p> </li> </ul> Classe Precision Recall F1-Score Support setosa 1.00 1.00 1.00 15 versicolor 0.81 0.87 0.84 15 virginica 0.86 0.80 0.83 15 <p>Da tabela, conclu\u00edmos que: * A classe setosa foi perfeitamente classificada (100% em todas as m\u00e9tricas). * Houve uma pequena confus\u00e3o entre as classes versicolor e virginica, que s\u00e3o naturalmente mais parecidas entre si.</p>"},{"location":"projeto/main/#matriz-de-confusao","title":"Matriz de confus\u00e3o","text":"<p>A Matriz de Confus\u00e3o nos permite visualizar exatamente onde o modelo acertou e errou.</p> <p></p> <p>An\u00e1lise da matriz: * Linha 'setosa': 15 foram corretamente previstas como setosa. 0 erros. * Linha 'versicolor': 13 foram corretamente previstas como versicolor, mas 2 foram incorretamente classificadas como virginica. * Linha 'virginica': 12 foram corretamente previstas como virginica, mas 3 foram incorretamente classificadas como versicolor.</p>"},{"location":"projeto/main/#visualizacao-da-arvore-de-decisao","title":"Visualiza\u00e7\u00e3o da \u00c1rvore de decis\u00e3o","text":"<p>A \u00e1rvore gerada pelo modelo pode ser visualizada para entendermos as regras que ela aprendeu.</p> <p></p> <p>A raiz da \u00e1rvore (<code>petal length (cm) &lt;= 2.45</code>) mostra que a caracter\u00edstica mais importante para a primeira divis\u00e3o \u00e9 o comprimento da p\u00e9tala, confirmando nossa an\u00e1lise explorat\u00f3ria inicial.</p>"},{"location":"projeto/main/#etapa-6-relatorio-final-e-conclusao","title":"Etapa 6: Relat\u00f3rio final e conclus\u00e3o","text":"<p>O projeto demonstrou com sucesso a aplica\u00e7\u00e3o de um modelo de \u00c1rvore de Decis\u00e3o para um problema de classifica\u00e7\u00e3o. O modelo alcan\u00e7ou um desempenho robusto, com uma acur\u00e1cia de 89% no conjunto de teste, e foi capaz de aprender regras l\u00f3gicas e interpret\u00e1veis para distinguir entre as esp\u00e9cies de flores Iris.</p> <p>A an\u00e1lise das m\u00e9tricas revelou que o modelo \u00e9 extremamente eficaz em identificar a esp\u00e9cie <code>setosa</code>, mas apresenta uma pequena dificuldade na distin\u00e7\u00e3o entre <code>versicolor</code> e <code>virginica</code>, que s\u00e3o morfologicamente mais similares.</p>"},{"location":"projeto/main/#possiveis-melhorias","title":"Poss\u00edveis melhorias","text":"<p>Para aprimorar ainda mais o desempenho do modelo, os seguintes passos poderiam ser explorados:</p> <ol> <li>Otimiza\u00e7\u00e3o de Hiperpar\u00e2metros: Utilizar t\u00e9cnicas como Grid Search ou Random Search para encontrar a melhor combina\u00e7\u00e3o de hiperpar\u00e2metros (como <code>max_depth</code> e <code>min_samples_leaf</code>), o que pode reduzir o superajuste e melhorar a generaliza\u00e7\u00e3o.</li> <li>Valida\u00e7\u00e3o Cruzada (Cross-Validation): Empregar a valida\u00e7\u00e3o cruzada k-fold para obter uma estimativa mais est\u00e1vel e confi\u00e1vel do desempenho do modelo.</li> <li>Compara\u00e7\u00e3o com Outros Modelos: Treinar e avaliar outros algoritmos de classifica\u00e7\u00e3o, como Random Forest (que \u00e9 um conjunto de \u00e1rvores de decis\u00e3o), SVM ou Regress\u00e3o Log\u00edstica, para comparar os resultados.</li> <li>An\u00e1lise de Import\u00e2ncia das Features: Extrair e visualizar a import\u00e2ncia de cada uma das quatro caracter\u00edsticas para entender quais delas mais contribu\u00edram para as decis\u00f5es do modelo.</li> </ol>"}]}